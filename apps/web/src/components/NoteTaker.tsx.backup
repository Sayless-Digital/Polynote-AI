'use client';

import { useState, useRef } from 'react';
import { Mic, MicOff, Save, Loader2 } from 'lucide-react';

export function NoteTaker() {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [title, setTitle] = useState('');
  const [tags, setTags] = useState<string[]>([]);
  const [categories, setCategories] = useState<string[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [interimTranscript, setInterimTranscript] = useState('');
  const [isTestingSetup, setIsTestingSetup] = useState(false);
  const [useManualInput, setUseManualInput] = useState(false);
  const [manualText, setManualText] = useState('');

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  const testSetup = async () => {
    setIsTestingSetup(true);
    let tests = [];

    // Test 1: Browser support
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      tests.push('‚ùå Browser not supported (use Chrome, Edge, or Safari)');
    } else {
      tests.push('‚úÖ Browser supports speech recognition');
    }

    // Test 2: Network connectivity
    try {
      await fetch('https://www.google.com/favicon.ico', {
        method: 'HEAD',
        mode: 'no-cors',
        signal: AbortSignal.timeout(5000)
      });
      tests.push('‚úÖ Network connection working');
    } catch (error) {
      tests.push('‚ùå Network connection issue');
    }

    // Test 2.5: Speech recognition service connectivity
    try {
      // Test if we can initialize speech recognition without network errors
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const testRecognition = new SpeechRecognition();
      testRecognition.continuous = false;
      testRecognition.interimResults = false;
      testRecognition.lang = 'en-US';

      // Try to start and stop quickly to test connectivity
      await new Promise((resolve, reject) => {
        const timeout = setTimeout(() => {
          testRecognition.stop();
          resolve(true);
        }, 1000);

        testRecognition.onstart = () => {
          console.log('Speech recognition service connected successfully');
          clearTimeout(timeout);
          testRecognition.stop();
          resolve(true);
        };

        testRecognition.onerror = (event) => {
          clearTimeout(timeout);
          if (event.error === 'network') {
            reject(new Error('Speech recognition service network error'));
          } else {
            reject(new Error(`Speech recognition error: ${event.error}`));
          }
        };

        testRecognition.onend = () => {
          resolve(true);
        };

        try {
          testRecognition.start();
        } catch (error) {
          reject(error);
        }
      });

      tests.push('‚úÖ Speech recognition service accessible');
    } catch (error) {
      console.error('Speech recognition connectivity test failed:', error);
      tests.push('‚ùå Speech recognition service blocked or unavailable');
    }

    // Test 3: Microphone permission
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach(track => track.stop());
      tests.push('‚úÖ Microphone access granted');
    } catch (error) {
      tests.push('‚ùå Microphone access denied or unavailable');
    }

    // Test 4: AI connection (server-side test)
    try {
      console.log('Testing AI connection via API endpoint...');
      const response = await fetch('/api/test-ai');
      const result = await response.json();

      console.log('AI API test result:', result);

      if (response.ok && result.success && result.aiConnection) {
        tests.push('‚úÖ AI connection working');
      } else {
        tests.push('‚ùå AI connection failed - check server logs for details');
      }
    } catch (error) {
      console.error('AI API test error:', error);
      tests.push('‚ùå AI API test failed: ' + (error instanceof Error ? error.message : 'Network error'));
    }

    setIsTestingSetup(false);
    alert('Setup Test Results:\n\n' + tests.join('\n'));
  };

  const startSpeechRecognition = async () => {
    // Check if speech recognition is supported
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('Speech recognition is not supported in this browser. Please use Chrome, Edge, or Safari.');
      return;
    }

    // Test network connectivity to Google's speech service
    try {
      const testResponse = await fetch('https://www.google.com/favicon.ico', {
        method: 'HEAD',
        mode: 'no-cors'
      });
      console.log('Network connectivity test passed');
    } catch (error) {
      console.warn('Network connectivity test failed:', error);
      alert('Network connection issue detected. Speech recognition requires internet access. Please check your connection and try again.');
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();

    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';

    recognition.onstart = () => {
      setIsListening(true);
      setInterimTranscript('');
    };

    recognition.onresult = (event) => {
      let finalTranscript = '';
      let interimTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      if (finalTranscript) {
        setTranscript(prev => prev + finalTranscript);
      }
      setInterimTranscript(interimTranscript);
    };

    recognition.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      setIsListening(false);

      // Provide user-friendly error messages
      let errorMessage = 'Speech recognition failed.';
      let suggestions = '';

      switch (event.error) {
        case 'network':
          errorMessage = 'Network connection error.';
          suggestions = 'Speech recognition requires internet access. Check your connection or try:\n‚Ä¢ Using a different network\n‚Ä¢ Disabling VPN/proxy\n‚Ä¢ Using Chrome or Edge browser\n‚Ä¢ Typing notes manually instead';
          break;
        case 'not-allowed':
          errorMessage = 'Microphone access denied.';
          suggestions = 'Please click "Allow" when your browser asks for microphone permission, then try recording again.';
          break;
        case 'no-speech':
          errorMessage = 'No speech detected.';
          suggestions = 'Please speak clearly into your microphone and try again.';
          break;
        case 'aborted':
          errorMessage = 'Speech recognition was stopped.';
          suggestions = 'The recording was interrupted. Please try again.';
          break;
        case 'audio-capture':
          errorMessage = 'Audio capture failed.';
          suggestions = 'Please check that your microphone is properly connected and not being used by another application.';
          break;
        case 'service-not-allowed':
          errorMessage = 'Speech recognition service not allowed.';
          suggestions = 'Your browser or network administrator may have disabled speech recognition.';
          break;
        default:
          errorMessage = `Speech recognition error: ${event.error}`;
          suggestions = 'An unexpected error occurred. Please try again or check the browser console for details.';
      }

      // Show a more detailed alert with suggestions
      alert(`${errorMessage}\n\n${suggestions}`);
    };

    recognition.onend = () => {
      setIsListening(false);
      setInterimTranscript('');
    };

    recognitionRef.current = recognition;
    recognition.start();
  };

  const stopSpeechRecognition = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      const audioChunks: Blob[] = [];

      mediaRecorder.ondataavailable = (event) => {
        audioChunks.push(event.data);
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        await processAudio(audioBlob);
      };

      mediaRecorder.start();
      setIsRecording(true);
      startSpeechRecognition(); // Start speech recognition alongside recording
    } catch (error) {
      console.error('Error starting recording:', error);
      alert('Error accessing microphone. Please check permissions.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      stopSpeechRecognition();

      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    }
  };

  const processAudio = async (audioBlob: Blob) => {
    setIsProcessing(true);
    try {
      // For now, we'll use a mock transcription
      // In a production app, you'd integrate with:
      // - Google Speech-to-Text API
      // - OpenAI Whisper API
      // - Azure Speech Services
      setTimeout(async () => {
        const mockTranscript = "This is a sample transcript from your voice recording. The AI will analyze this content and provide tags, categories, and a summary.";
        setTranscript(mockTranscript);

        // Use Gemini AI to analyze the transcript
        try {
          // Import the AI function dynamically to avoid SSR issues
          const { analyzeNote } = await import('@/lib/ai');
          const analysis = await analyzeNote(mockTranscript);
          console.log('AI analysis completed:', analysis);

          setTitle(analysis.title);
          setTags(analysis.tags);
          setCategories(analysis.categories);
        } catch (aiError) {
          console.error('Error with AI analysis:', aiError);
          // Fallback to basic analysis
          setTitle("Voice Note");
          setTags(["note"]);
          setCategories(["general"]);
        }

        setIsProcessing(false);
      }, 2000);
    } catch (error) {
      console.error('Error processing audio:', error);
      setIsProcessing(false);
    }
  };

  const saveNote = async () => {
    const contentToSave = useManualInput ? manualText : transcript;
    if (!contentToSave.trim()) return;

    setIsProcessing(true);
    try {
      const response = await fetch('/api/notes', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          title: title || undefined,
          content: contentToSave,
          transcript: useManualInput ? null : transcript,
          tags,
          categories,
        }),
      });

      if (!response.ok) {
        throw new Error('Failed to save note');
      }

      const savedNote = await response.json();

      // Reset form
      setTranscript('');
      setManualText('');
      setTitle('');
      setTags([]);
      setCategories([]);

      alert('Note saved successfully!');
    } catch (error) {
      console.error('Error saving note:', error);
      alert('Error saving note. Please try again.');
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div className="max-w-4xl mx-auto">
      <div className="bg-white dark:bg-gray-800 rounded-lg shadow-sm border border-gray-200 dark:border-gray-700 p-6">
        <h2 className="text-xl font-semibold text-gray-900 dark:text-white mb-6">
          Take Voice Notes
        </h2>

        {/* Input Controls */}
        <div className="flex flex-col items-center justify-center mb-6">
          {useManualInput ? (
            <div className="w-full">
              <textarea
                value={manualText}
                onChange={(e) => setManualText(e.target.value)}
                placeholder="Type your note here..."
                className="w-full px-4 py-3 border border-gray-300 dark:border-gray-600 rounded-md bg-white dark:bg-gray-700 text-gray-900 dark:text-white placeholder-gray-500 dark:placeholder-gray-400 focus:ring-2 focus:ring-blue-500 focus:border-transparent resize-vertical min-h-[100px]"
                rows={4}
              />
            </div>
          ) : (
            <button
              onClick={isRecording ? stopRecording : startRecording}
              disabled={isProcessing}
              className={`flex items-center gap-3 px-6 py-3 rounded-full font-medium transition-colors ${
                isRecording
                  ? 'bg-red-500 hover:bg-red-600 text-white animate-pulse'
                  : 'bg-blue-500 hover:bg-blue-600 text-white'
              } disabled:opacity-50 disabled:cursor-not-allowed`}
            >
              {isRecording ? (
                <>
                  <MicOff className="w-5 h-5" />
                  Stop Recording
                </>
              ) : (
                <>
                  <Mic className="w-5 h-5" />
                  Start Recording
                </>
              )}
            </button>
          )}
        </div>

          {/* Test Setup Button */}
          <div className="mt-4">
            <button
              onClick={testSetup}
              disabled={isTestingSetup}
              className="px-4 py-2 bg-gray-500 hover:bg-gray-600 text-white rounded-md font-medium transition-colors disabled:opacity-50 disabled:cursor-not-allowed text-sm"
            >
              {isTestingSetup ? 'Testing...' : 'Test Setup'}
            </button>
          </div>

          {/* Input Mode Toggle */}
          <div className="mt-4 flex justify-center">
            <div className="flex items-center space-x-4">
              <button
                onClick={() => setUseManualInput(false)}
                className={`px-3 py-1 text-sm rounded-md transition-colors ${
                  !useManualInput
                    ? 'bg-blue-100 text-blue-700 dark:bg-blue-900 dark:text-blue-300'
                    : 'text-gray-500 hover:text-gray-700 dark:text-gray-400'
                }`}
              >
                üé§ Voice Input
              </button>
              <button
                onClick={() => setUseManualInput(true)}
                className={`px-3 py-1 text-sm rounded-md transition-colors ${
                  useManualInput
                    ? 'bg-blue-100 text-blue-700 dark:bg-blue-900 dark:text-blue-300'
                    : 'text-gray-500 hover:text-gray-700 dark:text-gray-400'
                }`}
              >
                ‚úèÔ∏è Manual Input
              </button>
            </div>
          </div>

          {/* Status Information */}
          <div className="mt-3 text-center">
            <p className="text-sm text-gray-600 dark:text-gray-400">
              üí° <strong>Tip:</strong> Click "Test Setup" first to verify everything is working
            </p>
            <p className="text-xs text-gray-500 dark:text-gray-500 mt-1">
              Supported browsers: Chrome, Edge, Safari
            </p>
          </div>

          {/* Recording Status */}
          {isRecording && (
            <div className="mt-3 flex items-center gap-2 text-sm">
              <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
              <span className="text-gray-600 dark:text-gray-400">
                {isListening ? 'Listening & Recording...' : 'Recording...'}
              </span>
            </div>
          )}
        </div>

        {/* Processing Indicator */}
        {isProcessing && (
          <div className="flex items-center justify-center mb-6">
            <Loader2 className="w-6 h-6 animate-spin text-blue-500 mr-2" />
            <span className="text-gray-600 dark:text-gray-400">
              Processing your voice note...
            </span>
          </div>
        )}

        {/* Content Display */}
        {(transcript || manualText || isRecording) && (
          <div className="mb-6">
            <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
              Transcript
            </label>
            <div className="bg-gray-50 dark:bg-gray-700 rounded-lg p-4 border border-gray-200 dark:border-gray-600 min-h-[100px]">
              <p className="text-gray-900 dark:text-white whitespace-pre-wrap">
                {useManualInput ? manualText : (
                  <>
                    {transcript}
                    {interimTranscript && (
                      <span className="text-gray-500 dark:text-gray-400 italic">
                        {interimTranscript}
                      </span>
                    )}
                    {isRecording && !transcript && !interimTranscript && (
                      <span className="text-gray-500 dark:text-gray-400 italic">
                        Speak now... Your words will appear here
                      </span>
                    )}
                  </>
                )}
                {!useManualInput && !isRecording && !transcript && !manualText && (
                  <span className="text-gray-500 dark:text-gray-400 italic">
                    Record a voice note or switch to manual input
                  </span>
                )}
              </p>
            </div>
          </div>
        )}

        {/* Note Details */}
        {(transcript || manualText || title) && (
          <div className="space-y-4">
            <div>
              <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                Title
              </label>
              <input
                type="text"
                value={title}
                onChange={(e) => setTitle(e.target.value)}
                placeholder="Enter note title..."
                className="w-full px-3 py-2 border border-gray-300 dark:border-gray-600 rounded-md bg-white dark:bg-gray-700 text-gray-900 dark:text-white placeholder-gray-500 dark:placeholder-gray-400 focus:ring-2 focus:ring-blue-500 focus:border-transparent"
              />
            </div>

            <div>
              <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                AI-Generated Tags
              </label>
              <div className="flex flex-wrap gap-2">
                {tags.map((tag, index) => (
                  <span
                    key={index}
                    className="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-300"
                  >
                    {tag}
                  </span>
                ))}
              </div>
            </div>

            <div>
              <label className="block text-sm font-medium text-gray-700 dark:text-gray-300 mb-2">
                Categories
              </label>
              <div className="flex flex-wrap gap-2">
                {categories.map((category, index) => (
                  <span
                    key={index}
                    className="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-300"
                  >
                    {category}
                  </span>
                ))}
              </div>
            </div>

            <div className="flex justify-end">
              <button
                onClick={saveNote}
                disabled={isProcessing || !(transcript.trim() || manualText.trim())}
                className="flex items-center gap-2 px-4 py-2 bg-green-500 hover:bg-green-600 text-white rounded-md font-medium transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
              >
                <Save className="w-4 h-4" />
                Save Note
              </button>
            </div>
          </div>
        )}
      </div>
    </div>
  );
}
