{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 3, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 49, "column": 0}, "map": {"version":3,"sources":["file:///home/slk/Documents/Projects/polynote/apps/web/src/lib/ai.ts"],"sourcesContent":["import { google } from '@ai-sdk/google';\nimport { generateText, generateObject } from 'ai';\nimport { z } from 'zod';\n\n// Initialize Gemini Flash model with explicit API key\nexport const geminiFlash = google('models/gemini-1.5-flash-latest', {\n  apiKey: process.env.GOOGLE_GENERATIVE_AI_API_KEY,\n});\n\n// Schema for note analysis\nconst NoteAnalysisSchema = z.object({\n  title: z.string(),\n  summary: z.string(),\n  tags: z.array(z.string()),\n  categories: z.array(z.string()),\n  sentiment: z.string(),\n  keyPoints: z.array(z.string()),\n});\n\n// Schema for search queries\nconst SearchQuerySchema = z.object({\n  intent: z.string(),\n  keywords: z.array(z.string()),\n  filters: z.object({\n    categories: z.array(z.string()).optional(),\n    tags: z.array(z.string()).optional(),\n    dateRange: z.string().optional(),\n  }),\n});\n\n/**\n * Analyze a note transcript and extract metadata\n */\nexport async function analyzeNote(transcript: string) {\n  const prompt = `You are an AI assistant that analyzes notes and extracts structured information.\n\nNote content: \"${transcript}\"\n\nPlease analyze this content and provide:\n1. A concise, descriptive title (not just the first few words)\n2. A brief summary that captures the main ideas\n3. 3-5 relevant tags/keywords\n4. Appropriate categories\n5. The overall sentiment\n6. Key points mentioned\n\nMake sure to actually analyze and summarize the content, not just repeat it.`;\n\n  try {\n    console.log('Calling AI analysis with prompt:', prompt.substring(0, 200) + '...');\n    const result = await generateObject({\n      model: geminiFlash,\n      schema: NoteAnalysisSchema,\n      prompt,\n    });\n\n    console.log('AI analysis successful:', result.object);\n    return result.object;\n  } catch (error) {\n    console.error('AI analysis failed, using fallback:', error);\n    // Fallback analysis\n    return {\n      title: transcript.split(' ').slice(0, 5).join(' ') + '...',\n      summary: transcript.length > 100 ? transcript.substring(0, 100) + '...' : transcript,\n      tags: ['note'],\n      categories: ['general'],\n      sentiment: 'neutral',\n      keyPoints: [transcript],\n    };\n  }\n}\n\n/**\n * Generate search suggestions based on user query\n */\nexport async function generateSearchQuery(query: string) {\n  const prompt = `\nAnalyze this search query and provide structured search parameters:\n\nQuery: \"${query}\"\n\nPlease identify:\n- The user's intent\n- Key search keywords\n- Any category or tag filters mentioned\n- Date range preferences if any\n\nMake the search parameters specific and helpful.\n`;\n\n  try {\n    const result = await generateObject({\n      model: geminiFlash,\n      schema: SearchQuerySchema,\n      prompt,\n    });\n\n    return result.object;\n  } catch (error) {\n    console.error('Error generating search query:', error);\n    return {\n      intent: 'general_search',\n      keywords: query.split(' '),\n      filters: {},\n    };\n  }\n}\n\n/**\n * Generate a response to user questions about their notes\n */\nexport async function generateNoteResponse(question: string, context: string) {\n  const prompt = `\nBased on the following note content, answer the user's question:\n\nNote Content: \"${context}\"\n\nUser Question: \"${question}\"\n\nProvide a helpful, concise answer based on the note content.\n`;\n\n  try {\n    const result = await generateText({\n      model: geminiFlash,\n      prompt,\n    });\n\n    return result.text;\n  } catch (error) {\n    console.error('Error generating response:', error);\n    return 'I apologize, but I encountered an error processing your question.';\n  }\n}\n\n/**\n * Test AI connection and API key\n */\nexport async function testAIConnection(): Promise<boolean> {\n  try {\n    const result = await generateText({\n      model: geminiFlash,\n      prompt: 'Say \"Hello\" if you can read this message.',\n    });\n\n    return result.text.includes('Hello') || result.text.length > 0;\n  } catch (error) {\n    console.error('AI connection test failed:', error);\n    return false;\n  }\n}\n\n/**\n * Transcribe audio to text (placeholder for voice transcription)\n */\nexport async function transcribeAudio(): Promise<string> {\n  // This is a placeholder - in a real implementation, you'd use:\n  // - Web Speech API for browser-based transcription\n  // - Google Speech-to-Text API\n  // - OpenAI Whisper API\n  // For now, return a mock transcript\n  return new Promise((resolve) => {\n    setTimeout(() => {\n      resolve(\"This is a mock transcript from the audio. In a real implementation, this would be the actual transcribed text from the user's voice recording.\");\n    }, 1000);\n  });\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAAA;AACA;AACA;;;;AAGO,MAAM,cAAc,IAAA,mKAAM,EAAC,kCAAkC;IAClE,QAAQ,QAAQ,GAAG,CAAC,4BAA4B;AAClD;AAEA,2BAA2B;AAC3B,MAAM,qBAAqB,oLAAC,CAAC,MAAM,CAAC;IAClC,OAAO,oLAAC,CAAC,MAAM;IACf,SAAS,oLAAC,CAAC,MAAM;IACjB,MAAM,oLAAC,CAAC,KAAK,CAAC,oLAAC,CAAC,MAAM;IACtB,YAAY,oLAAC,CAAC,KAAK,CAAC,oLAAC,CAAC,MAAM;IAC5B,WAAW,oLAAC,CAAC,MAAM;IACnB,WAAW,oLAAC,CAAC,KAAK,CAAC,oLAAC,CAAC,MAAM;AAC7B;AAEA,4BAA4B;AAC5B,MAAM,oBAAoB,oLAAC,CAAC,MAAM,CAAC;IACjC,QAAQ,oLAAC,CAAC,MAAM;IAChB,UAAU,oLAAC,CAAC,KAAK,CAAC,oLAAC,CAAC,MAAM;IAC1B,SAAS,oLAAC,CAAC,MAAM,CAAC;QAChB,YAAY,oLAAC,CAAC,KAAK,CAAC,oLAAC,CAAC,MAAM,IAAI,QAAQ;QACxC,MAAM,oLAAC,CAAC,KAAK,CAAC,oLAAC,CAAC,MAAM,IAAI,QAAQ;QAClC,WAAW,oLAAC,CAAC,MAAM,GAAG,QAAQ;IAChC;AACF;AAKO,eAAe,YAAY,UAAkB;IAClD,MAAM,SAAS,CAAC;;eAEH,EAAE,WAAW;;;;;;;;;;4EAUgD,CAAC;IAE3E,IAAI;QACF,QAAQ,GAAG,CAAC,oCAAoC,OAAO,SAAS,CAAC,GAAG,OAAO;QAC3E,MAAM,SAAS,MAAM,IAAA,wKAAc,EAAC;YAClC,OAAO;YACP,QAAQ;YACR;QACF;QAEA,QAAQ,GAAG,CAAC,2BAA2B,OAAO,MAAM;QACpD,OAAO,OAAO,MAAM;IACtB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,uCAAuC;QACrD,oBAAoB;QACpB,OAAO;YACL,OAAO,WAAW,KAAK,CAAC,KAAK,KAAK,CAAC,GAAG,GAAG,IAAI,CAAC,OAAO;YACrD,SAAS,WAAW,MAAM,GAAG,MAAM,WAAW,SAAS,CAAC,GAAG,OAAO,QAAQ;YAC1E,MAAM;gBAAC;aAAO;YACd,YAAY;gBAAC;aAAU;YACvB,WAAW;YACX,WAAW;gBAAC;aAAW;QACzB;IACF;AACF;AAKO,eAAe,oBAAoB,KAAa;IACrD,MAAM,SAAS,CAAC;;;QAGV,EAAE,MAAM;;;;;;;;;AAShB,CAAC;IAEC,IAAI;QACF,MAAM,SAAS,MAAM,IAAA,wKAAc,EAAC;YAClC,OAAO;YACP,QAAQ;YACR;QACF;QAEA,OAAO,OAAO,MAAM;IACtB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO;YACL,QAAQ;YACR,UAAU,MAAM,KAAK,CAAC;YACtB,SAAS,CAAC;QACZ;IACF;AACF;AAKO,eAAe,qBAAqB,QAAgB,EAAE,OAAe;IAC1E,MAAM,SAAS,CAAC;;;eAGH,EAAE,QAAQ;;gBAET,EAAE,SAAS;;;AAG3B,CAAC;IAEC,IAAI;QACF,MAAM,SAAS,MAAM,IAAA,sKAAY,EAAC;YAChC,OAAO;YACP;QACF;QAEA,OAAO,OAAO,IAAI;IACpB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,8BAA8B;QAC5C,OAAO;IACT;AACF;AAKO,eAAe;IACpB,IAAI;QACF,MAAM,SAAS,MAAM,IAAA,sKAAY,EAAC;YAChC,OAAO;YACP,QAAQ;QACV;QAEA,OAAO,OAAO,IAAI,CAAC,QAAQ,CAAC,YAAY,OAAO,IAAI,CAAC,MAAM,GAAG;IAC/D,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,8BAA8B;QAC5C,OAAO;IACT;AACF;AAKO,eAAe;IACpB,+DAA+D;IAC/D,mDAAmD;IACnD,8BAA8B;IAC9B,uBAAuB;IACvB,oCAAoC;IACpC,OAAO,IAAI,QAAQ,CAAC;QAClB,WAAW;YACT,QAAQ;QACV,GAAG;IACL;AACF","debugId":null}},
    {"offset": {"line": 212, "column": 0}, "map": {"version":3,"sources":["file:///home/slk/Documents/Projects/polynote/apps/web/src/app/api/notes/analyze/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\nimport { analyzeNote } from '@/lib/ai';\n\nexport async function POST(request: NextRequest) {\n  try {\n    const body = await request.json();\n    const { content, title } = body;\n\n    if (!content?.trim()) {\n      return NextResponse.json(\n        { error: 'Content is required' },\n        { status: 400 }\n      );\n    }\n\n    console.log('AI Analysis - Content received:', {\n      contentLength: content.length,\n      hasFileContent: content.includes('--- Content from'),\n      contentPreview: content.substring(0, 200) + (content.length > 200 ? '...' : ''),\n      fileContentSections: (content.match(/--- Content from .+? ---/g) || []).length,\n      fullContent: content\n    });\n\n    // Use the existing AI analysis function\n    // Content now includes both user text and extracted file content\n    const analysis = await analyzeNote(content);\n\n    console.log('AI Analysis - Result:', {\n      title: analysis.title,\n      tags: analysis.tags,\n      categories: analysis.categories,\n      summaryLength: analysis.summary?.length || 0\n    });\n\n    return NextResponse.json(analysis);\n  } catch (error) {\n    console.error('Error analyzing note:', error);\n    return NextResponse.json(\n      { error: 'Failed to analyze note' },\n      { status: 500 }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,MAAM,EAAE,OAAO,EAAE,KAAK,EAAE,GAAG;QAE3B,IAAI,CAAC,SAAS,QAAQ;YACpB,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAsB,GAC/B;gBAAE,QAAQ;YAAI;QAElB;QAEA,QAAQ,GAAG,CAAC,mCAAmC;YAC7C,eAAe,QAAQ,MAAM;YAC7B,gBAAgB,QAAQ,QAAQ,CAAC;YACjC,gBAAgB,QAAQ,SAAS,CAAC,GAAG,OAAO,CAAC,QAAQ,MAAM,GAAG,MAAM,QAAQ,EAAE;YAC9E,qBAAqB,CAAC,QAAQ,KAAK,CAAC,gCAAgC,EAAE,EAAE,MAAM;YAC9E,aAAa;QACf;QAEA,wCAAwC;QACxC,iEAAiE;QACjE,MAAM,WAAW,MAAM,IAAA,gJAAW,EAAC;QAEnC,QAAQ,GAAG,CAAC,yBAAyB;YACnC,OAAO,SAAS,KAAK;YACrB,MAAM,SAAS,IAAI;YACnB,YAAY,SAAS,UAAU;YAC/B,eAAe,SAAS,OAAO,EAAE,UAAU;QAC7C;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;IAC3B,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,yBAAyB;QACvC,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAyB,GAClC;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}}]
}