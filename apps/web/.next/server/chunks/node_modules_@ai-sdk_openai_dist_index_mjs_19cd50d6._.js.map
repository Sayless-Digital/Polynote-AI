{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/openai-provider.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/chat/openai-chat-language-model.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/openai-error.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/chat/convert-to-openai-chat-messages.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/chat/get-response-metadata.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/chat/map-openai-finish-reason.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/chat/openai-chat-options.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/chat/openai-chat-prepare-tools.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/tool/file-search.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/tool/web-search-preview.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/completion/openai-completion-language-model.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/completion/convert-to-openai-completion-prompt.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/completion/get-response-metadata.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/completion/map-openai-finish-reason.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/completion/openai-completion-options.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/embedding/openai-embedding-model.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/embedding/openai-embedding-options.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/image/openai-image-model.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/image/openai-image-options.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/tool/code-interpreter.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/openai-tools.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/responses/openai-responses-language-model.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/responses/convert-to-openai-responses-messages.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/responses/map-openai-responses-finish-reason.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/responses/openai-responses-prepare-tools.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/speech/openai-speech-model.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/transcription/openai-transcription-model.ts","file:///home/mercury/Documents/Git%20Projects/Polynote-AI/node_modules/%40ai-sdk/openai/src/transcription/openai-transcription-options.ts"],"sourcesContent":["import {\n  EmbeddingModelV2,\n  ImageModelV2,\n  LanguageModelV2,\n  ProviderV2,\n  SpeechModelV2,\n  TranscriptionModelV2,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  loadApiKey,\n  withoutTrailingSlash,\n} from '@ai-sdk/provider-utils';\nimport { OpenAIChatLanguageModel } from './chat/openai-chat-language-model';\nimport { OpenAIChatModelId } from './chat/openai-chat-options';\nimport { OpenAICompletionLanguageModel } from './completion/openai-completion-language-model';\nimport { OpenAICompletionModelId } from './completion/openai-completion-options';\nimport { OpenAIEmbeddingModel } from './embedding/openai-embedding-model';\nimport { OpenAIEmbeddingModelId } from './embedding/openai-embedding-options';\nimport { OpenAIImageModel } from './image/openai-image-model';\nimport { OpenAIImageModelId } from './image/openai-image-options';\nimport { openaiTools } from './openai-tools';\nimport { OpenAIResponsesLanguageModel } from './responses/openai-responses-language-model';\nimport { OpenAIResponsesModelId } from './responses/openai-responses-settings';\nimport { OpenAISpeechModel } from './speech/openai-speech-model';\nimport { OpenAISpeechModelId } from './speech/openai-speech-options';\nimport { OpenAITranscriptionModel } from './transcription/openai-transcription-model';\nimport { OpenAITranscriptionModelId } from './transcription/openai-transcription-options';\n\nexport interface OpenAIProvider extends ProviderV2 {\n  (modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI model for text generation.\n   */\n  languageModel(modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI chat model for text generation.\n   */\n  chat(modelId: OpenAIChatModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI responses API model for text generation.\n   */\n  responses(modelId: OpenAIResponsesModelId): LanguageModelV2;\n\n  /**\nCreates an OpenAI completion model for text generation.\n   */\n  completion(modelId: OpenAICompletionModelId): LanguageModelV2;\n\n  /**\nCreates a model for text embeddings.\n   */\n  embedding(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for text embeddings.\n   */\n  textEmbedding(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for text embeddings.\n   */\n  textEmbeddingModel(modelId: OpenAIEmbeddingModelId): EmbeddingModelV2<string>;\n\n  /**\nCreates a model for image generation.\n   */\n  image(modelId: OpenAIImageModelId): ImageModelV2;\n\n  /**\nCreates a model for image generation.\n   */\n  imageModel(modelId: OpenAIImageModelId): ImageModelV2;\n\n  /**\nCreates a model for transcription.\n   */\n  transcription(modelId: OpenAITranscriptionModelId): TranscriptionModelV2;\n\n  /**\nCreates a model for speech generation.\n   */\n  speech(modelId: OpenAISpeechModelId): SpeechModelV2;\n\n  /**\nOpenAI-specific tools.\n   */\n  tools: typeof openaiTools;\n}\n\nexport interface OpenAIProviderSettings {\n  /**\nBase URL for the OpenAI API calls.\n     */\n  baseURL?: string;\n\n  /**\nAPI key for authenticating requests.\n     */\n  apiKey?: string;\n\n  /**\nOpenAI Organization.\n     */\n  organization?: string;\n\n  /**\nOpenAI project.\n     */\n  project?: string;\n\n  /**\nCustom headers to include in the requests.\n     */\n  headers?: Record<string, string>;\n\n  /**\nProvider name. Overrides the `openai` default name for 3rd party providers.\n   */\n  name?: string;\n\n  /**\nCustom fetch implementation. You can use it as a middleware to intercept requests,\nor to provide a custom fetch implementation for e.g. testing.\n    */\n  fetch?: FetchFunction;\n}\n\n/**\nCreate an OpenAI provider instance.\n */\nexport function createOpenAI(\n  options: OpenAIProviderSettings = {},\n): OpenAIProvider {\n  const baseURL =\n    withoutTrailingSlash(options.baseURL) ?? 'https://api.openai.com/v1';\n\n  const providerName = options.name ?? 'openai';\n\n  const getHeaders = () => ({\n    Authorization: `Bearer ${loadApiKey({\n      apiKey: options.apiKey,\n      environmentVariableName: 'OPENAI_API_KEY',\n      description: 'OpenAI',\n    })}`,\n    'OpenAI-Organization': options.organization,\n    'OpenAI-Project': options.project,\n    ...options.headers,\n  });\n\n  const createChatModel = (modelId: OpenAIChatModelId) =>\n    new OpenAIChatLanguageModel(modelId, {\n      provider: `${providerName}.chat`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createCompletionModel = (modelId: OpenAICompletionModelId) =>\n    new OpenAICompletionLanguageModel(modelId, {\n      provider: `${providerName}.completion`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createEmbeddingModel = (modelId: OpenAIEmbeddingModelId) =>\n    new OpenAIEmbeddingModel(modelId, {\n      provider: `${providerName}.embedding`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createImageModel = (modelId: OpenAIImageModelId) =>\n    new OpenAIImageModel(modelId, {\n      provider: `${providerName}.image`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createTranscriptionModel = (modelId: OpenAITranscriptionModelId) =>\n    new OpenAITranscriptionModel(modelId, {\n      provider: `${providerName}.transcription`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createSpeechModel = (modelId: OpenAISpeechModelId) =>\n    new OpenAISpeechModel(modelId, {\n      provider: `${providerName}.speech`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n    });\n\n  const createLanguageModel = (modelId: OpenAIResponsesModelId) => {\n    if (new.target) {\n      throw new Error(\n        'The OpenAI model function cannot be called with the new keyword.',\n      );\n    }\n\n    return createResponsesModel(modelId);\n  };\n\n  const createResponsesModel = (modelId: OpenAIResponsesModelId) => {\n    return new OpenAIResponsesLanguageModel(modelId, {\n      provider: `${providerName}.responses`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch,\n      fileIdPrefixes: ['file-'],\n    });\n  };\n\n  const provider = function (modelId: OpenAIResponsesModelId) {\n    return createLanguageModel(modelId);\n  };\n\n  provider.languageModel = createLanguageModel;\n  provider.chat = createChatModel;\n  provider.completion = createCompletionModel;\n  provider.responses = createResponsesModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n\n  provider.image = createImageModel;\n  provider.imageModel = createImageModel;\n\n  provider.transcription = createTranscriptionModel;\n  provider.transcriptionModel = createTranscriptionModel;\n\n  provider.speech = createSpeechModel;\n  provider.speechModel = createSpeechModel;\n\n  provider.tools = openaiTools;\n\n  return provider as OpenAIProvider;\n}\n\n/**\nDefault OpenAI provider instance.\n */\nexport const openai = createOpenAI();\n","import {\n  InvalidResponseDataError,\n  LanguageModelV2,\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  LanguageModelV2Content,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  isParsableJson,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  openaiErrorDataSchema,\n  openaiFailedResponseHandler,\n} from '../openai-error';\nimport { convertToOpenAIChatMessages } from './convert-to-openai-chat-messages';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAIChatModelId,\n  openaiProviderOptions,\n} from './openai-chat-options';\nimport { prepareChatTools } from './openai-chat-prepare-tools';\n\ntype OpenAIChatConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAIChatLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAIChatModelId;\n\n  readonly supportedUrls = {\n    'image/*': [/^https?:\\/\\/.*$/],\n  };\n\n  private readonly config: OpenAIChatConfig;\n\n  constructor(modelId: OpenAIChatModelId, config: OpenAIChatConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    tools,\n    toolChoice,\n    providerOptions,\n  }: LanguageModelV2CallOptions) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiProviderOptions,\n      })) ?? {};\n\n    const structuredOutputs = openaiOptions.structuredOutputs ?? true;\n\n    if (topK != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'topK',\n      });\n    }\n\n    if (\n      responseFormat?.type === 'json' &&\n      responseFormat.schema != null &&\n      !structuredOutputs\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details:\n          'JSON response format schema is only supported with structuredOutputs',\n      });\n    }\n\n    const { messages, warnings: messageWarnings } = convertToOpenAIChatMessages(\n      {\n        prompt,\n        systemMessageMode: getSystemMessageMode(this.modelId),\n      },\n    );\n\n    warnings.push(...messageWarnings);\n\n    const strictJsonSchema = openaiOptions.strictJsonSchema ?? false;\n\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n\n      // model specific settings:\n      logit_bias: openaiOptions.logitBias,\n      logprobs:\n        openaiOptions.logprobs === true ||\n        typeof openaiOptions.logprobs === 'number'\n          ? true\n          : undefined,\n      top_logprobs:\n        typeof openaiOptions.logprobs === 'number'\n          ? openaiOptions.logprobs\n          : typeof openaiOptions.logprobs === 'boolean'\n            ? openaiOptions.logprobs\n              ? 0\n              : undefined\n            : undefined,\n      user: openaiOptions.user,\n      parallel_tool_calls: openaiOptions.parallelToolCalls,\n\n      // standardized settings:\n      max_tokens: maxOutputTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      response_format:\n        responseFormat?.type === 'json'\n          ? structuredOutputs && responseFormat.schema != null\n            ? {\n                type: 'json_schema',\n                json_schema: {\n                  schema: responseFormat.schema,\n                  strict: strictJsonSchema,\n                  name: responseFormat.name ?? 'response',\n                  description: responseFormat.description,\n                },\n              }\n            : { type: 'json_object' }\n          : undefined,\n      stop: stopSequences,\n      seed,\n      verbosity: openaiOptions.textVerbosity,\n\n      // openai specific settings:\n      // TODO AI SDK 6: remove, we auto-map maxOutputTokens now\n      max_completion_tokens: openaiOptions.maxCompletionTokens,\n      store: openaiOptions.store,\n      metadata: openaiOptions.metadata,\n      prediction: openaiOptions.prediction,\n      reasoning_effort: openaiOptions.reasoningEffort,\n      service_tier: openaiOptions.serviceTier,\n      prompt_cache_key: openaiOptions.promptCacheKey,\n      safety_identifier: openaiOptions.safetyIdentifier,\n\n      // messages:\n      messages,\n    };\n\n    if (isReasoningModel(this.modelId)) {\n      // remove unsupported settings for reasoning models\n      // see https://platform.openai.com/docs/guides/reasoning#limitations\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details: 'temperature is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'topP',\n          details: 'topP is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.frequency_penalty != null) {\n        baseArgs.frequency_penalty = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'frequencyPenalty',\n          details: 'frequencyPenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.presence_penalty != null) {\n        baseArgs.presence_penalty = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'presencePenalty',\n          details: 'presencePenalty is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.logit_bias != null) {\n        baseArgs.logit_bias = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'logitBias is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.logprobs != null) {\n        baseArgs.logprobs = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'logprobs is not supported for reasoning models',\n        });\n      }\n      if (baseArgs.top_logprobs != null) {\n        baseArgs.top_logprobs = undefined;\n        warnings.push({\n          type: 'other',\n          message: 'topLogprobs is not supported for reasoning models',\n        });\n      }\n\n      // reasoning models use max_completion_tokens instead of max_tokens:\n      if (baseArgs.max_tokens != null) {\n        if (baseArgs.max_completion_tokens == null) {\n          baseArgs.max_completion_tokens = baseArgs.max_tokens;\n        }\n        baseArgs.max_tokens = undefined;\n      }\n    } else if (\n      this.modelId.startsWith('gpt-4o-search-preview') ||\n      this.modelId.startsWith('gpt-4o-mini-search-preview')\n    ) {\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details:\n            'temperature is not supported for the search preview models and has been removed.',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions.serviceTier === 'flex' &&\n      !supportsFlexProcessing(this.modelId)\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions.serviceTier === 'priority' &&\n      !supportsPriorityProcessing(this.modelId)\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      baseArgs.service_tier = undefined;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = prepareChatTools({\n      tools,\n      toolChoice,\n      structuredOutputs,\n      strictJsonSchema,\n    });\n\n    return {\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args: body, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiChatResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n    const content: Array<LanguageModelV2Content> = [];\n\n    // text content:\n    const text = choice.message.content;\n    if (text != null && text.length > 0) {\n      content.push({ type: 'text', text });\n    }\n\n    // tool calls:\n    for (const toolCall of choice.message.tool_calls ?? []) {\n      content.push({\n        type: 'tool-call' as const,\n        toolCallId: toolCall.id ?? generateId(),\n        toolName: toolCall.function.name,\n        input: toolCall.function.arguments!,\n      });\n    }\n\n    // annotations/citations:\n    for (const annotation of choice.message.annotations ?? []) {\n      content.push({\n        type: 'source',\n        sourceType: 'url',\n        id: generateId(),\n        url: annotation.url,\n        title: annotation.title,\n      });\n    }\n\n    // provider metadata:\n    const completionTokenDetails = response.usage?.completion_tokens_details;\n    const promptTokenDetails = response.usage?.prompt_tokens_details;\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n    if (completionTokenDetails?.accepted_prediction_tokens != null) {\n      providerMetadata.openai.acceptedPredictionTokens =\n        completionTokenDetails?.accepted_prediction_tokens;\n    }\n    if (completionTokenDetails?.rejected_prediction_tokens != null) {\n      providerMetadata.openai.rejectedPredictionTokens =\n        completionTokenDetails?.rejected_prediction_tokens;\n    }\n    if (choice.logprobs?.content != null) {\n      providerMetadata.openai.logprobs = choice.logprobs.content;\n    }\n\n    return {\n      content,\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      usage: {\n        inputTokens: response.usage?.prompt_tokens ?? undefined,\n        outputTokens: response.usage?.completion_tokens ?? undefined,\n        totalTokens: response.usage?.total_tokens ?? undefined,\n        reasoningTokens: completionTokenDetails?.reasoning_tokens ?? undefined,\n        cachedInputTokens: promptTokenDetails?.cached_tokens ?? undefined,\n      },\n      request: { body },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      warnings,\n      providerMetadata,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/chat/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiChatChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const toolCalls: Array<{\n      id: string;\n      type: 'function';\n      function: {\n        name: string;\n        arguments: string;\n      };\n      hasFinished: boolean;\n    }> = [];\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    let isFirstChunk = true;\n    let isActiveText = false;\n\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof openaiChatChunkSchema>>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n            }\n\n            if (value.usage != null) {\n              usage.inputTokens = value.usage.prompt_tokens ?? undefined;\n              usage.outputTokens = value.usage.completion_tokens ?? undefined;\n              usage.totalTokens = value.usage.total_tokens ?? undefined;\n              usage.reasoningTokens =\n                value.usage.completion_tokens_details?.reasoning_tokens ??\n                undefined;\n              usage.cachedInputTokens =\n                value.usage.prompt_tokens_details?.cached_tokens ?? undefined;\n\n              if (\n                value.usage.completion_tokens_details\n                  ?.accepted_prediction_tokens != null\n              ) {\n                providerMetadata.openai.acceptedPredictionTokens =\n                  value.usage.completion_tokens_details?.accepted_prediction_tokens;\n              }\n              if (\n                value.usage.completion_tokens_details\n                  ?.rejected_prediction_tokens != null\n              ) {\n                providerMetadata.openai.rejectedPredictionTokens =\n                  value.usage.completion_tokens_details?.rejected_prediction_tokens;\n              }\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.logprobs?.content != null) {\n              providerMetadata.openai.logprobs = choice.logprobs.content;\n            }\n\n            if (choice?.delta == null) {\n              return;\n            }\n\n            const delta = choice.delta;\n\n            if (delta.content != null) {\n              if (!isActiveText) {\n                controller.enqueue({ type: 'text-start', id: '0' });\n                isActiveText = true;\n              }\n\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: delta.content,\n              });\n            }\n\n            if (delta.tool_calls != null) {\n              for (const toolCallDelta of delta.tool_calls) {\n                const index = toolCallDelta.index;\n\n                // Tool call start. OpenAI returns all information except the arguments in the first chunk.\n                if (toolCalls[index] == null) {\n                  if (toolCallDelta.type !== 'function') {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function' type.`,\n                    });\n                  }\n\n                  if (toolCallDelta.id == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'id' to be a string.`,\n                    });\n                  }\n\n                  if (toolCallDelta.function?.name == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function.name' to be a string.`,\n                    });\n                  }\n\n                  controller.enqueue({\n                    type: 'tool-input-start',\n                    id: toolCallDelta.id,\n                    toolName: toolCallDelta.function.name,\n                  });\n\n                  toolCalls[index] = {\n                    id: toolCallDelta.id,\n                    type: 'function',\n                    function: {\n                      name: toolCallDelta.function.name,\n                      arguments: toolCallDelta.function.arguments ?? '',\n                    },\n                    hasFinished: false,\n                  };\n\n                  const toolCall = toolCalls[index];\n\n                  if (\n                    toolCall.function?.name != null &&\n                    toolCall.function?.arguments != null\n                  ) {\n                    // send delta if the argument text has already started:\n                    if (toolCall.function.arguments.length > 0) {\n                      controller.enqueue({\n                        type: 'tool-input-delta',\n                        id: toolCall.id,\n                        delta: toolCall.function.arguments,\n                      });\n                    }\n\n                    // check if tool call is complete\n                    // (some providers send the full tool call in one chunk):\n                    if (isParsableJson(toolCall.function.arguments)) {\n                      controller.enqueue({\n                        type: 'tool-input-end',\n                        id: toolCall.id,\n                      });\n\n                      controller.enqueue({\n                        type: 'tool-call',\n                        toolCallId: toolCall.id ?? generateId(),\n                        toolName: toolCall.function.name,\n                        input: toolCall.function.arguments,\n                      });\n                      toolCall.hasFinished = true;\n                    }\n                  }\n\n                  continue;\n                }\n\n                // existing tool call, merge if not finished\n                const toolCall = toolCalls[index];\n\n                if (toolCall.hasFinished) {\n                  continue;\n                }\n\n                if (toolCallDelta.function?.arguments != null) {\n                  toolCall.function!.arguments +=\n                    toolCallDelta.function?.arguments ?? '';\n                }\n\n                // send delta\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.id,\n                  delta: toolCallDelta.function.arguments ?? '',\n                });\n\n                // check if tool call is complete\n                if (\n                  toolCall.function?.name != null &&\n                  toolCall.function?.arguments != null &&\n                  isParsableJson(toolCall.function.arguments)\n                ) {\n                  controller.enqueue({\n                    type: 'tool-input-end',\n                    id: toolCall.id,\n                  });\n\n                  controller.enqueue({\n                    type: 'tool-call',\n                    toolCallId: toolCall.id ?? generateId(),\n                    toolName: toolCall.function.name,\n                    input: toolCall.function.arguments,\n                  });\n                  toolCall.hasFinished = true;\n                }\n              }\n            }\n\n            // annotations/citations:\n            if (delta.annotations != null) {\n              for (const annotation of delta.annotations) {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: generateId(),\n                  url: annotation.url,\n                  title: annotation.title,\n                });\n              }\n            }\n          },\n\n          flush(controller) {\n            if (isActiveText) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n              ...(providerMetadata != null ? { providerMetadata } : {}),\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nconst openaiTokenUsageSchema = z\n  .object({\n    prompt_tokens: z.number().nullish(),\n    completion_tokens: z.number().nullish(),\n    total_tokens: z.number().nullish(),\n    prompt_tokens_details: z\n      .object({\n        cached_tokens: z.number().nullish(),\n      })\n      .nullish(),\n    completion_tokens_details: z\n      .object({\n        reasoning_tokens: z.number().nullish(),\n        accepted_prediction_tokens: z.number().nullish(),\n        rejected_prediction_tokens: z.number().nullish(),\n      })\n      .nullish(),\n  })\n  .nullish();\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiChatResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      message: z.object({\n        role: z.literal('assistant').nullish(),\n        content: z.string().nullish(),\n        tool_calls: z\n          .array(\n            z.object({\n              id: z.string().nullish(),\n              type: z.literal('function'),\n              function: z.object({\n                name: z.string(),\n                arguments: z.string(),\n              }),\n            }),\n          )\n          .nullish(),\n        annotations: z\n          .array(\n            z.object({\n              type: z.literal('url_citation'),\n              start_index: z.number(),\n              end_index: z.number(),\n              url: z.string(),\n              title: z.string(),\n            }),\n          )\n          .nullish(),\n      }),\n      index: z.number(),\n      logprobs: z\n        .object({\n          content: z\n            .array(\n              z.object({\n                token: z.string(),\n                logprob: z.number(),\n                top_logprobs: z.array(\n                  z.object({\n                    token: z.string(),\n                    logprob: z.number(),\n                  }),\n                ),\n              }),\n            )\n            .nullish(),\n        })\n        .nullish(),\n      finish_reason: z.string().nullish(),\n    }),\n  ),\n  usage: openaiTokenUsageSchema,\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiChatChunkSchema = z.union([\n  z.object({\n    id: z.string().nullish(),\n    created: z.number().nullish(),\n    model: z.string().nullish(),\n    choices: z.array(\n      z.object({\n        delta: z\n          .object({\n            role: z.enum(['assistant']).nullish(),\n            content: z.string().nullish(),\n            tool_calls: z\n              .array(\n                z.object({\n                  index: z.number(),\n                  id: z.string().nullish(),\n                  type: z.literal('function').nullish(),\n                  function: z.object({\n                    name: z.string().nullish(),\n                    arguments: z.string().nullish(),\n                  }),\n                }),\n              )\n              .nullish(),\n            annotations: z\n              .array(\n                z.object({\n                  type: z.literal('url_citation'),\n                  start_index: z.number(),\n                  end_index: z.number(),\n                  url: z.string(),\n                  title: z.string(),\n                }),\n              )\n              .nullish(),\n          })\n          .nullish(),\n        logprobs: z\n          .object({\n            content: z\n              .array(\n                z.object({\n                  token: z.string(),\n                  logprob: z.number(),\n                  top_logprobs: z.array(\n                    z.object({\n                      token: z.string(),\n                      logprob: z.number(),\n                    }),\n                  ),\n                }),\n              )\n              .nullish(),\n          })\n          .nullish(),\n        finish_reason: z.string().nullish(),\n        index: z.number(),\n      }),\n    ),\n    usage: openaiTokenUsageSchema,\n  }),\n  openaiErrorDataSchema,\n]);\n\nfunction isReasoningModel(modelId: string) {\n  return (\n    (modelId.startsWith('o') || modelId.startsWith('gpt-5')) &&\n    !modelId.startsWith('gpt-5-chat')\n  );\n}\n\nfunction supportsFlexProcessing(modelId: string) {\n  return (\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'))\n  );\n}\n\nfunction supportsPriorityProcessing(modelId: string) {\n  return (\n    modelId.startsWith('gpt-4') ||\n    modelId.startsWith('gpt-5-mini') ||\n    (modelId.startsWith('gpt-5') &&\n      !modelId.startsWith('gpt-5-nano') &&\n      !modelId.startsWith('gpt-5-chat')) ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini')\n  );\n}\n\nfunction getSystemMessageMode(modelId: string) {\n  if (!isReasoningModel(modelId)) {\n    return 'system';\n  }\n\n  return (\n    reasoningModels[modelId as keyof typeof reasoningModels]\n      ?.systemMessageMode ?? 'developer'\n  );\n}\n\nconst reasoningModels = {\n  'o1-mini': {\n    systemMessageMode: 'remove',\n  },\n  'o1-mini-2024-09-12': {\n    systemMessageMode: 'remove',\n  },\n  'o1-preview': {\n    systemMessageMode: 'remove',\n  },\n  'o1-preview-2024-09-12': {\n    systemMessageMode: 'remove',\n  },\n  o3: {\n    systemMessageMode: 'developer',\n  },\n  'o3-2025-04-16': {\n    systemMessageMode: 'developer',\n  },\n  'o3-mini': {\n    systemMessageMode: 'developer',\n  },\n  'o3-mini-2025-01-31': {\n    systemMessageMode: 'developer',\n  },\n  'o4-mini': {\n    systemMessageMode: 'developer',\n  },\n  'o4-mini-2025-04-16': {\n    systemMessageMode: 'developer',\n  },\n} as const;\n","import { z } from 'zod/v4';\nimport { createJsonErrorResponseHandler } from '@ai-sdk/provider-utils';\n\nexport const openaiErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish(),\n  }),\n});\n\nexport type OpenAIErrorData = z.infer<typeof openaiErrorDataSchema>;\n\nexport const openaiFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: openaiErrorDataSchema,\n  errorToMessage: data => data.error.message,\n});\n","import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { OpenAIChatPrompt } from './openai-chat-prompt';\nimport { convertToBase64 } from '@ai-sdk/provider-utils';\n\nexport function convertToOpenAIChatMessages({\n  prompt,\n  systemMessageMode = 'system',\n}: {\n  prompt: LanguageModelV2Prompt;\n  systemMessageMode?: 'system' | 'developer' | 'remove';\n}): {\n  messages: OpenAIChatPrompt;\n  warnings: Array<LanguageModelV2CallWarning>;\n} {\n  const messages: OpenAIChatPrompt = [];\n  const warnings: Array<LanguageModelV2CallWarning> = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            messages.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            messages.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        if (content.length === 1 && content[0].type === 'text') {\n          messages.push({ role: 'user', content: content[0].text });\n          break;\n        }\n\n        messages.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'image_url',\n                    image_url: {\n                      url:\n                        part.data instanceof URL\n                          ? part.data.toString()\n                          : `data:${mediaType};base64,${convertToBase64(part.data)}`,\n\n                      // OpenAI specific extension: image detail\n                      detail: part.providerOptions?.openai?.imageDetail,\n                    },\n                  };\n                } else if (part.mediaType.startsWith('audio/')) {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'audio file parts with URLs',\n                    });\n                  }\n\n                  switch (part.mediaType) {\n                    case 'audio/wav': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'wav',\n                        },\n                      };\n                    }\n                    case 'audio/mp3':\n                    case 'audio/mpeg': {\n                      return {\n                        type: 'input_audio',\n                        input_audio: {\n                          data: convertToBase64(part.data),\n                          format: 'mp3',\n                        },\n                      };\n                    }\n\n                    default: {\n                      throw new UnsupportedFunctionalityError({\n                        functionality: `audio content parts with media type ${part.mediaType}`,\n                      });\n                    }\n                  }\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: 'PDF file parts with URLs',\n                    });\n                  }\n\n                  return {\n                    type: 'file',\n                    file:\n                      typeof part.data === 'string' &&\n                      part.data.startsWith('file-')\n                        ? { file_id: part.data }\n                        : {\n                            filename: part.filename ?? `part-${index}.pdf`,\n                            file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                          },\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        let text = '';\n        const toolCalls: Array<{\n          id: string;\n          type: 'function';\n          function: { name: string; arguments: string };\n        }> = [];\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              text += part.text;\n              break;\n            }\n            case 'tool-call': {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: 'function',\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.input),\n                },\n              });\n              break;\n            }\n          }\n        }\n\n        messages.push({\n          role: 'assistant',\n          content: text,\n          tool_calls: toolCalls.length > 0 ? toolCalls : undefined,\n        });\n\n        break;\n      }\n\n      case 'tool': {\n        for (const toolResponse of content) {\n          const output = toolResponse.output;\n\n          let contentValue: string;\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'content':\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n          }\n\n          messages.push({\n            role: 'tool',\n            tool_call_id: toolResponse.toolCallId,\n            content: contentValue,\n          });\n        }\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { messages, warnings };\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n","import { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAIChatModelId =\n  | 'o1'\n  | 'o1-2024-12-17'\n  | 'o3-mini'\n  | 'o3-mini-2025-01-31'\n  | 'o3'\n  | 'o3-2025-04-16'\n  | 'gpt-4.1'\n  | 'gpt-4.1-2025-04-14'\n  | 'gpt-4.1-mini'\n  | 'gpt-4.1-mini-2025-04-14'\n  | 'gpt-4.1-nano'\n  | 'gpt-4.1-nano-2025-04-14'\n  | 'gpt-4o'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-11-20'\n  | 'gpt-4o-mini'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4-turbo'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4'\n  | 'gpt-4-0613'\n  | 'gpt-4.5-preview'\n  | 'gpt-4.5-preview-2025-02-27'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo'\n  | 'gpt-3.5-turbo-1106'\n  | 'chatgpt-4o-latest'\n  | 'gpt-5'\n  | 'gpt-5-2025-08-07'\n  | 'gpt-5-mini'\n  | 'gpt-5-mini-2025-08-07'\n  | 'gpt-5-nano'\n  | 'gpt-5-nano-2025-08-07'\n  | 'gpt-5-chat-latest'\n  | (string & {});\n\nexport const openaiProviderOptions = z.object({\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in\n   * the GPT tokenizer) to an associated bias value from -100 to 100.\n   */\n  logitBias: z.record(z.coerce.number<string>(), z.number()).optional(),\n\n  /**\n   * Return the log probabilities of the tokens.\n   *\n   * Setting to true will return the log probabilities of the tokens that\n   * were generated.\n   *\n   * Setting to a number will return the log probabilities of the top n\n   * tokens that were generated.\n   */\n  logprobs: z.union([z.boolean(), z.number()]).optional(),\n\n  /**\n   * Whether to enable parallel function calling during tool use. Default to true.\n   */\n  parallelToolCalls: z.boolean().optional(),\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to\n   * monitor and detect abuse.\n   */\n  user: z.string().optional(),\n\n  /**\n   * Reasoning effort for reasoning models. Defaults to `medium`.\n   */\n  reasoningEffort: z.enum(['minimal', 'low', 'medium', 'high']).optional(),\n\n  /**\n   * Maximum number of completion tokens to generate. Useful for reasoning models.\n   */\n  maxCompletionTokens: z.number().optional(),\n\n  /**\n   * Whether to enable persistence in responses API.\n   */\n  store: z.boolean().optional(),\n\n  /**\n   * Metadata to associate with the request.\n   */\n  metadata: z.record(z.string().max(64), z.string().max(512)).optional(),\n\n  /**\n   * Parameters for prediction mode.\n   */\n  prediction: z.record(z.string(), z.any()).optional(),\n\n  /**\n   * Whether to use structured outputs.\n   *\n   * @default true\n   */\n  structuredOutputs: z.boolean().optional(),\n\n  /**\n   * Service tier for the request.\n   * - 'auto': Default service tier\n   * - 'flex': 50% cheaper processing at the cost of increased latency. Only available for o3 and o4-mini models.\n   * - 'priority': Higher-speed processing with predictably low latency at premium cost. Available for Enterprise customers.\n   *\n   * @default 'auto'\n   */\n  serviceTier: z.enum(['auto', 'flex', 'priority']).optional(),\n\n  /**\n   * Whether to use strict JSON schema validation.\n   *\n   * @default false\n   */\n  strictJsonSchema: z.boolean().optional(),\n\n  /**\n   * Controls the verbosity of the model's responses.\n   * Lower values will result in more concise responses, while higher values will result in more verbose responses.\n   */\n  textVerbosity: z.enum(['low', 'medium', 'high']).optional(),\n\n  /**\n   * A cache key for prompt caching. Allows manual control over prompt caching behavior.\n   * Useful for improving cache hit rates and working around automatic caching issues.\n   */\n  promptCacheKey: z.string().optional(),\n\n  /**\n   * A stable identifier used to help detect users of your application\n   * that may be violating OpenAI's usage policies. The IDs should be a\n   * string that uniquely identifies each user. We recommend hashing their\n   * username or email address, in order to avoid sending us any identifying\n   * information.\n   */\n  safetyIdentifier: z.string().optional(),\n});\n\nexport type OpenAIProviderOptions = z.infer<typeof openaiProviderOptions>;\n","import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { fileSearchArgsSchema } from '../tool/file-search';\nimport { webSearchPreviewArgsSchema } from '../tool/web-search-preview';\nimport { OpenAIChatToolChoice, OpenAIChatTools } from './openai-chat-types';\n\nexport function prepareChatTools({\n  tools,\n  toolChoice,\n  structuredOutputs,\n  strictJsonSchema,\n}: {\n  tools: LanguageModelV2CallOptions['tools'];\n  toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n  structuredOutputs: boolean;\n  strictJsonSchema: boolean;\n}): {\n  tools?: OpenAIChatTools;\n  toolChoice?: OpenAIChatToolChoice;\n  toolWarnings: Array<LanguageModelV2CallWarning>;\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: LanguageModelV2CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: OpenAIChatTools = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          function: {\n            name: tool.name,\n            description: tool.description,\n            parameters: tool.inputSchema,\n            strict: structuredOutputs ? strictJsonSchema : undefined,\n          },\n        });\n        break;\n      case 'provider-defined':\n        switch (tool.id) {\n          case 'openai.file_search': {\n            const args = fileSearchArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'file_search',\n              vector_store_ids: args.vectorStoreIds,\n              max_num_results: args.maxNumResults,\n              ranking_options: args.ranking\n                ? { ranker: args.ranking.ranker }\n                : undefined,\n              filters: args.filters,\n            });\n            break;\n          }\n          case 'openai.web_search_preview': {\n            const args = webSearchPreviewArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'web_search_preview',\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          default:\n            toolWarnings.push({ type: 'unsupported-tool', tool });\n            break;\n        }\n        break;\n      default:\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice: {\n          type: 'function',\n          function: {\n            name: toolChoice.toolName,\n          },\n        },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import { createProviderDefinedToolFactory } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// Filter schemas\nconst comparisonFilterSchema = z.object({\n  key: z.string(),\n  type: z.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']),\n  value: z.union([z.string(), z.number(), z.boolean()]),\n});\n\nconst compoundFilterSchema: z.ZodType<any> = z.object({\n  type: z.enum(['and', 'or']),\n  filters: z.array(\n    z.union([comparisonFilterSchema, z.lazy(() => compoundFilterSchema)]),\n  ),\n});\n\nconst filtersSchema = z.union([comparisonFilterSchema, compoundFilterSchema]);\n\n// Args validation schema\nexport const fileSearchArgsSchema = z.object({\n  /**\n   * List of vector store IDs to search through. If not provided, searches all available vector stores.\n   */\n  vectorStoreIds: z.array(z.string()).optional(),\n\n  /**\n   * Maximum number of search results to return. Defaults to 10.\n   */\n  maxNumResults: z.number().optional(),\n\n  /**\n   * Ranking options for the search.\n   */\n  ranking: z\n    .object({\n      ranker: z.enum(['auto', 'default-2024-08-21']).optional(),\n    })\n    .optional(),\n\n  /**\n   * A filter to apply based on file attributes.\n   */\n  filters: filtersSchema.optional(),\n});\n\nexport const fileSearch = createProviderDefinedToolFactory<\n  {\n    /**\n     * The search query to execute.\n     */\n    query: string;\n  },\n  {\n    /**\n     * List of vector store IDs to search through. If not provided, searches all available vector stores.\n     */\n    vectorStoreIds?: string[];\n\n    /**\n     * Maximum number of search results to return. Defaults to 10.\n     */\n    maxNumResults?: number;\n\n    /**\n     * Ranking options for the search.\n     */\n    ranking?: {\n      ranker?: 'auto' | 'default-2024-08-21';\n    };\n\n    /**\n     * A filter to apply based on file attributes.\n     */\n    filters?:\n      | {\n          key: string;\n          type: 'eq' | 'ne' | 'gt' | 'gte' | 'lt' | 'lte';\n          value: string | number | boolean;\n        }\n      | {\n          type: 'and' | 'or';\n          filters: any[];\n        };\n  }\n>({\n  id: 'openai.file_search',\n  name: 'file_search',\n  inputSchema: z.object({\n    query: z.string(),\n  }),\n});\n","import { createProviderDefinedToolFactory } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\n// Args validation schema\nexport const webSearchPreviewArgsSchema = z.object({\n  /**\n   * Search context size to use for the web search.\n   * - high: Most comprehensive context, highest cost, slower response\n   * - medium: Balanced context, cost, and latency (default)\n   * - low: Least context, lowest cost, fastest response\n   */\n  searchContextSize: z.enum(['low', 'medium', 'high']).optional(),\n\n  /**\n   * User location information to provide geographically relevant search results.\n   */\n  userLocation: z\n    .object({\n      /**\n       * Type of location (always 'approximate')\n       */\n      type: z.literal('approximate'),\n      /**\n       * Two-letter ISO country code (e.g., 'US', 'GB')\n       */\n      country: z.string().optional(),\n      /**\n       * City name (free text, e.g., 'Minneapolis')\n       */\n      city: z.string().optional(),\n      /**\n       * Region name (free text, e.g., 'Minnesota')\n       */\n      region: z.string().optional(),\n      /**\n       * IANA timezone (e.g., 'America/Chicago')\n       */\n      timezone: z.string().optional(),\n    })\n    .optional(),\n});\n\nexport const webSearchPreview = createProviderDefinedToolFactory<\n  {\n    // Web search doesn't take input parameters - it's controlled by the prompt\n  },\n  {\n    /**\n     * Search context size to use for the web search.\n     * - high: Most comprehensive context, highest cost, slower response\n     * - medium: Balanced context, cost, and latency (default)\n     * - low: Least context, lowest cost, fastest response\n     */\n    searchContextSize?: 'low' | 'medium' | 'high';\n\n    /**\n     * User location information to provide geographically relevant search results.\n     */\n    userLocation?: {\n      /**\n       * Type of location (always 'approximate')\n       */\n      type: 'approximate';\n      /**\n       * Two-letter ISO country code (e.g., 'US', 'GB')\n       */\n      country?: string;\n      /**\n       * City name (free text, e.g., 'Minneapolis')\n       */\n      city?: string;\n      /**\n       * Region name (free text, e.g., 'Minnesota')\n       */\n      region?: string;\n      /**\n       * IANA timezone (e.g., 'America/Chicago')\n       */\n      timezone?: string;\n    };\n  }\n>({\n  id: 'openai.web_search_preview',\n  name: 'web_search_preview',\n  inputSchema: z.object({\n    action: z\n      .discriminatedUnion('type', [\n        z.object({\n          type: z.literal('search'),\n          query: z.string().nullish(),\n        }),\n        z.object({\n          type: z.literal('open_page'),\n          url: z.string(),\n        }),\n        z.object({\n          type: z.literal('find'),\n          url: z.string(),\n          pattern: z.string(),\n        }),\n      ])\n      .nullish(),\n  }),\n});\n","import {\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  FetchFunction,\n  ParseResult,\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  openaiErrorDataSchema,\n  openaiFailedResponseHandler,\n} from '../openai-error';\nimport { convertToOpenAICompletionPrompt } from './convert-to-openai-completion-prompt';\nimport { getResponseMetadata } from './get-response-metadata';\nimport { mapOpenAIFinishReason } from './map-openai-finish-reason';\nimport {\n  OpenAICompletionModelId,\n  openaiCompletionProviderOptions,\n} from './openai-completion-options';\n\ntype OpenAICompletionConfig = {\n  provider: string;\n  headers: () => Record<string, string | undefined>;\n  url: (options: { modelId: string; path: string }) => string;\n  fetch?: FetchFunction;\n};\n\nexport class OpenAICompletionLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAICompletionModelId;\n\n  private readonly config: OpenAICompletionConfig;\n\n  private get providerOptionsName(): string {\n    return this.config.provider.split('.')[0].trim();\n  }\n\n  constructor(\n    modelId: OpenAICompletionModelId,\n    config: OpenAICompletionConfig,\n  ) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    // No URLs are supported for completion models.\n  };\n\n  private async getArgs({\n    prompt,\n    maxOutputTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    tools,\n    toolChoice,\n    seed,\n    providerOptions,\n  }: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openaiOptions = {\n      ...(await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n      ...(await parseProviderOptions({\n        provider: this.providerOptionsName,\n        providerOptions,\n        schema: openaiCompletionProviderOptions,\n      })),\n    };\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'topK' });\n    }\n\n    if (tools?.length) {\n      warnings.push({ type: 'unsupported-setting', setting: 'tools' });\n    }\n\n    if (toolChoice != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'toolChoice' });\n    }\n\n    if (responseFormat != null && responseFormat.type !== 'text') {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'responseFormat',\n        details: 'JSON response format is not supported.',\n      });\n    }\n\n    const { prompt: completionPrompt, stopSequences } =\n      convertToOpenAICompletionPrompt({ prompt });\n\n    const stop = [...(stopSequences ?? []), ...(userStopSequences ?? [])];\n\n    return {\n      args: {\n        // model id:\n        model: this.modelId,\n\n        // model specific settings:\n        echo: openaiOptions.echo,\n        logit_bias: openaiOptions.logitBias,\n        logprobs:\n          openaiOptions?.logprobs === true\n            ? 0\n            : openaiOptions?.logprobs === false\n              ? undefined\n              : openaiOptions?.logprobs,\n        suffix: openaiOptions.suffix,\n        user: openaiOptions.user,\n\n        // standardized settings:\n        max_tokens: maxOutputTokens,\n        temperature,\n        top_p: topP,\n        frequency_penalty: frequencyPenalty,\n        presence_penalty: presencePenalty,\n        seed,\n\n        // prompt:\n        prompt: completionPrompt,\n\n        // stop sequences:\n        stop: stop.length > 0 ? stop : undefined,\n      },\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiCompletionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const choice = response.choices[0];\n\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n\n    if (choice.logprobs != null) {\n      providerMetadata.openai.logprobs = choice.logprobs;\n    }\n\n    return {\n      content: [{ type: 'text', text: choice.text }],\n      usage: {\n        inputTokens: response.usage?.prompt_tokens,\n        outputTokens: response.usage?.completion_tokens,\n        totalTokens: response.usage?.total_tokens,\n      },\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      request: { body: args },\n      response: {\n        ...getResponseMetadata(response),\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args, warnings } = await this.getArgs(options);\n\n    const body = {\n      ...args,\n      stream: true,\n\n      stream_options: {\n        include_usage: true,\n      },\n    };\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/completions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiCompletionChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const providerMetadata: SharedV2ProviderMetadata = { openai: {} };\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    let isFirstChunk = true;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof openaiCompletionChunkSchema>>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            // handle error chunks:\n            if ('error' in value) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: value.error });\n              return;\n            }\n\n            if (isFirstChunk) {\n              isFirstChunk = false;\n\n              controller.enqueue({\n                type: 'response-metadata',\n                ...getResponseMetadata(value),\n              });\n\n              controller.enqueue({ type: 'text-start', id: '0' });\n            }\n\n            if (value.usage != null) {\n              usage.inputTokens = value.usage.prompt_tokens;\n              usage.outputTokens = value.usage.completion_tokens;\n              usage.totalTokens = value.usage.total_tokens;\n            }\n\n            const choice = value.choices[0];\n\n            if (choice?.finish_reason != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n\n            if (choice?.logprobs != null) {\n              providerMetadata.openai.logprobs = choice.logprobs;\n            }\n\n            if (choice?.text != null && choice.text.length > 0) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: '0',\n                delta: choice.text,\n              });\n            }\n          },\n\n          flush(controller) {\n            if (!isFirstChunk) {\n              controller.enqueue({ type: 'text-end', id: '0' });\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              providerMetadata,\n              usage,\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nconst usageSchema = z.object({\n  prompt_tokens: z.number(),\n  completion_tokens: z.number(),\n  total_tokens: z.number(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompletionResponseSchema = z.object({\n  id: z.string().nullish(),\n  created: z.number().nullish(),\n  model: z.string().nullish(),\n  choices: z.array(\n    z.object({\n      text: z.string(),\n      finish_reason: z.string(),\n      logprobs: z\n        .object({\n          tokens: z.array(z.string()),\n          token_logprobs: z.array(z.number()),\n          top_logprobs: z.array(z.record(z.string(), z.number())).nullish(),\n        })\n        .nullish(),\n    }),\n  ),\n  usage: usageSchema.nullish(),\n});\n\n// limited version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiCompletionChunkSchema = z.union([\n  z.object({\n    id: z.string().nullish(),\n    created: z.number().nullish(),\n    model: z.string().nullish(),\n    choices: z.array(\n      z.object({\n        text: z.string(),\n        finish_reason: z.string().nullish(),\n        index: z.number(),\n        logprobs: z\n          .object({\n            tokens: z.array(z.string()),\n            token_logprobs: z.array(z.number()),\n            top_logprobs: z.array(z.record(z.string(), z.number())).nullish(),\n          })\n          .nullish(),\n      }),\n    ),\n    usage: usageSchema.nullish(),\n  }),\n  openaiErrorDataSchema,\n]);\n","import {\n  InvalidPromptError,\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\n\nexport function convertToOpenAICompletionPrompt({\n  prompt,\n  user = 'user',\n  assistant = 'assistant',\n}: {\n  prompt: LanguageModelV2Prompt;\n  user?: string;\n  assistant?: string;\n}): {\n  prompt: string;\n  stopSequences?: string[];\n} {\n  // transform to a chat message format:\n  let text = '';\n\n  // if first message is a system message, add it to the text:\n  if (prompt[0].role === 'system') {\n    text += `${prompt[0].content}\\n\\n`;\n    prompt = prompt.slice(1);\n  }\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        throw new InvalidPromptError({\n          message: 'Unexpected system message in prompt: ${content}',\n          prompt,\n        });\n      }\n\n      case 'user': {\n        const userMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n            }\n          })\n          .filter(Boolean)\n          .join('');\n\n        text += `${user}:\\n${userMessage}\\n\\n`;\n        break;\n      }\n\n      case 'assistant': {\n        const assistantMessage = content\n          .map(part => {\n            switch (part.type) {\n              case 'text': {\n                return part.text;\n              }\n              case 'tool-call': {\n                throw new UnsupportedFunctionalityError({\n                  functionality: 'tool-call messages',\n                });\n              }\n            }\n          })\n          .join('');\n\n        text += `${assistant}:\\n${assistantMessage}\\n\\n`;\n        break;\n      }\n\n      case 'tool': {\n        throw new UnsupportedFunctionalityError({\n          functionality: 'tool messages',\n        });\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  // Assistant message prefix:\n  text += `${assistant}:\\n`;\n\n  return {\n    prompt: text,\n    stopSequences: [`\\n${user}:`],\n  };\n}\n","export function getResponseMetadata({\n  id,\n  model,\n  created,\n}: {\n  id?: string | undefined | null;\n  created?: number | undefined | null;\n  model?: string | undefined | null;\n}) {\n  return {\n    id: id ?? undefined,\n    modelId: model ?? undefined,\n    timestamp: created != null ? new Date(created * 1000) : undefined,\n  };\n}\n","import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIFinishReason(\n  finishReason: string | null | undefined,\n): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case 'stop':\n      return 'stop';\n    case 'length':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    case 'function_call':\n    case 'tool_calls':\n      return 'tool-calls';\n    default:\n      return 'unknown';\n  }\n}\n","import { z } from 'zod/v4';\n\n// https://platform.openai.com/docs/models\nexport type OpenAICompletionModelId = 'gpt-3.5-turbo-instruct' | (string & {});\n\nexport const openaiCompletionProviderOptions = z.object({\n  /**\nEcho back the prompt in addition to the completion.\n   */\n  echo: z.boolean().optional(),\n\n  /**\nModify the likelihood of specified tokens appearing in the completion.\n\nAccepts a JSON object that maps tokens (specified by their token ID in\nthe GPT tokenizer) to an associated bias value from -100 to 100. You\ncan use this tokenizer tool to convert text to token IDs. Mathematically,\nthe bias is added to the logits generated by the model prior to sampling.\nThe exact effect will vary per model, but values between -1 and 1 should\ndecrease or increase likelihood of selection; values like -100 or 100\nshould result in a ban or exclusive selection of the relevant token.\n\nAs an example, you can pass {\"50256\": -100} to prevent the <|endoftext|>\ntoken from being generated.\n */\n  logitBias: z.record(z.string(), z.number()).optional(),\n\n  /**\nThe suffix that comes after a completion of inserted text.\n */\n  suffix: z.string().optional(),\n\n  /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n */\n  user: z.string().optional(),\n\n  /**\nReturn the log probabilities of the tokens. Including logprobs will increase\nthe response size and can slow down response times. However, it can\nbe useful to better understand how the model is behaving.\nSetting to true will return the log probabilities of the tokens that\nwere generated.\nSetting to a number will return the log probabilities of the top n\ntokens that were generated.\n   */\n  logprobs: z.union([z.boolean(), z.number()]).optional(),\n});\n\nexport type OpenAICompletionProviderOptions = z.infer<\n  typeof openaiCompletionProviderOptions\n>;\n","import {\n  EmbeddingModelV2,\n  TooManyEmbeddingValuesForCallError,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAIEmbeddingModelId,\n  openaiEmbeddingProviderOptions,\n} from './openai-embedding-options';\n\nexport class OpenAIEmbeddingModel implements EmbeddingModelV2<string> {\n  readonly specificationVersion = 'v2';\n  readonly modelId: OpenAIEmbeddingModelId;\n  readonly maxEmbeddingsPerCall = 2048;\n  readonly supportsParallelCalls = true;\n\n  private readonly config: OpenAIConfig;\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(modelId: OpenAIEmbeddingModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  async doEmbed({\n    values,\n    headers,\n    abortSignal,\n    providerOptions,\n  }: Parameters<EmbeddingModelV2<string>['doEmbed']>[0]): Promise<\n    Awaited<ReturnType<EmbeddingModelV2<string>['doEmbed']>>\n  > {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values,\n      });\n    }\n\n    // Parse provider options\n    const openaiOptions =\n      (await parseProviderOptions({\n        provider: 'openai',\n        providerOptions,\n        schema: openaiEmbeddingProviderOptions,\n      })) ?? {};\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/embeddings',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: 'float',\n        dimensions: openaiOptions.dimensions,\n        user: openaiOptions.user,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTextEmbeddingResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      embeddings: response.data.map(item => item.embedding),\n      usage: response.usage\n        ? { tokens: response.usage.prompt_tokens }\n        : undefined,\n      response: { headers: responseHeaders, body: rawValue },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiTextEmbeddingResponseSchema = z.object({\n  data: z.array(z.object({ embedding: z.array(z.number()) })),\n  usage: z.object({ prompt_tokens: z.number() }).nullish(),\n});\n","import { z } from 'zod/v4';\n\nexport type OpenAIEmbeddingModelId =\n  | 'text-embedding-3-small'\n  | 'text-embedding-3-large'\n  | 'text-embedding-ada-002'\n  | (string & {});\n\nexport const openaiEmbeddingProviderOptions = z.object({\n  /**\nThe number of dimensions the resulting output embeddings should have.\nOnly supported in text-embedding-3 and later models.\n   */\n  dimensions: z.number().optional(),\n\n  /**\nA unique identifier representing your end-user, which can help OpenAI to\nmonitor and detect abuse. Learn more.\n*/\n  user: z.string().optional(),\n});\n\nexport type OpenAIEmbeddingProviderOptions = z.infer<\n  typeof openaiEmbeddingProviderOptions\n>;\n","import { ImageModelV2, ImageModelV2CallWarning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createJsonResponseHandler,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAIImageModelId,\n  hasDefaultResponseFormat,\n  modelMaxImagesPerCall,\n} from './openai-image-options';\n\ninterface OpenAIImageModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAIImageModel implements ImageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get maxImagesPerCall(): number {\n    return modelMaxImagesPerCall[this.modelId] ?? 1;\n  }\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAIImageModelId,\n    private readonly config: OpenAIImageModelConfig,\n  ) {}\n\n  async doGenerate({\n    prompt,\n    n,\n    size,\n    aspectRatio,\n    seed,\n    providerOptions,\n    headers,\n    abortSignal,\n  }: Parameters<ImageModelV2['doGenerate']>[0]): Promise<\n    Awaited<ReturnType<ImageModelV2['doGenerate']>>\n  > {\n    const warnings: Array<ImageModelV2CallWarning> = [];\n\n    if (aspectRatio != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'aspectRatio',\n        details:\n          'This model does not support aspect ratio. Use `size` instead.',\n      });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'seed' });\n    }\n\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { value: response, responseHeaders } = await postJsonToApi({\n      url: this.config.url({\n        path: '/images/generations',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        prompt,\n        n,\n        size,\n        ...(providerOptions.openai ?? {}),\n        ...(!hasDefaultResponseFormat.has(this.modelId)\n          ? { response_format: 'b64_json' }\n          : {}),\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiImageResponseSchema,\n      ),\n      abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      images: response.data.map(item => item.b64_json),\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n      },\n      providerMetadata: {\n        openai: {\n          images: response.data.map(item =>\n            item.revised_prompt\n              ? {\n                  revisedPrompt: item.revised_prompt,\n                }\n              : null,\n          ),\n        },\n      },\n    };\n  }\n}\n\n// minimal version of the schema, focussed on what is needed for the implementation\n// this approach limits breakages when the API changes and increases efficiency\nconst openaiImageResponseSchema = z.object({\n  data: z.array(\n    z.object({ b64_json: z.string(), revised_prompt: z.string().optional() }),\n  ),\n});\n","export type OpenAIImageModelId =\n  | 'gpt-image-1'\n  | 'dall-e-3'\n  | 'dall-e-2'\n  | (string & {});\n\n// https://platform.openai.com/docs/guides/images\nexport const modelMaxImagesPerCall: Record<OpenAIImageModelId, number> = {\n  'dall-e-3': 1,\n  'dall-e-2': 10,\n  'gpt-image-1': 10,\n};\n\nexport const hasDefaultResponseFormat = new Set(['gpt-image-1']);\n","import { createProviderDefinedToolFactory } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\n\nexport const codeInterpreterArgsSchema = z.object({\n  container: z\n    .union([\n      z.string(),\n      z.object({\n        fileIds: z.array(z.string()).optional(),\n      }),\n    ])\n    .optional(),\n});\n\nexport const codeInterpreter = createProviderDefinedToolFactory<\n  {},\n  {\n    /**\n     * The code interpreter container.\n     * Can be a container ID\n     * or an object that specifies uploaded file IDs to make available to your code.\n     */\n    container?: string | { fileIds?: string[] };\n  }\n>({\n  id: 'openai.code_interpreter',\n  name: 'code_interpreter',\n  inputSchema: z.object({}),\n});\n","import { codeInterpreter } from './tool/code-interpreter';\nimport { fileSearch } from './tool/file-search';\nimport { webSearchPreview } from './tool/web-search-preview';\n\nexport const openaiTools = {\n  codeInterpreter,\n  fileSearch,\n  webSearchPreview,\n};\n","import {\n  APICallError,\n  LanguageModelV2,\n  LanguageModelV2CallWarning,\n  LanguageModelV2Content,\n  LanguageModelV2FinishReason,\n  LanguageModelV2StreamPart,\n  LanguageModelV2Usage,\n  SharedV2ProviderMetadata,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  parseProviderOptions,\n  ParseResult,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { convertToOpenAIResponsesMessages } from './convert-to-openai-responses-messages';\nimport { mapOpenAIResponseFinishReason } from './map-openai-responses-finish-reason';\nimport { prepareResponsesTools } from './openai-responses-prepare-tools';\nimport { OpenAIResponsesModelId } from './openai-responses-settings';\n\nconst webSearchCallItem = z.object({\n  type: z.literal('web_search_call'),\n  id: z.string(),\n  status: z.string(),\n  action: z\n    .discriminatedUnion('type', [\n      z.object({\n        type: z.literal('search'),\n        query: z.string().nullish(),\n      }),\n      z.object({\n        type: z.literal('open_page'),\n        url: z.string(),\n      }),\n      z.object({\n        type: z.literal('find'),\n        url: z.string(),\n        pattern: z.string(),\n      }),\n    ])\n    .nullish(),\n});\n\n/**\n * `top_logprobs` request body argument can be set to an integer between\n * 0 and 20 specifying the number of most likely tokens to return at each\n * token position, each with an associated log probability.\n *\n * @see https://platform.openai.com/docs/api-reference/responses/create#responses_create-top_logprobs\n */\nconst TOP_LOGPROBS_MAX = 20;\n\nconst LOGPROBS_SCHEMA = z.array(\n  z.object({\n    token: z.string(),\n    logprob: z.number(),\n    top_logprobs: z.array(\n      z.object({\n        token: z.string(),\n        logprob: z.number(),\n      }),\n    ),\n  }),\n);\n\nexport class OpenAIResponsesLanguageModel implements LanguageModelV2 {\n  readonly specificationVersion = 'v2';\n\n  readonly modelId: OpenAIResponsesModelId;\n\n  private readonly config: OpenAIConfig;\n\n  constructor(modelId: OpenAIResponsesModelId, config: OpenAIConfig) {\n    this.modelId = modelId;\n    this.config = config;\n  }\n\n  readonly supportedUrls: Record<string, RegExp[]> = {\n    'image/*': [/^https?:\\/\\/.*$/],\n    'application/pdf': [/^https?:\\/\\/.*$/],\n  };\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  private async getArgs({\n    maxOutputTokens,\n    temperature,\n    stopSequences,\n    topP,\n    topK,\n    presencePenalty,\n    frequencyPenalty,\n    seed,\n    prompt,\n    providerOptions,\n    tools,\n    toolChoice,\n    responseFormat,\n  }: Parameters<LanguageModelV2['doGenerate']>[0]) {\n    const warnings: LanguageModelV2CallWarning[] = [];\n    const modelConfig = getResponsesModelConfig(this.modelId);\n\n    if (topK != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'topK' });\n    }\n\n    if (seed != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'seed' });\n    }\n\n    if (presencePenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'presencePenalty',\n      });\n    }\n\n    if (frequencyPenalty != null) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'frequencyPenalty',\n      });\n    }\n\n    if (stopSequences != null) {\n      warnings.push({ type: 'unsupported-setting', setting: 'stopSequences' });\n    }\n\n    const { messages, warnings: messageWarnings } =\n      await convertToOpenAIResponsesMessages({\n        prompt,\n        systemMessageMode: modelConfig.systemMessageMode,\n        fileIdPrefixes: this.config.fileIdPrefixes,\n      });\n\n    warnings.push(...messageWarnings);\n\n    const openaiOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openaiResponsesProviderOptionsSchema,\n    });\n\n    const strictJsonSchema = openaiOptions?.strictJsonSchema ?? false;\n\n    const topLogprobs =\n      typeof openaiOptions?.logprobs === 'number'\n        ? openaiOptions?.logprobs\n        : openaiOptions?.logprobs === true\n          ? TOP_LOGPROBS_MAX\n          : undefined;\n    const openaiOptionsInclude = topLogprobs\n      ? Array.isArray(openaiOptions?.include)\n        ? [...openaiOptions?.include, 'message.output_text.logprobs']\n        : ['message.output_text.logprobs']\n      : openaiOptions?.include;\n\n    const baseArgs = {\n      model: this.modelId,\n      input: messages,\n      temperature,\n      top_p: topP,\n      max_output_tokens: maxOutputTokens,\n\n      ...((responseFormat?.type === 'json' || openaiOptions?.textVerbosity) && {\n        text: {\n          ...(responseFormat?.type === 'json' && {\n            format:\n              responseFormat.schema != null\n                ? {\n                    type: 'json_schema',\n                    strict: strictJsonSchema,\n                    name: responseFormat.name ?? 'response',\n                    description: responseFormat.description,\n                    schema: responseFormat.schema,\n                  }\n                : { type: 'json_object' },\n          }),\n          ...(openaiOptions?.textVerbosity && {\n            verbosity: openaiOptions.textVerbosity,\n          }),\n        },\n      }),\n\n      // provider options:\n      metadata: openaiOptions?.metadata,\n      parallel_tool_calls: openaiOptions?.parallelToolCalls,\n      previous_response_id: openaiOptions?.previousResponseId,\n      store: openaiOptions?.store,\n      user: openaiOptions?.user,\n      instructions: openaiOptions?.instructions,\n      service_tier: openaiOptions?.serviceTier,\n      include: openaiOptionsInclude,\n      prompt_cache_key: openaiOptions?.promptCacheKey,\n      safety_identifier: openaiOptions?.safetyIdentifier,\n      top_logprobs: topLogprobs,\n\n      // model-specific settings:\n      ...(modelConfig.isReasoningModel &&\n        (openaiOptions?.reasoningEffort != null ||\n          openaiOptions?.reasoningSummary != null) && {\n          reasoning: {\n            ...(openaiOptions?.reasoningEffort != null && {\n              effort: openaiOptions.reasoningEffort,\n            }),\n            ...(openaiOptions?.reasoningSummary != null && {\n              summary: openaiOptions.reasoningSummary,\n            }),\n          },\n        }),\n      ...(modelConfig.requiredAutoTruncation && {\n        truncation: 'auto',\n      }),\n    };\n\n    if (modelConfig.isReasoningModel) {\n      // remove unsupported settings for reasoning models\n      // see https://platform.openai.com/docs/guides/reasoning#limitations\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'temperature',\n          details: 'temperature is not supported for reasoning models',\n        });\n      }\n\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = undefined;\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'topP',\n          details: 'topP is not supported for reasoning models',\n        });\n      }\n    } else {\n      if (openaiOptions?.reasoningEffort != null) {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'reasoningEffort',\n          details: 'reasoningEffort is not supported for non-reasoning models',\n        });\n      }\n\n      if (openaiOptions?.reasoningSummary != null) {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'reasoningSummary',\n          details: 'reasoningSummary is not supported for non-reasoning models',\n        });\n      }\n    }\n\n    // Validate flex processing support\n    if (\n      openaiOptions?.serviceTier === 'flex' &&\n      !modelConfig.supportsFlexProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'flex processing is only available for o3, o4-mini, and gpt-5 models',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    // Validate priority processing support\n    if (\n      openaiOptions?.serviceTier === 'priority' &&\n      !modelConfig.supportsPriorityProcessing\n    ) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'serviceTier',\n        details:\n          'priority processing is only available for supported models (gpt-4, gpt-5, gpt-5-mini, o3, o4-mini) and requires Enterprise access. gpt-5-nano is not supported',\n      });\n      // Remove from args if not supported\n      delete (baseArgs as any).service_tier;\n    }\n\n    const {\n      tools: openaiTools,\n      toolChoice: openaiToolChoice,\n      toolWarnings,\n    } = prepareResponsesTools({\n      tools,\n      toolChoice,\n      strictJsonSchema,\n    });\n\n    return {\n      args: {\n        ...baseArgs,\n        tools: openaiTools,\n        tool_choice: openaiToolChoice,\n      },\n      warnings: [...warnings, ...toolWarnings],\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<LanguageModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doGenerate']>>> {\n    const { args: body, warnings } = await this.getArgs(options);\n    const url = this.config.url({\n      path: '/responses',\n      modelId: this.modelId,\n    });\n\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        z.object({\n          id: z.string(),\n          created_at: z.number(),\n          error: z\n            .object({\n              code: z.string(),\n              message: z.string(),\n            })\n            .nullish(),\n          model: z.string(),\n          output: z.array(\n            z.discriminatedUnion('type', [\n              z.object({\n                type: z.literal('message'),\n                role: z.literal('assistant'),\n                id: z.string(),\n                content: z.array(\n                  z.object({\n                    type: z.literal('output_text'),\n                    text: z.string(),\n                    logprobs: LOGPROBS_SCHEMA.nullish(),\n                    annotations: z.array(\n                      z.discriminatedUnion('type', [\n                        z.object({\n                          type: z.literal('url_citation'),\n                          start_index: z.number(),\n                          end_index: z.number(),\n                          url: z.string(),\n                          title: z.string(),\n                        }),\n                        z.object({\n                          type: z.literal('file_citation'),\n                          file_id: z.string(),\n                          filename: z.string().nullish(),\n                          index: z.number().nullish(),\n                          start_index: z.number().nullish(),\n                          end_index: z.number().nullish(),\n                          quote: z.string().nullish(),\n                        }),\n                      ]),\n                    ),\n                  }),\n                ),\n              }),\n              z.object({\n                type: z.literal('function_call'),\n                call_id: z.string(),\n                name: z.string(),\n                arguments: z.string(),\n                id: z.string(),\n              }),\n              webSearchCallItem,\n              z.object({\n                type: z.literal('computer_call'),\n                id: z.string(),\n                status: z.string().optional(),\n              }),\n              z.object({\n                type: z.literal('file_search_call'),\n                id: z.string(),\n                status: z.string().optional(),\n                queries: z.array(z.string()).nullish(),\n                results: z\n                  .array(\n                    z.object({\n                      attributes: z.object({\n                        file_id: z.string(),\n                        filename: z.string(),\n                        score: z.number(),\n                        text: z.string(),\n                      }),\n                    }),\n                  )\n                  .nullish(),\n              }),\n              z.object({\n                type: z.literal('reasoning'),\n                id: z.string(),\n                encrypted_content: z.string().nullish(),\n                summary: z.array(\n                  z.object({\n                    type: z.literal('summary_text'),\n                    text: z.string(),\n                  }),\n                ),\n              }),\n            ]),\n          ),\n          service_tier: z.string().nullish(),\n          incomplete_details: z.object({ reason: z.string() }).nullable(),\n          usage: usageSchema,\n        }),\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    if (response.error) {\n      throw new APICallError({\n        message: response.error.message,\n        url,\n        requestBodyValues: body,\n        statusCode: 400,\n        responseHeaders,\n        responseBody: rawResponse as string,\n        isRetryable: false,\n      });\n    }\n\n    const content: Array<LanguageModelV2Content> = [];\n    const logprobs: Array<z.infer<typeof LOGPROBS_SCHEMA>> = [];\n\n    // map response content to content array\n    for (const part of response.output) {\n      switch (part.type) {\n        case 'reasoning': {\n          // when there are no summary parts, we need to add an empty reasoning part:\n          if (part.summary.length === 0) {\n            part.summary.push({ type: 'summary_text', text: '' });\n          }\n\n          for (const summary of part.summary) {\n            content.push({\n              type: 'reasoning' as const,\n              text: summary.text,\n              providerMetadata: {\n                openai: {\n                  itemId: part.id,\n                  reasoningEncryptedContent: part.encrypted_content ?? null,\n                },\n              },\n            });\n          }\n          break;\n        }\n\n        case 'message': {\n          for (const contentPart of part.content) {\n            if (\n              options.providerOptions?.openai?.logprobs &&\n              contentPart.logprobs\n            ) {\n              logprobs.push(contentPart.logprobs);\n            }\n\n            content.push({\n              type: 'text',\n              text: contentPart.text,\n              providerMetadata: {\n                openai: {\n                  itemId: part.id,\n                },\n              },\n            });\n\n            for (const annotation of contentPart.annotations) {\n              if (annotation.type === 'url_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: this.config.generateId?.() ?? generateId(),\n                  url: annotation.url,\n                  title: annotation.title,\n                });\n              } else if (annotation.type === 'file_citation') {\n                content.push({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: this.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title: annotation.quote ?? annotation.filename ?? 'Document',\n                  filename: annotation.filename ?? annotation.file_id,\n                });\n              }\n            }\n          }\n\n          break;\n        }\n\n        case 'function_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.call_id,\n            toolName: part.name,\n            input: part.arguments,\n            providerMetadata: {\n              openai: {\n                itemId: part.id,\n              },\n            },\n          });\n          break;\n        }\n\n        case 'web_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'web_search_preview',\n            input: JSON.stringify({ action: part.action }),\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'web_search_preview',\n            result: { status: part.status },\n            providerExecuted: true,\n          });\n          break;\n        }\n\n        case 'computer_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'computer_use',\n            input: '',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'computer_use',\n            result: {\n              type: 'computer_use_tool_result',\n              status: part.status || 'completed',\n            },\n            providerExecuted: true,\n          });\n          break;\n        }\n\n        case 'file_search_call': {\n          content.push({\n            type: 'tool-call',\n            toolCallId: part.id,\n            toolName: 'file_search',\n            input: '',\n            providerExecuted: true,\n          });\n\n          content.push({\n            type: 'tool-result',\n            toolCallId: part.id,\n            toolName: 'file_search',\n            result: {\n              type: 'file_search_tool_result',\n              status: part.status || 'completed',\n              ...(part.queries && { queries: part.queries }),\n              ...(part.results && { results: part.results }),\n            },\n            providerExecuted: true,\n          });\n          break;\n        }\n      }\n    }\n\n    const providerMetadata: SharedV2ProviderMetadata = {\n      openai: { responseId: response.id },\n    };\n\n    if (logprobs.length > 0) {\n      providerMetadata.openai.logprobs = logprobs;\n    }\n\n    if (typeof response.service_tier === 'string') {\n      providerMetadata.openai.serviceTier = response.service_tier;\n    }\n\n    return {\n      content,\n      finishReason: mapOpenAIResponseFinishReason({\n        finishReason: response.incomplete_details?.reason,\n        hasToolCalls: content.some(part => part.type === 'tool-call'),\n      }),\n      usage: {\n        inputTokens: response.usage.input_tokens,\n        outputTokens: response.usage.output_tokens,\n        totalTokens: response.usage.input_tokens + response.usage.output_tokens,\n        reasoningTokens:\n          response.usage.output_tokens_details?.reasoning_tokens ?? undefined,\n        cachedInputTokens:\n          response.usage.input_tokens_details?.cached_tokens ?? undefined,\n      },\n      request: { body },\n      response: {\n        id: response.id,\n        timestamp: new Date(response.created_at * 1000),\n        modelId: response.model,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n      providerMetadata,\n      warnings,\n    };\n  }\n\n  async doStream(\n    options: Parameters<LanguageModelV2['doStream']>[0],\n  ): Promise<Awaited<ReturnType<LanguageModelV2['doStream']>>> {\n    const { args: body, warnings } = await this.getArgs(options);\n\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: '/responses',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: {\n        ...body,\n        stream: true,\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiResponsesChunkSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const self = this;\n\n    let finishReason: LanguageModelV2FinishReason = 'unknown';\n    const usage: LanguageModelV2Usage = {\n      inputTokens: undefined,\n      outputTokens: undefined,\n      totalTokens: undefined,\n    };\n    const logprobs: Array<z.infer<typeof LOGPROBS_SCHEMA>> = [];\n    let responseId: string | null = null;\n    const ongoingToolCalls: Record<\n      number,\n      { toolName: string; toolCallId: string } | undefined\n    > = {};\n    let hasToolCalls = false;\n\n    const activeReasoning: Record<\n      string,\n      {\n        encryptedContent?: string | null;\n        summaryParts: number[];\n      }\n    > = {};\n\n    let serviceTier: string | undefined;\n\n    return {\n      stream: response.pipeThrough(\n        new TransformStream<\n          ParseResult<z.infer<typeof openaiResponsesChunkSchema>>,\n          LanguageModelV2StreamPart\n        >({\n          start(controller) {\n            controller.enqueue({ type: 'stream-start', warnings });\n          },\n\n          transform(chunk, controller) {\n            if (options.includeRawChunks) {\n              controller.enqueue({ type: 'raw', rawValue: chunk.rawValue });\n            }\n\n            // handle failed chunk parsing / validation:\n            if (!chunk.success) {\n              finishReason = 'error';\n              controller.enqueue({ type: 'error', error: chunk.error });\n              return;\n            }\n\n            const value = chunk.value;\n\n            if (isResponseOutputItemAddedChunk(value)) {\n              if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: value.item.name,\n                  toolCallId: value.item.call_id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.call_id,\n                  toolName: value.item.name,\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: 'web_search_preview',\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: 'web_search_preview',\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: 'computer_use',\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: 'computer_use',\n                });\n              } else if (value.item.type === 'file_search_call') {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: 'file_search',\n                  toolCallId: value.item.id,\n                };\n\n                controller.enqueue({\n                  type: 'tool-input-start',\n                  id: value.item.id,\n                  toolName: 'file_search',\n                });\n              } else if (value.item.type === 'message') {\n                controller.enqueue({\n                  type: 'text-start',\n                  id: value.item.id,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (isResponseOutputItemAddedReasoningChunk(value)) {\n                activeReasoning[value.item.id] = {\n                  encryptedContent: value.item.encrypted_content,\n                  summaryParts: [0],\n                };\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item.id}:0`,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                      reasoningEncryptedContent:\n                        value.item.encrypted_content ?? null,\n                    },\n                  },\n                });\n              }\n            } else if (isResponseOutputItemDoneChunk(value)) {\n              if (value.item.type === 'function_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n                hasToolCalls = true;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.call_id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.call_id,\n                  toolName: value.item.name,\n                  input: value.item.arguments,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item.id,\n                    },\n                  },\n                });\n              } else if (value.item.type === 'web_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n                hasToolCalls = true;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'web_search_preview',\n                  input: JSON.stringify({ action: value.item.action }),\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'web_search_preview',\n                  result: { status: value.item.status },\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'computer_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n                hasToolCalls = true;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'computer_use',\n                  input: '',\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'computer_use',\n                  result: {\n                    type: 'computer_use_tool_result',\n                    status: value.item.status || 'completed',\n                  },\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'file_search_call') {\n                ongoingToolCalls[value.output_index] = undefined;\n                hasToolCalls = true;\n\n                controller.enqueue({\n                  type: 'tool-input-end',\n                  id: value.item.id,\n                });\n\n                controller.enqueue({\n                  type: 'tool-call',\n                  toolCallId: value.item.id,\n                  toolName: 'file_search',\n                  input: '',\n                  providerExecuted: true,\n                });\n\n                controller.enqueue({\n                  type: 'tool-result',\n                  toolCallId: value.item.id,\n                  toolName: 'file_search',\n                  result: {\n                    type: 'file_search_tool_result',\n                    status: value.item.status || 'completed',\n                    ...(value.item.queries && { queries: value.item.queries }),\n                    ...(value.item.results && { results: value.item.results }),\n                  },\n                  providerExecuted: true,\n                });\n              } else if (value.item.type === 'message') {\n                controller.enqueue({\n                  type: 'text-end',\n                  id: value.item.id,\n                });\n              } else if (isResponseOutputItemDoneReasoningChunk(value)) {\n                const activeReasoningPart = activeReasoning[value.item.id];\n\n                for (const summaryIndex of activeReasoningPart.summaryParts) {\n                  controller.enqueue({\n                    type: 'reasoning-end',\n                    id: `${value.item.id}:${summaryIndex}`,\n                    providerMetadata: {\n                      openai: {\n                        itemId: value.item.id,\n                        reasoningEncryptedContent:\n                          value.item.encrypted_content ?? null,\n                      },\n                    },\n                  });\n                }\n\n                delete activeReasoning[value.item.id];\n              }\n            } else if (isResponseFunctionCallArgumentsDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: 'tool-input-delta',\n                  id: toolCall.toolCallId,\n                  delta: value.delta,\n                });\n              }\n            } else if (isResponseCreatedChunk(value)) {\n              responseId = value.response.id;\n              controller.enqueue({\n                type: 'response-metadata',\n                id: value.response.id,\n                timestamp: new Date(value.response.created_at * 1000),\n                modelId: value.response.model,\n              });\n            } else if (isTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: 'text-delta',\n                id: value.item_id,\n                delta: value.delta,\n              });\n\n              if (options.providerOptions?.openai?.logprobs && value.logprobs) {\n                logprobs.push(value.logprobs);\n              }\n            } else if (isResponseReasoningSummaryPartAddedChunk(value)) {\n              // the first reasoning start is pushed in isResponseOutputItemAddedReasoningChunk.\n              if (value.summary_index > 0) {\n                activeReasoning[value.item_id]?.summaryParts.push(\n                  value.summary_index,\n                );\n\n                controller.enqueue({\n                  type: 'reasoning-start',\n                  id: `${value.item_id}:${value.summary_index}`,\n                  providerMetadata: {\n                    openai: {\n                      itemId: value.item_id,\n                      reasoningEncryptedContent:\n                        activeReasoning[value.item_id]?.encryptedContent ??\n                        null,\n                    },\n                  },\n                });\n              }\n            } else if (isResponseReasoningSummaryTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: 'reasoning-delta',\n                id: `${value.item_id}:${value.summary_index}`,\n                delta: value.delta,\n                providerMetadata: {\n                  openai: {\n                    itemId: value.item_id,\n                  },\n                },\n              });\n            } else if (isResponseFinishedChunk(value)) {\n              finishReason = mapOpenAIResponseFinishReason({\n                finishReason: value.response.incomplete_details?.reason,\n                hasToolCalls,\n              });\n              usage.inputTokens = value.response.usage.input_tokens;\n              usage.outputTokens = value.response.usage.output_tokens;\n              usage.totalTokens =\n                value.response.usage.input_tokens +\n                value.response.usage.output_tokens;\n              usage.reasoningTokens =\n                value.response.usage.output_tokens_details?.reasoning_tokens ??\n                undefined;\n              usage.cachedInputTokens =\n                value.response.usage.input_tokens_details?.cached_tokens ??\n                undefined;\n              if (typeof value.response.service_tier === 'string') {\n                serviceTier = value.response.service_tier;\n              }\n            } else if (isResponseAnnotationAddedChunk(value)) {\n              if (value.annotation.type === 'url_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'url',\n                  id: self.config.generateId?.() ?? generateId(),\n                  url: value.annotation.url,\n                  title: value.annotation.title,\n                });\n              } else if (value.annotation.type === 'file_citation') {\n                controller.enqueue({\n                  type: 'source',\n                  sourceType: 'document',\n                  id: self.config.generateId?.() ?? generateId(),\n                  mediaType: 'text/plain',\n                  title:\n                    value.annotation.quote ??\n                    value.annotation.filename ??\n                    'Document',\n                  filename:\n                    value.annotation.filename ?? value.annotation.file_id,\n                });\n              }\n            } else if (isErrorChunk(value)) {\n              controller.enqueue({ type: 'error', error: value });\n            }\n          },\n\n          flush(controller) {\n            const providerMetadata: SharedV2ProviderMetadata = {\n              openai: {\n                responseId,\n              },\n            };\n\n            if (logprobs.length > 0) {\n              providerMetadata.openai.logprobs = logprobs;\n            }\n\n            if (serviceTier !== undefined) {\n              providerMetadata.openai.serviceTier = serviceTier;\n            }\n\n            controller.enqueue({\n              type: 'finish',\n              finishReason,\n              usage,\n              providerMetadata,\n            });\n          },\n        }),\n      ),\n      request: { body },\n      response: { headers: responseHeaders },\n    };\n  }\n}\n\nconst usageSchema = z.object({\n  input_tokens: z.number(),\n  input_tokens_details: z\n    .object({ cached_tokens: z.number().nullish() })\n    .nullish(),\n  output_tokens: z.number(),\n  output_tokens_details: z\n    .object({ reasoning_tokens: z.number().nullish() })\n    .nullish(),\n});\n\nconst textDeltaChunkSchema = z.object({\n  type: z.literal('response.output_text.delta'),\n  item_id: z.string(),\n  delta: z.string(),\n  logprobs: LOGPROBS_SCHEMA.nullish(),\n});\n\nconst errorChunkSchema = z.object({\n  type: z.literal('error'),\n  code: z.string(),\n  message: z.string(),\n  param: z.string().nullish(),\n  sequence_number: z.number(),\n});\n\nconst responseFinishedChunkSchema = z.object({\n  type: z.enum(['response.completed', 'response.incomplete']),\n  response: z.object({\n    incomplete_details: z.object({ reason: z.string() }).nullish(),\n    usage: usageSchema,\n    service_tier: z.string().nullish(),\n  }),\n});\n\nconst responseCreatedChunkSchema = z.object({\n  type: z.literal('response.created'),\n  response: z.object({\n    id: z.string(),\n    created_at: z.number(),\n    model: z.string(),\n    service_tier: z.string().nullish(),\n  }),\n});\n\nconst responseOutputItemAddedSchema = z.object({\n  type: z.literal('response.output_item.added'),\n  output_index: z.number(),\n  item: z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('message'),\n      id: z.string(),\n    }),\n    z.object({\n      type: z.literal('reasoning'),\n      id: z.string(),\n      encrypted_content: z.string().nullish(),\n    }),\n    z.object({\n      type: z.literal('function_call'),\n      id: z.string(),\n      call_id: z.string(),\n      name: z.string(),\n      arguments: z.string(),\n    }),\n    z.object({\n      type: z.literal('web_search_call'),\n      id: z.string(),\n      status: z.string(),\n      action: z\n        .object({\n          type: z.literal('search'),\n          query: z.string().optional(),\n        })\n        .nullish(),\n    }),\n    z.object({\n      type: z.literal('computer_call'),\n      id: z.string(),\n      status: z.string(),\n    }),\n    z.object({\n      type: z.literal('file_search_call'),\n      id: z.string(),\n      status: z.string(),\n      queries: z.array(z.string()).nullish(),\n      results: z\n        .array(\n          z.object({\n            attributes: z.object({\n              file_id: z.string(),\n              filename: z.string(),\n              score: z.number(),\n              text: z.string(),\n            }),\n          }),\n        )\n        .optional(),\n    }),\n  ]),\n});\n\nconst responseOutputItemDoneSchema = z.object({\n  type: z.literal('response.output_item.done'),\n  output_index: z.number(),\n  item: z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('message'),\n      id: z.string(),\n    }),\n    z.object({\n      type: z.literal('reasoning'),\n      id: z.string(),\n      encrypted_content: z.string().nullish(),\n    }),\n    z.object({\n      type: z.literal('function_call'),\n      id: z.string(),\n      call_id: z.string(),\n      name: z.string(),\n      arguments: z.string(),\n      status: z.literal('completed'),\n    }),\n    webSearchCallItem,\n    z.object({\n      type: z.literal('computer_call'),\n      id: z.string(),\n      status: z.literal('completed'),\n    }),\n    z.object({\n      type: z.literal('file_search_call'),\n      id: z.string(),\n      status: z.literal('completed'),\n      queries: z.array(z.string()).nullish(),\n      results: z\n        .array(\n          z.object({\n            attributes: z.object({\n              file_id: z.string(),\n              filename: z.string(),\n              score: z.number(),\n              text: z.string(),\n            }),\n          }),\n        )\n        .nullish(),\n    }),\n  ]),\n});\n\nconst responseFunctionCallArgumentsDeltaSchema = z.object({\n  type: z.literal('response.function_call_arguments.delta'),\n  item_id: z.string(),\n  output_index: z.number(),\n  delta: z.string(),\n});\n\nconst responseAnnotationAddedSchema = z.object({\n  type: z.literal('response.output_text.annotation.added'),\n  annotation: z.discriminatedUnion('type', [\n    z.object({\n      type: z.literal('url_citation'),\n      url: z.string(),\n      title: z.string(),\n    }),\n    z.object({\n      type: z.literal('file_citation'),\n      file_id: z.string(),\n      filename: z.string().nullish(),\n      index: z.number().nullish(),\n      start_index: z.number().nullish(),\n      end_index: z.number().nullish(),\n      quote: z.string().nullish(),\n    }),\n  ]),\n});\n\nconst responseReasoningSummaryPartAddedSchema = z.object({\n  type: z.literal('response.reasoning_summary_part.added'),\n  item_id: z.string(),\n  summary_index: z.number(),\n});\n\nconst responseReasoningSummaryTextDeltaSchema = z.object({\n  type: z.literal('response.reasoning_summary_text.delta'),\n  item_id: z.string(),\n  summary_index: z.number(),\n  delta: z.string(),\n});\n\nconst openaiResponsesChunkSchema = z.union([\n  textDeltaChunkSchema,\n  responseFinishedChunkSchema,\n  responseCreatedChunkSchema,\n  responseOutputItemAddedSchema,\n  responseOutputItemDoneSchema,\n  responseFunctionCallArgumentsDeltaSchema,\n  responseAnnotationAddedSchema,\n  responseReasoningSummaryPartAddedSchema,\n  responseReasoningSummaryTextDeltaSchema,\n  errorChunkSchema,\n  z.object({ type: z.string() }).loose(), // fallback for unknown chunks\n]);\n\ntype ExtractByType<\n  T,\n  K extends T extends { type: infer U } ? U : never,\n> = T extends { type: K } ? T : never;\n\nfunction isTextDeltaChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof textDeltaChunkSchema> {\n  return chunk.type === 'response.output_text.delta';\n}\n\nfunction isResponseOutputItemDoneChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemDoneSchema> {\n  return chunk.type === 'response.output_item.done';\n}\n\nfunction isResponseOutputItemDoneReasoningChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemDoneSchema> & {\n  item: ExtractByType<\n    z.infer<typeof responseOutputItemDoneSchema>['item'],\n    'reasoning'\n  >;\n} {\n  return (\n    isResponseOutputItemDoneChunk(chunk) && chunk.item.type === 'reasoning'\n  );\n}\n\nfunction isResponseFinishedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseFinishedChunkSchema> {\n  return (\n    chunk.type === 'response.completed' || chunk.type === 'response.incomplete'\n  );\n}\n\nfunction isResponseCreatedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseCreatedChunkSchema> {\n  return chunk.type === 'response.created';\n}\n\nfunction isResponseFunctionCallArgumentsDeltaChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseFunctionCallArgumentsDeltaSchema> {\n  return chunk.type === 'response.function_call_arguments.delta';\n}\n\nfunction isResponseOutputItemAddedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemAddedSchema> {\n  return chunk.type === 'response.output_item.added';\n}\n\nfunction isResponseOutputItemAddedReasoningChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseOutputItemAddedSchema> & {\n  item: ExtractByType<\n    z.infer<typeof responseOutputItemAddedSchema>['item'],\n    'reasoning'\n  >;\n} {\n  return (\n    isResponseOutputItemAddedChunk(chunk) && chunk.item.type === 'reasoning'\n  );\n}\n\nfunction isResponseAnnotationAddedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseAnnotationAddedSchema> {\n  return chunk.type === 'response.output_text.annotation.added';\n}\n\nfunction isResponseReasoningSummaryPartAddedChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseReasoningSummaryPartAddedSchema> {\n  return chunk.type === 'response.reasoning_summary_part.added';\n}\n\nfunction isResponseReasoningSummaryTextDeltaChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof responseReasoningSummaryTextDeltaSchema> {\n  return chunk.type === 'response.reasoning_summary_text.delta';\n}\n\nfunction isErrorChunk(\n  chunk: z.infer<typeof openaiResponsesChunkSchema>,\n): chunk is z.infer<typeof errorChunkSchema> {\n  return chunk.type === 'error';\n}\n\ntype ResponsesModelConfig = {\n  isReasoningModel: boolean;\n  systemMessageMode: 'remove' | 'system' | 'developer';\n  requiredAutoTruncation: boolean;\n  supportsFlexProcessing: boolean;\n  supportsPriorityProcessing: boolean;\n};\n\nfunction getResponsesModelConfig(modelId: string): ResponsesModelConfig {\n  const supportsFlexProcessing =\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini') ||\n    (modelId.startsWith('gpt-5') && !modelId.startsWith('gpt-5-chat'));\n  const supportsPriorityProcessing =\n    modelId.startsWith('gpt-4') ||\n    modelId.startsWith('gpt-5-mini') ||\n    (modelId.startsWith('gpt-5') &&\n      !modelId.startsWith('gpt-5-nano') &&\n      !modelId.startsWith('gpt-5-chat')) ||\n    modelId.startsWith('o3') ||\n    modelId.startsWith('o4-mini');\n  const defaults = {\n    requiredAutoTruncation: false,\n    systemMessageMode: 'system' as const,\n    supportsFlexProcessing,\n    supportsPriorityProcessing,\n  };\n\n  // gpt-5-chat models are non-reasoning\n  if (modelId.startsWith('gpt-5-chat')) {\n    return {\n      ...defaults,\n      isReasoningModel: false,\n    };\n  }\n\n  // o series reasoning models:\n  if (\n    modelId.startsWith('o') ||\n    modelId.startsWith('gpt-5') ||\n    modelId.startsWith('codex-') ||\n    modelId.startsWith('computer-use')\n  ) {\n    if (modelId.startsWith('o1-mini') || modelId.startsWith('o1-preview')) {\n      return {\n        ...defaults,\n        isReasoningModel: true,\n        systemMessageMode: 'remove',\n      };\n    }\n\n    return {\n      ...defaults,\n      isReasoningModel: true,\n      systemMessageMode: 'developer',\n    };\n  }\n\n  // gpt models:\n  return {\n    ...defaults,\n    isReasoningModel: false,\n  };\n}\n\n// TODO AI SDK 6: use optional here instead of nullish\nconst openaiResponsesProviderOptionsSchema = z.object({\n  metadata: z.any().nullish(),\n  parallelToolCalls: z.boolean().nullish(),\n  previousResponseId: z.string().nullish(),\n  store: z.boolean().nullish(),\n  user: z.string().nullish(),\n  reasoningEffort: z.string().nullish(),\n  strictJsonSchema: z.boolean().nullish(),\n  instructions: z.string().nullish(),\n  reasoningSummary: z.string().nullish(),\n  serviceTier: z.enum(['auto', 'flex', 'priority']).nullish(),\n  include: z\n    .array(\n      z.enum([\n        'reasoning.encrypted_content',\n        'file_search_call.results',\n        'message.output_text.logprobs',\n      ]),\n    )\n    .nullish(),\n  textVerbosity: z.enum(['low', 'medium', 'high']).nullish(),\n  promptCacheKey: z.string().nullish(),\n  safetyIdentifier: z.string().nullish(),\n\n  /**\n   * Return the log probabilities of the tokens.\n   *\n   * Setting to true will return the log probabilities of the tokens that\n   * were generated.\n   *\n   * Setting to a number will return the log probabilities of the top n\n   * tokens that were generated.\n   *\n   * @see https://platform.openai.com/docs/api-reference/responses/create\n   * @see https://cookbook.openai.com/examples/using_logprobs\n   */\n  logprobs: z\n    .union([z.boolean(), z.number().min(1).max(TOP_LOGPROBS_MAX)])\n    .optional(),\n});\n\nexport type OpenAIResponsesProviderOptions = z.infer<\n  typeof openaiResponsesProviderOptionsSchema\n>;\n","import {\n  LanguageModelV2CallWarning,\n  LanguageModelV2Prompt,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { parseProviderOptions } from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport {\n  OpenAIResponsesPrompt,\n  OpenAIResponsesReasoning,\n} from './openai-responses-api-types';\nimport { convertToBase64 } from '@ai-sdk/provider-utils';\n\n/**\n * Check if a string is a file ID based on the given prefixes\n * Returns false if prefixes is undefined (disables file ID detection)\n */\nfunction isFileId(data: string, prefixes?: readonly string[]): boolean {\n  if (!prefixes) return false;\n  return prefixes.some(prefix => data.startsWith(prefix));\n}\n\nexport async function convertToOpenAIResponsesMessages({\n  prompt,\n  systemMessageMode,\n  fileIdPrefixes,\n}: {\n  prompt: LanguageModelV2Prompt;\n  systemMessageMode: 'system' | 'developer' | 'remove';\n  fileIdPrefixes?: readonly string[];\n}): Promise<{\n  messages: OpenAIResponsesPrompt;\n  warnings: Array<LanguageModelV2CallWarning>;\n}> {\n  const messages: OpenAIResponsesPrompt = [];\n  const warnings: Array<LanguageModelV2CallWarning> = [];\n\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case 'system': {\n        switch (systemMessageMode) {\n          case 'system': {\n            messages.push({ role: 'system', content });\n            break;\n          }\n          case 'developer': {\n            messages.push({ role: 'developer', content });\n            break;\n          }\n          case 'remove': {\n            warnings.push({\n              type: 'other',\n              message: 'system messages are removed for this model',\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck: never = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`,\n            );\n          }\n        }\n        break;\n      }\n\n      case 'user': {\n        messages.push({\n          role: 'user',\n          content: content.map((part, index) => {\n            switch (part.type) {\n              case 'text': {\n                return { type: 'input_text', text: part.text };\n              }\n              case 'file': {\n                if (part.mediaType.startsWith('image/')) {\n                  const mediaType =\n                    part.mediaType === 'image/*'\n                      ? 'image/jpeg'\n                      : part.mediaType;\n\n                  return {\n                    type: 'input_image',\n                    ...(part.data instanceof URL\n                      ? { image_url: part.data.toString() }\n                      : typeof part.data === 'string' &&\n                          isFileId(part.data, fileIdPrefixes)\n                        ? { file_id: part.data }\n                        : {\n                            image_url: `data:${mediaType};base64,${convertToBase64(part.data)}`,\n                          }),\n                    detail: part.providerOptions?.openai?.imageDetail,\n                  };\n                } else if (part.mediaType === 'application/pdf') {\n                  if (part.data instanceof URL) {\n                    return {\n                      type: 'input_file',\n                      file_url: part.data.toString(),\n                    };\n                  }\n                  return {\n                    type: 'input_file',\n                    ...(typeof part.data === 'string' &&\n                    isFileId(part.data, fileIdPrefixes)\n                      ? { file_id: part.data }\n                      : {\n                          filename: part.filename ?? `part-${index}.pdf`,\n                          file_data: `data:application/pdf;base64,${convertToBase64(part.data)}`,\n                        }),\n                  };\n                } else {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: `file part media type ${part.mediaType}`,\n                  });\n                }\n              }\n            }\n          }),\n        });\n\n        break;\n      }\n\n      case 'assistant': {\n        const reasoningMessages: Record<string, OpenAIResponsesReasoning> = {};\n\n        for (const part of content) {\n          switch (part.type) {\n            case 'text': {\n              messages.push({\n                role: 'assistant',\n                content: [{ type: 'output_text', text: part.text }],\n                id:\n                  (part.providerOptions?.openai?.itemId as string) ?? undefined,\n              });\n              break;\n            }\n            case 'tool-call': {\n              if (part.providerExecuted) {\n                break;\n              }\n\n              messages.push({\n                type: 'function_call',\n                call_id: part.toolCallId,\n                name: part.toolName,\n                arguments: JSON.stringify(part.input),\n                id:\n                  (part.providerOptions?.openai?.itemId as string) ?? undefined,\n              });\n              break;\n            }\n\n            case 'tool-result': {\n              warnings.push({\n                type: 'other',\n                message: `tool result parts in assistant messages are not supported for OpenAI responses`,\n              });\n              break;\n            }\n\n            case 'reasoning': {\n              const providerOptions = await parseProviderOptions({\n                provider: 'openai',\n                providerOptions: part.providerOptions,\n                schema: openaiResponsesReasoningProviderOptionsSchema,\n              });\n\n              const reasoningId = providerOptions?.itemId;\n\n              if (reasoningId != null) {\n                const existingReasoningMessage = reasoningMessages[reasoningId];\n\n                const summaryParts: Array<{\n                  type: 'summary_text';\n                  text: string;\n                }> = [];\n\n                if (part.text.length > 0) {\n                  summaryParts.push({ type: 'summary_text', text: part.text });\n                } else if (existingReasoningMessage !== undefined) {\n                  warnings.push({\n                    type: 'other',\n                    message: `Cannot append empty reasoning part to existing reasoning sequence. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                  });\n                }\n\n                if (existingReasoningMessage === undefined) {\n                  reasoningMessages[reasoningId] = {\n                    type: 'reasoning',\n                    id: reasoningId,\n                    encrypted_content:\n                      providerOptions?.reasoningEncryptedContent,\n                    summary: summaryParts,\n                  };\n                  messages.push(reasoningMessages[reasoningId]);\n                } else {\n                  existingReasoningMessage.summary.push(...summaryParts);\n                }\n              } else {\n                warnings.push({\n                  type: 'other',\n                  message: `Non-OpenAI reasoning parts are not supported. Skipping reasoning part: ${JSON.stringify(part)}.`,\n                });\n              }\n              break;\n            }\n          }\n        }\n\n        break;\n      }\n\n      case 'tool': {\n        for (const part of content) {\n          const output = part.output;\n\n          let contentValue: string;\n          switch (output.type) {\n            case 'text':\n            case 'error-text':\n              contentValue = output.value;\n              break;\n            case 'content':\n            case 'json':\n            case 'error-json':\n              contentValue = JSON.stringify(output.value);\n              break;\n          }\n\n          messages.push({\n            type: 'function_call_output',\n            call_id: part.toolCallId,\n            output: contentValue,\n          });\n        }\n\n        break;\n      }\n\n      default: {\n        const _exhaustiveCheck: never = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n\n  return { messages, warnings };\n}\n\nconst openaiResponsesReasoningProviderOptionsSchema = z.object({\n  itemId: z.string().nullish(),\n  reasoningEncryptedContent: z.string().nullish(),\n});\n\nexport type OpenAIResponsesReasoningProviderOptions = z.infer<\n  typeof openaiResponsesReasoningProviderOptionsSchema\n>;\n","import { LanguageModelV2FinishReason } from '@ai-sdk/provider';\n\nexport function mapOpenAIResponseFinishReason({\n  finishReason,\n  hasToolCalls,\n}: {\n  finishReason: string | null | undefined;\n  hasToolCalls: boolean;\n}): LanguageModelV2FinishReason {\n  switch (finishReason) {\n    case undefined:\n    case null:\n      return hasToolCalls ? 'tool-calls' : 'stop';\n    case 'max_output_tokens':\n      return 'length';\n    case 'content_filter':\n      return 'content-filter';\n    default:\n      return hasToolCalls ? 'tool-calls' : 'unknown';\n  }\n}\n","import {\n  LanguageModelV2CallOptions,\n  LanguageModelV2CallWarning,\n  UnsupportedFunctionalityError,\n} from '@ai-sdk/provider';\nimport { OpenAIResponsesTool } from './openai-responses-api-types';\nimport { fileSearchArgsSchema } from '../tool/file-search';\nimport { codeInterpreterArgsSchema } from '../tool/code-interpreter';\nimport { webSearchPreviewArgsSchema } from '../tool/web-search-preview';\n\nexport function prepareResponsesTools({\n  tools,\n  toolChoice,\n  strictJsonSchema,\n}: {\n  tools: LanguageModelV2CallOptions['tools'];\n  toolChoice?: LanguageModelV2CallOptions['toolChoice'];\n  strictJsonSchema: boolean;\n}): {\n  tools?: Array<OpenAIResponsesTool>;\n  toolChoice?:\n    | 'auto'\n    | 'none'\n    | 'required'\n    | { type: 'file_search' }\n    | { type: 'web_search_preview' }\n    | { type: 'function'; name: string }\n    | { type: 'code_interpreter' };\n  toolWarnings: LanguageModelV2CallWarning[];\n} {\n  // when the tools array is empty, change it to undefined to prevent errors:\n  tools = tools?.length ? tools : undefined;\n\n  const toolWarnings: LanguageModelV2CallWarning[] = [];\n\n  if (tools == null) {\n    return { tools: undefined, toolChoice: undefined, toolWarnings };\n  }\n\n  const openaiTools: Array<OpenAIResponsesTool> = [];\n\n  for (const tool of tools) {\n    switch (tool.type) {\n      case 'function':\n        openaiTools.push({\n          type: 'function',\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.inputSchema,\n          strict: strictJsonSchema,\n        });\n        break;\n      case 'provider-defined': {\n        switch (tool.id) {\n          case 'openai.file_search': {\n            const args = fileSearchArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'file_search',\n              vector_store_ids: args.vectorStoreIds,\n              max_num_results: args.maxNumResults,\n              ranking_options: args.ranking\n                ? { ranker: args.ranking.ranker }\n                : undefined,\n              filters: args.filters,\n            });\n            break;\n          }\n          case 'openai.web_search_preview': {\n            const args = webSearchPreviewArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'web_search_preview',\n              search_context_size: args.searchContextSize,\n              user_location: args.userLocation,\n            });\n            break;\n          }\n          case 'openai.code_interpreter': {\n            const args = codeInterpreterArgsSchema.parse(tool.args);\n            openaiTools.push({\n              type: 'code_interpreter',\n              container:\n                args.container == null\n                  ? { type: 'auto', file_ids: undefined }\n                  : typeof args.container === 'string'\n                    ? args.container\n                    : { type: 'auto', file_ids: args.container.fileIds },\n            });\n            break;\n          }\n          default: {\n            toolWarnings.push({ type: 'unsupported-tool', tool });\n            break;\n          }\n        }\n        break;\n      }\n      default:\n        toolWarnings.push({ type: 'unsupported-tool', tool });\n        break;\n    }\n  }\n\n  if (toolChoice == null) {\n    return { tools: openaiTools, toolChoice: undefined, toolWarnings };\n  }\n\n  const type = toolChoice.type;\n\n  switch (type) {\n    case 'auto':\n    case 'none':\n    case 'required':\n      return { tools: openaiTools, toolChoice: type, toolWarnings };\n    case 'tool':\n      return {\n        tools: openaiTools,\n        toolChoice:\n          toolChoice.toolName === 'code_interpreter' ||\n          toolChoice.toolName === 'file_search' ||\n          toolChoice.toolName === 'web_search_preview'\n            ? { type: toolChoice.toolName }\n            : { type: 'function', name: toolChoice.toolName },\n        toolWarnings,\n      };\n    default: {\n      const _exhaustiveCheck: never = type;\n      throw new UnsupportedFunctionalityError({\n        functionality: `tool choice type: ${_exhaustiveCheck}`,\n      });\n    }\n  }\n}\n","import { SpeechModelV2, SpeechModelV2CallWarning } from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  createBinaryResponseHandler,\n  parseProviderOptions,\n  postJsonToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport { OpenAISpeechAPITypes } from './openai-speech-api-types';\nimport { OpenAISpeechModelId } from './openai-speech-options';\n\n// https://platform.openai.com/docs/api-reference/audio/createSpeech\nconst OpenAIProviderOptionsSchema = z.object({\n  instructions: z.string().nullish(),\n  speed: z.number().min(0.25).max(4.0).default(1.0).nullish(),\n});\n\nexport type OpenAISpeechCallOptions = z.infer<\n  typeof OpenAIProviderOptionsSchema\n>;\n\ninterface OpenAISpeechModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\nexport class OpenAISpeechModel implements SpeechModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAISpeechModelId,\n    private readonly config: OpenAISpeechModelConfig,\n  ) {}\n\n  private async getArgs({\n    text,\n    voice = 'alloy',\n    outputFormat = 'mp3',\n    speed,\n    instructions,\n    language,\n    providerOptions,\n  }: Parameters<SpeechModelV2['doGenerate']>[0]) {\n    const warnings: SpeechModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: OpenAIProviderOptionsSchema,\n    });\n\n    // Create request body\n    const requestBody: Record<string, unknown> = {\n      model: this.modelId,\n      input: text,\n      voice,\n      response_format: 'mp3',\n      speed,\n      instructions,\n    };\n\n    if (outputFormat) {\n      if (['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'].includes(outputFormat)) {\n        requestBody.response_format = outputFormat;\n      } else {\n        warnings.push({\n          type: 'unsupported-setting',\n          setting: 'outputFormat',\n          details: `Unsupported output format: ${outputFormat}. Using mp3 instead.`,\n        });\n      }\n    }\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const speechModelOptions: OpenAISpeechAPITypes = {};\n\n      for (const key in speechModelOptions) {\n        const value = speechModelOptions[key as keyof OpenAISpeechAPITypes];\n        if (value !== undefined) {\n          requestBody[key] = value;\n        }\n      }\n    }\n\n    if (language) {\n      warnings.push({\n        type: 'unsupported-setting',\n        setting: 'language',\n        details: `OpenAI speech models do not support language selection. Language parameter \"${language}\" was ignored.`,\n      });\n    }\n\n    return {\n      requestBody,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: Parameters<SpeechModelV2['doGenerate']>[0],\n  ): Promise<Awaited<ReturnType<SpeechModelV2['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { requestBody, warnings } = await this.getArgs(options);\n\n    const {\n      value: audio,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: '/audio/speech',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: requestBody,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createBinaryResponseHandler(),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    return {\n      audio,\n      warnings,\n      request: {\n        body: JSON.stringify(requestBody),\n      },\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n","import {\n  TranscriptionModelV2,\n  TranscriptionModelV2CallOptions,\n  TranscriptionModelV2CallWarning,\n} from '@ai-sdk/provider';\nimport {\n  combineHeaders,\n  convertBase64ToUint8Array,\n  createJsonResponseHandler,\n  mediaTypeToExtension,\n  parseProviderOptions,\n  postFormDataToApi,\n} from '@ai-sdk/provider-utils';\nimport { z } from 'zod/v4';\nimport { OpenAIConfig } from '../openai-config';\nimport { openaiFailedResponseHandler } from '../openai-error';\nimport {\n  OpenAITranscriptionModelId,\n  openAITranscriptionProviderOptions,\n  OpenAITranscriptionProviderOptions,\n} from './openai-transcription-options';\n\nexport type OpenAITranscriptionCallOptions = Omit<\n  TranscriptionModelV2CallOptions,\n  'providerOptions'\n> & {\n  providerOptions?: {\n    openai?: OpenAITranscriptionProviderOptions;\n  };\n};\n\ninterface OpenAITranscriptionModelConfig extends OpenAIConfig {\n  _internal?: {\n    currentDate?: () => Date;\n  };\n}\n\n// https://platform.openai.com/docs/guides/speech-to-text#supported-languages\nconst languageMap = {\n  afrikaans: 'af',\n  arabic: 'ar',\n  armenian: 'hy',\n  azerbaijani: 'az',\n  belarusian: 'be',\n  bosnian: 'bs',\n  bulgarian: 'bg',\n  catalan: 'ca',\n  chinese: 'zh',\n  croatian: 'hr',\n  czech: 'cs',\n  danish: 'da',\n  dutch: 'nl',\n  english: 'en',\n  estonian: 'et',\n  finnish: 'fi',\n  french: 'fr',\n  galician: 'gl',\n  german: 'de',\n  greek: 'el',\n  hebrew: 'he',\n  hindi: 'hi',\n  hungarian: 'hu',\n  icelandic: 'is',\n  indonesian: 'id',\n  italian: 'it',\n  japanese: 'ja',\n  kannada: 'kn',\n  kazakh: 'kk',\n  korean: 'ko',\n  latvian: 'lv',\n  lithuanian: 'lt',\n  macedonian: 'mk',\n  malay: 'ms',\n  marathi: 'mr',\n  maori: 'mi',\n  nepali: 'ne',\n  norwegian: 'no',\n  persian: 'fa',\n  polish: 'pl',\n  portuguese: 'pt',\n  romanian: 'ro',\n  russian: 'ru',\n  serbian: 'sr',\n  slovak: 'sk',\n  slovenian: 'sl',\n  spanish: 'es',\n  swahili: 'sw',\n  swedish: 'sv',\n  tagalog: 'tl',\n  tamil: 'ta',\n  thai: 'th',\n  turkish: 'tr',\n  ukrainian: 'uk',\n  urdu: 'ur',\n  vietnamese: 'vi',\n  welsh: 'cy',\n};\n\nexport class OpenAITranscriptionModel implements TranscriptionModelV2 {\n  readonly specificationVersion = 'v2';\n\n  get provider(): string {\n    return this.config.provider;\n  }\n\n  constructor(\n    readonly modelId: OpenAITranscriptionModelId,\n    private readonly config: OpenAITranscriptionModelConfig,\n  ) {}\n\n  private async getArgs({\n    audio,\n    mediaType,\n    providerOptions,\n  }: OpenAITranscriptionCallOptions) {\n    const warnings: TranscriptionModelV2CallWarning[] = [];\n\n    // Parse provider options\n    const openAIOptions = await parseProviderOptions({\n      provider: 'openai',\n      providerOptions,\n      schema: openAITranscriptionProviderOptions,\n    });\n\n    // Create form data with base fields\n    const formData = new FormData();\n    const blob =\n      audio instanceof Uint8Array\n        ? new Blob([audio])\n        : new Blob([convertBase64ToUint8Array(audio)]);\n\n    formData.append('model', this.modelId);\n    const fileExtension = mediaTypeToExtension(mediaType);\n    formData.append(\n      'file',\n      new File([blob], 'audio', { type: mediaType }),\n      `audio.${fileExtension}`,\n    );\n\n    // Add provider-specific options\n    if (openAIOptions) {\n      const transcriptionModelOptions = {\n        include: openAIOptions.include,\n        language: openAIOptions.language,\n        prompt: openAIOptions.prompt,\n        // https://platform.openai.com/docs/api-reference/audio/createTranscription#audio_createtranscription-response_format\n        // prefer verbose_json to get segments for models that support it\n        response_format: [\n          'gpt-4o-transcribe',\n          'gpt-4o-mini-transcribe',\n        ].includes(this.modelId)\n          ? 'json'\n          : 'verbose_json',\n        temperature: openAIOptions.temperature,\n        timestamp_granularities: openAIOptions.timestampGranularities,\n      };\n\n      for (const [key, value] of Object.entries(transcriptionModelOptions)) {\n        if (value != null) {\n          formData.append(key, String(value));\n        }\n      }\n    }\n\n    return {\n      formData,\n      warnings,\n    };\n  }\n\n  async doGenerate(\n    options: OpenAITranscriptionCallOptions,\n  ): Promise<Awaited<ReturnType<TranscriptionModelV2['doGenerate']>>> {\n    const currentDate = this.config._internal?.currentDate?.() ?? new Date();\n    const { formData, warnings } = await this.getArgs(options);\n\n    const {\n      value: response,\n      responseHeaders,\n      rawValue: rawResponse,\n    } = await postFormDataToApi({\n      url: this.config.url({\n        path: '/audio/transcriptions',\n        modelId: this.modelId,\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      formData,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiTranscriptionResponseSchema,\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch,\n    });\n\n    const language =\n      response.language != null && response.language in languageMap\n        ? languageMap[response.language as keyof typeof languageMap]\n        : undefined;\n\n    return {\n      text: response.text,\n      segments:\n        response.segments?.map(segment => ({\n          text: segment.text,\n          startSecond: segment.start,\n          endSecond: segment.end,\n        })) ??\n        response.words?.map(word => ({\n          text: word.word,\n          startSecond: word.start,\n          endSecond: word.end,\n        })) ??\n        [],\n      language,\n      durationInSeconds: response.duration ?? undefined,\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse,\n      },\n    };\n  }\n}\n\nconst openaiTranscriptionResponseSchema = z.object({\n  text: z.string(),\n  language: z.string().nullish(),\n  duration: z.number().nullish(),\n  words: z\n    .array(\n      z.object({\n        word: z.string(),\n        start: z.number(),\n        end: z.number(),\n      }),\n    )\n    .nullish(),\n  segments: z\n    .array(\n      z.object({\n        id: z.number(),\n        seek: z.number(),\n        start: z.number(),\n        end: z.number(),\n        text: z.string(),\n        tokens: z.array(z.number()),\n        temperature: z.number(),\n        avg_logprob: z.number(),\n        compression_ratio: z.number(),\n        no_speech_prob: z.number(),\n      }),\n    )\n    .nullish(),\n});\n","import { z } from 'zod/v4';\n\nexport type OpenAITranscriptionModelId =\n  | 'whisper-1'\n  | 'gpt-4o-mini-transcribe'\n  | 'gpt-4o-transcribe'\n  | (string & {});\n\n// https://platform.openai.com/docs/api-reference/audio/createTranscription\nexport const openAITranscriptionProviderOptions = z.object({\n  /**\n   * Additional information to include in the transcription response.\n   */\n\n  include: z.array(z.string()).optional(),\n\n  /**\n   * The language of the input audio in ISO-639-1 format.\n   */\n  language: z.string().optional(),\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio segment.\n   */\n  prompt: z.string().optional(),\n\n  /**\n   * The sampling temperature, between 0 and 1.\n   * @default 0\n   */\n  temperature: z.number().min(0).max(1).default(0).optional(),\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * @default ['segment']\n   */\n  timestampGranularities: z\n    .array(z.enum(['word', 'segment']))\n    .default(['segment'])\n    .optional(),\n});\n\nexport type OpenAITranscriptionProviderOptions = z.infer<\n  typeof openAITranscriptionProviderOptions\n>;\n"],"names":["z","z","UnsupportedFunctionalityError","z","createProviderDefinedToolFactory","z","openaiTools","UnsupportedFunctionalityError","openaiTools","toolCall","z","combineHeaders","createEventSourceResponseHandler","createJsonResponseHandler","parseProviderOptions","postJsonToApi","z","UnsupportedFunctionalityError","getResponseMetadata","mapOpenAIFinishReason","z","parseProviderOptions","postJsonToApi","combineHeaders","createJsonResponseHandler","mapOpenAIFinishReason","getResponseMetadata","createEventSourceResponseHandler","z","combineHeaders","createJsonResponseHandler","parseProviderOptions","postJsonToApi","z","z","parseProviderOptions","postJsonToApi","combineHeaders","createJsonResponseHandler","z","combineHeaders","createJsonResponseHandler","postJsonToApi","z","postJsonToApi","combineHeaders","createJsonResponseHandler","z","createProviderDefinedToolFactory","z","combineHeaders","createEventSourceResponseHandler","createJsonResponseHandler","generateId","parseProviderOptions","postJsonToApi","z","UnsupportedFunctionalityError","parseProviderOptions","z","convertToBase64","_a","_b","_c","UnsupportedFunctionalityError","openaiTools","UnsupportedFunctionalityError","z","parseProviderOptions","openaiTools","postJsonToApi","combineHeaders","createJsonResponseHandler","usageSchema","generateId","createEventSourceResponseHandler","supportsFlexProcessing","supportsPriorityProcessing","combineHeaders","parseProviderOptions","postJsonToApi","z","z","parseProviderOptions","postJsonToApi","combineHeaders","combineHeaders","createJsonResponseHandler","parseProviderOptions","z","z","parseProviderOptions","combineHeaders","createJsonResponseHandler","z"],"mappings":";;;;;;;AAQA;;ACRA;AAsBA,SAAS,KAAAA,UAAS;;;;;;;ACnBX,IAAM,wBAAwB,oLAAA,CAAE,MAAA,CAAO;IAC5C,OAAO,oLAAA,CAAE,MAAA,CAAO;QACd,SAAS,oLAAA,CAAE,MAAA,CAAO;QAAA,iEAAA;QAAA,iEAAA;QAAA,aAAA;QAKlB,MAAM,oLAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACzB,OAAO,oLAAA,CAAE,GAAA,CAAI,EAAE,OAAA,CAAQ;QACvB,MAAM,oLAAA,CAAE,KAAA,CAAM;YAAC,oLAAA,CAAE,MAAA,CAAO;YAAG,oLAAA,CAAE,MAAA,CAAO,CAAC;SAAC,EAAE,OAAA,CAAQ;IAClD,CAAC;AACH,CAAC;AAIM,IAAM,kCAA8B,sNAAA,EAA+B;IACxE,aAAa;IACb,gBAAgB,CAAA,OAAQ,KAAK,KAAA,CAAM,OAAA;AACrC,CAAC;;;ACbM,SAAS,4BAA4B,EAC1C,MAAA,EACA,oBAAoB,QAAA,EACtB,EAME;IACA,MAAM,WAA6B,CAAC,CAAA;IACpC,MAAM,WAA8C,CAAC,CAAA;IAErD,KAAA,MAAW,EAAE,IAAA,EAAM,OAAA,CAAQ,CAAA,IAAK,OAAQ;QACtC,OAAQ,MAAM;YACZ,KAAK;gBAAU;oBACb,OAAQ,mBAAmB;wBACzB,KAAK;4BAAU;gCACb,SAAS,IAAA,CAAK;oCAAE,MAAM;oCAAU;gCAAQ,CAAC;gCACzC;4BACF;wBACA,KAAK;4BAAa;gCAChB,SAAS,IAAA,CAAK;oCAAE,MAAM;oCAAa;gCAAQ,CAAC;gCAC5C;4BACF;wBACA,KAAK;4BAAU;gCACb,SAAS,IAAA,CAAK;oCACZ,MAAM;oCACN,SAAS;gCACX,CAAC;gCACD;4BACF;wBACA;4BAAS;gCACP,MAAM,mBAA0B;gCAChC,MAAM,IAAI,MACR,CAAA,iCAAA,EAAoC,gBAAgB,EAAA;4BAExD;oBACF;oBACA;gBACF;YAEA,KAAK;gBAAQ;oBACX,IAAI,QAAQ,MAAA,KAAW,KAAK,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA,KAAS,QAAQ;wBACtD,SAAS,IAAA,CAAK;4BAAE,MAAM;4BAAQ,SAAS,OAAA,CAAQ,CAAC,CAAA,CAAE,IAAA;wBAAK,CAAC;wBACxD;oBACF;oBAEA,SAAS,IAAA,CAAK;wBACZ,MAAM;wBACN,SAAS,QAAQ,GAAA,CAAI,CAAC,MAAM,UAAU;4BA1DhD,IAAA,IAAA,IAAA;4BA2DY,OAAQ,KAAK,IAAA,EAAM;gCACjB,KAAK;oCAAQ;wCACX,OAAO;4CAAE,MAAM;4CAAQ,MAAM,KAAK,IAAA;wCAAK;oCACzC;gCACA,KAAK;oCAAQ;wCACX,IAAI,KAAK,SAAA,CAAU,UAAA,CAAW,QAAQ,GAAG;4CACvC,MAAM,YACJ,KAAK,SAAA,KAAc,YACf,eACA,KAAK,SAAA;4CAEX,OAAO;gDACL,MAAM;gDACN,WAAW;oDACT,KACE,KAAK,IAAA,YAAgB,MACjB,KAAK,IAAA,CAAK,QAAA,CAAS,IACnB,CAAA,KAAA,EAAQ,SAAS,CAAA,QAAA,MAAW,uMAAA,EAAgB,KAAK,IAAI,CAAC,EAAA;oDAAA,0CAAA;oDAG5D,QAAA,CAAQ,KAAA,CAAA,KAAA,KAAK,eAAA,KAAL,OAAA,KAAA,IAAA,GAAsB,MAAA,KAAtB,OAAA,KAAA,IAAA,GAA8B,WAAA;gDACxC;4CACF;wCACF,OAAA,IAAW,KAAK,SAAA,CAAU,UAAA,CAAW,QAAQ,GAAG;4CAC9C,IAAI,KAAK,IAAA,YAAgB,KAAK;gDAC5B,MAAM,IAAI,4LAAA,CAA8B;oDACtC,eAAe;gDACjB,CAAC;4CACH;4CAEA,OAAQ,KAAK,SAAA,EAAW;gDACtB,KAAK;oDAAa;wDAChB,OAAO;4DACL,MAAM;4DACN,aAAa;gEACX,UAAM,uMAAA,EAAgB,KAAK,IAAI;gEAC/B,QAAQ;4DACV;wDACF;oDACF;gDACA,KAAK;gDACL,KAAK;oDAAc;wDACjB,OAAO;4DACL,MAAM;4DACN,aAAa;gEACX,UAAM,uMAAA,EAAgB,KAAK,IAAI;gEAC/B,QAAQ;4DACV;wDACF;oDACF;gDAEA;oDAAS;wDACP,MAAM,IAAI,4LAAA,CAA8B;4DACtC,eAAe,CAAA,oCAAA,EAAuC,KAAK,SAAS,EAAA;wDACtE,CAAC;oDACH;4CACF;wCACF,OAAA,IAAW,KAAK,SAAA,KAAc,mBAAmB;4CAC/C,IAAI,KAAK,IAAA,YAAgB,KAAK;gDAC5B,MAAM,IAAI,4LAAA,CAA8B;oDACtC,eAAe;gDACjB,CAAC;4CACH;4CAEA,OAAO;gDACL,MAAM;gDACN,MACE,OAAO,KAAK,IAAA,KAAS,YACrB,KAAK,IAAA,CAAK,UAAA,CAAW,OAAO,IACxB;oDAAE,SAAS,KAAK,IAAA;gDAAK,IACrB;oDACE,UAAA,CAAU,KAAA,KAAK,QAAA,KAAL,OAAA,KAAiB,CAAA,KAAA,EAAQ,KAAK,CAAA,IAAA,CAAA;oDACxC,WAAW,CAAA,4BAAA,MAA+B,uMAAA,EAAgB,KAAK,IAAI,CAAC,EAAA;gDACtE;4CACR;wCACF,OAAO;4CACL,MAAM,IAAI,4LAAA,CAA8B;gDACtC,eAAe,CAAA,qBAAA,EAAwB,KAAK,SAAS,EAAA;4CACvD,CAAC;wCACH;oCACF;4BACF;wBACF,CAAC;oBACH,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAa;oBAChB,IAAI,OAAO;oBACX,MAAM,YAID,CAAC,CAAA;oBAEN,KAAA,MAAW,QAAQ,QAAS;wBAC1B,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,QAAQ,KAAK,IAAA;oCACb;gCACF;4BACA,KAAK;gCAAa;oCAChB,UAAU,IAAA,CAAK;wCACb,IAAI,KAAK,UAAA;wCACT,MAAM;wCACN,UAAU;4CACR,MAAM,KAAK,QAAA;4CACX,WAAW,KAAK,SAAA,CAAU,KAAK,KAAK;wCACtC;oCACF,CAAC;oCACD;gCACF;wBACF;oBACF;oBAEA,SAAS,IAAA,CAAK;wBACZ,MAAM;wBACN,SAAS;wBACT,YAAY,UAAU,MAAA,GAAS,IAAI,YAAY,KAAA;oBACjD,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAQ;oBACX,KAAA,MAAW,gBAAgB,QAAS;wBAClC,MAAM,SAAS,aAAa,MAAA;wBAE5B,IAAI;wBACJ,OAAQ,OAAO,IAAA,EAAM;4BACnB,KAAK;4BACL,KAAK;gCACH,eAAe,OAAO,KAAA;gCACtB;4BACF,KAAK;4BACL,KAAK;4BACL,KAAK;gCACH,eAAe,KAAK,SAAA,CAAU,OAAO,KAAK;gCAC1C;wBACJ;wBAEA,SAAS,IAAA,CAAK;4BACZ,MAAM;4BACN,cAAc,aAAa,UAAA;4BAC3B,SAAS;wBACX,CAAC;oBACH;oBACA;gBACF;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,OAAO;QAAE;QAAU;IAAS;AAC9B;;AC1NO,SAAS,oBAAoB,EAClC,EAAA,EACA,KAAA,EACA,OAAA,EACF,EAIG;IACD,OAAO;QACL,IAAI,MAAA,OAAA,KAAM,KAAA;QACV,SAAS,SAAA,OAAA,QAAS,KAAA;QAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI,KAAA;IAC1D;AACF;;ACZO,SAAS,sBACd,YAAA,EAC6B;IAC7B,OAAQ,cAAc;QACpB,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;QACL,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;;ACuBO,IAAM,wBAAwBC,oLAAAA,CAAE,MAAA,CAAO;IAAA;;;;;GAAA,GAO5C,WAAWA,oLAAAA,CAAE,MAAA,CAAOA,oLAAAA,CAAE,MAAA,CAAO,MAAA,CAAe,GAAGA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,QAAA,CAAS;IAAA;;;;;;;;GAAA,GAWpE,UAAUA,oLAAAA,CAAE,KAAA,CAAM;QAACA,oLAAAA,CAAE,OAAA,CAAQ;QAAGA,oLAAAA,CAAE,MAAA,CAAO,CAAC;KAAC,EAAE,QAAA,CAAS;IAAA;;GAAA,GAKtD,mBAAmBA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IAAA;;;GAAA,GAMxC,MAAMA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;GAAA,GAK1B,iBAAiBA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAW;QAAO;QAAU,MAAM;KAAC,EAAE,QAAA,CAAS;IAAA;;GAAA,GAKvE,qBAAqBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;GAAA,GAKzC,OAAOA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IAAA;;GAAA,GAK5B,UAAUA,oLAAAA,CAAE,MAAA,CAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,EAAE,GAAGA,oLAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,GAAG,CAAC,EAAE,QAAA,CAAS;IAAA;;GAAA,GAKrE,YAAYA,oLAAAA,CAAE,MAAA,CAAOA,oLAAAA,CAAE,MAAA,CAAO,GAAGA,oLAAAA,CAAE,GAAA,CAAI,CAAC,EAAE,QAAA,CAAS;IAAA;;;;GAAA,GAOnD,mBAAmBA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IAAA;;;;;;;GAAA,GAUxC,aAAaA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAQ;QAAQ,UAAU;KAAC,EAAE,QAAA,CAAS;IAAA;;;;GAAA,GAO3D,kBAAkBA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IAAA;;;GAAA,GAMvC,eAAeA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAO;QAAU,MAAM;KAAC,EAAE,QAAA,CAAS;IAAA;;;GAAA,GAM1D,gBAAgBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;;;;;GAAA,GASpC,kBAAkBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;AACxC,CAAC;;;;AEzID,IAAM,yBAAyBE,oLAAAA,CAAE,MAAA,CAAO;IACtC,KAAKA,oLAAAA,CAAE,MAAA,CAAO;IACd,MAAMA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAM;QAAM;QAAM;QAAO;QAAM,KAAK;KAAC;IACnD,OAAOA,oLAAAA,CAAE,KAAA,CAAM;QAACA,oLAAAA,CAAE,MAAA,CAAO;QAAGA,oLAAAA,CAAE,MAAA,CAAO;QAAGA,oLAAAA,CAAE,OAAA,CAAQ,CAAC;KAAC;AACtD,CAAC;AAED,IAAM,uBAAuCA,oLAAAA,CAAE,MAAA,CAAO;IACpD,MAAMA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAO,IAAI;KAAC;IAC1B,SAASA,oLAAAA,CAAE,KAAA,CACTA,oLAAAA,CAAE,KAAA,CAAM;QAAC;QAAwBA,oLAAAA,CAAE,IAAA,CAAK,IAAM,oBAAoB,CAAC;KAAC;AAExE,CAAC;AAED,IAAM,gBAAgBA,oLAAAA,CAAE,KAAA,CAAM;IAAC;IAAwB,oBAAoB;CAAC;AAGrE,IAAM,uBAAuBA,oLAAAA,CAAE,MAAA,CAAO;IAAA;;GAAA,GAI3C,gBAAgBA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,QAAA,CAAS;IAAA;;GAAA,GAK7C,eAAeA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;GAAA,GAKnC,SAASA,oLAAAA,CACN,MAAA,CAAO;QACN,QAAQA,oLAAAA,CAAE,IAAA,CAAK;YAAC;YAAQ,oBAAoB;SAAC,EAAE,QAAA,CAAS;IAC1D,CAAC,EACA,QAAA,CAAS;IAAA;;GAAA,GAKZ,SAAS,cAAc,QAAA,CAAS;AAClC,CAAC;AAEM,IAAM,iBAAa,wNAAA,EAuCxB;IACA,IAAI;IACJ,MAAM;IACN,aAAaA,oLAAAA,CAAE,MAAA,CAAO;QACpB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;IAClB,CAAC;AACH,CAAC;;;ACvFM,IAAM,6BAA6BE,oLAAAA,CAAE,MAAA,CAAO;IAAA;;;;;GAAA,GAOjD,mBAAmBA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAO;QAAU,MAAM;KAAC,EAAE,QAAA,CAAS;IAAA;;GAAA,GAK9D,cAAcA,oLAAAA,CACX,MAAA,CAAO;QAAA;;KAAA,GAIN,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,aAAa;QAAA;;KAAA,GAI7B,SAASA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;QAAA;;KAAA,GAI7B,MAAMA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;QAAA;;KAAA,GAI1B,QAAQA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;QAAA;;KAAA,GAI5B,UAAUA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAChC,CAAC,EACA,QAAA,CAAS;AACd,CAAC;AAEM,IAAM,uBAAmBD,wNAAAA,EAuC9B;IACA,IAAI;IACJ,MAAM;IACN,aAAaC,oLAAAA,CAAE,MAAA,CAAO;QACpB,QAAQA,oLAAAA,CACL,kBAAA,CAAmB,QAAQ;YAC1BA,oLAAAA,CAAE,MAAA,CAAO;gBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,QAAQ;gBACxB,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,CAAC;YACDA,oLAAAA,CAAE,MAAA,CAAO;gBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;gBAC3B,KAAKA,oLAAAA,CAAE,MAAA,CAAO;YAChB,CAAC;YACDA,oLAAAA,CAAE,MAAA,CAAO;gBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,MAAM;gBACtB,KAAKA,oLAAAA,CAAE,MAAA,CAAO;gBACd,SAASA,oLAAAA,CAAE,MAAA,CAAO;YACpB,CAAC;SACF,EACA,OAAA,CAAQ;IACb,CAAC;AACH,CAAC;;AF9FM,SAAS,iBAAiB,EAC/B,KAAA,EACA,UAAA,EACA,iBAAA,EACA,gBAAA,EACF,EASE;IAEA,QAAA,CAAQ,SAAA,OAAA,KAAA,IAAA,MAAO,MAAA,IAAS,QAAQ,KAAA;IAEhC,MAAM,eAA6C,CAAC,CAAA;IAEpD,IAAI,SAAS,MAAM;QACjB,OAAO;YAAE,OAAO,KAAA;YAAW,YAAY,KAAA;YAAW;QAAa;IACjE;IAEA,MAAMC,eAA+B,CAAC,CAAA;IAEtC,KAAA,MAAW,QAAQ,MAAO;QACxB,OAAQ,KAAK,IAAA,EAAM;YACjB,KAAK;gBACHA,aAAY,IAAA,CAAK;oBACf,MAAM;oBACN,UAAU;wBACR,MAAM,KAAK,IAAA;wBACX,aAAa,KAAK,WAAA;wBAClB,YAAY,KAAK,WAAA;wBACjB,QAAQ,oBAAoB,mBAAmB,KAAA;oBACjD;gBACF,CAAC;gBACD;YACF,KAAK;gBACH,OAAQ,KAAK,EAAA,EAAI;oBACf,KAAK;wBAAsB;4BACzB,MAAM,OAAO,qBAAqB,KAAA,CAAM,KAAK,IAAI;4BACjDA,aAAY,IAAA,CAAK;gCACf,MAAM;gCACN,kBAAkB,KAAK,cAAA;gCACvB,iBAAiB,KAAK,aAAA;gCACtB,iBAAiB,KAAK,OAAA,GAClB;oCAAE,QAAQ,KAAK,OAAA,CAAQ,MAAA;gCAAO,IAC9B,KAAA;gCACJ,SAAS,KAAK,OAAA;4BAChB,CAAC;4BACD;wBACF;oBACA,KAAK;wBAA6B;4BAChC,MAAM,OAAO,2BAA2B,KAAA,CAAM,KAAK,IAAI;4BACvDA,aAAY,IAAA,CAAK;gCACf,MAAM;gCACN,qBAAqB,KAAK,iBAAA;gCAC1B,eAAe,KAAK,YAAA;4BACtB,CAAC;4BACD;wBACF;oBACA;wBACE,aAAa,IAAA,CAAK;4BAAE,MAAM;4BAAoB;wBAAK,CAAC;wBACpD;gBACJ;gBACA;YACF;gBACE,aAAa,IAAA,CAAK;oBAAE,MAAM;oBAAoB;gBAAK,CAAC;gBACpD;QACJ;IACF;IAEA,IAAI,cAAc,MAAM;QACtB,OAAO;YAAE,OAAOA;YAAa,YAAY,KAAA;YAAW;QAAa;IACnE;IAEA,MAAM,OAAO,WAAW,IAAA;IAExB,OAAQ,MAAM;QACZ,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO;gBAAE,OAAOA;gBAAa,YAAY;gBAAM;YAAa;QAC9D,KAAK;YACH,OAAO;gBACL,OAAOA;gBACP,YAAY;oBACV,MAAM;oBACN,UAAU;wBACR,MAAM,WAAW,QAAA;oBACnB;gBACF;gBACA;YACF;QACF;YAAS;gBACP,MAAM,mBAA0B;gBAChC,MAAM,IAAIC,4LAAAA,CAA8B;oBACtC,eAAe,CAAA,kBAAA,EAAqB,gBAAgB,EAAA;gBACtD,CAAC;YACH;IACF;AACF;;ANrEO,IAAM,0BAAN,MAAyD;IAW9D,YAAY,OAAA,EAA4B,MAAA,CAA0B;QAVlE,IAAA,CAAS,oBAAA,GAAuB;QAIhC,IAAA,CAAS,aAAA,GAAgB;YACvB,WAAW;gBAAC,iBAAiB;aAAA;QAC/B;QAKE,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,MAAA,GAAS;IAChB;IAEA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEA,MAAc,QAAQ,EACpB,MAAA,EACA,eAAA,EACA,WAAA,EACA,IAAA,EACA,IAAA,EACA,gBAAA,EACA,eAAA,EACA,aAAA,EACA,cAAA,EACA,IAAA,EACA,KAAA,EACA,UAAA,EACA,eAAA,EACF,EAA+B;QA7EjC,IAAA,IAAA,IAAA,IAAA;QA8EI,MAAM,WAAyC,CAAC,CAAA;QAGhD,MAAM,gBAAA,CACH,KAAA,UAAM,4MAAA,EAAqB;YAC1B,UAAU;YACV;YACA,QAAQ;QACV,CAAC,CAAA,KAJA,OAAA,KAIM,CAAC;QAEV,MAAM,oBAAA,CAAoB,KAAA,cAAc,iBAAA,KAAd,OAAA,KAAmC;QAE7D,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;YACX,CAAC;QACH;QAEA,IAAA,CACE,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,UACzB,eAAe,MAAA,IAAU,QACzB,CAAC,mBACD;YACA,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;QACH;QAEA,MAAM,EAAE,QAAA,EAAU,UAAU,eAAA,CAAgB,CAAA,GAAI,4BAC9C;YACE;YACA,mBAAmB,qBAAqB,IAAA,CAAK,OAAO;QACtD;QAGF,SAAS,IAAA,CAAK,GAAG,eAAe;QAEhC,MAAM,mBAAA,CAAmB,KAAA,cAAc,gBAAA,KAAd,OAAA,KAAkC;QAE3D,MAAM,WAAW;YAAA,YAAA;YAEf,OAAO,IAAA,CAAK,OAAA;YAAA,2BAAA;YAGZ,YAAY,cAAc,SAAA;YAC1B,UACE,cAAc,QAAA,KAAa,QAC3B,OAAO,cAAc,QAAA,KAAa,WAC9B,OACA,KAAA;YACN,cACE,OAAO,cAAc,QAAA,KAAa,WAC9B,cAAc,QAAA,GACd,OAAO,cAAc,QAAA,KAAa,YAChC,cAAc,QAAA,GACZ,IACA,KAAA,IACF,KAAA;YACR,MAAM,cAAc,IAAA;YACpB,qBAAqB,cAAc,iBAAA;YAAA,yBAAA;YAGnC,YAAY;YACZ;YACA,OAAO;YACP,mBAAmB;YACnB,kBAAkB;YAClB,iBAAA,CACE,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,SACrB,qBAAqB,eAAe,MAAA,IAAU,OAC5C;gBACE,MAAM;gBACN,aAAa;oBACX,QAAQ,eAAe,MAAA;oBACvB,QAAQ;oBACR,MAAA,CAAM,KAAA,eAAe,IAAA,KAAf,OAAA,KAAuB;oBAC7B,aAAa,eAAe,WAAA;gBAC9B;YACF,IACA;gBAAE,MAAM;YAAc,IACxB,KAAA;YACN,MAAM;YACN;YACA,WAAW,cAAc,aAAA;YAAA,4BAAA;YAAA,yDAAA;YAIzB,uBAAuB,cAAc,mBAAA;YACrC,OAAO,cAAc,KAAA;YACrB,UAAU,cAAc,QAAA;YACxB,YAAY,cAAc,UAAA;YAC1B,kBAAkB,cAAc,eAAA;YAChC,cAAc,cAAc,WAAA;YAC5B,kBAAkB,cAAc,cAAA;YAChC,mBAAmB,cAAc,gBAAA;YAAA,YAAA;YAGjC;QACF;QAEA,IAAI,iBAAiB,IAAA,CAAK,OAAO,GAAG;YAGlC,IAAI,SAAS,WAAA,IAAe,MAAM;gBAChC,SAAS,WAAA,GAAc,KAAA;gBACvB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;YACA,IAAI,SAAS,KAAA,IAAS,MAAM;gBAC1B,SAAS,KAAA,GAAQ,KAAA;gBACjB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;YACA,IAAI,SAAS,iBAAA,IAAqB,MAAM;gBACtC,SAAS,iBAAA,GAAoB,KAAA;gBAC7B,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;YACA,IAAI,SAAS,gBAAA,IAAoB,MAAM;gBACrC,SAAS,gBAAA,GAAmB,KAAA;gBAC5B,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;YACA,IAAI,SAAS,UAAA,IAAc,MAAM;gBAC/B,SAAS,UAAA,GAAa,KAAA;gBACtB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;gBACX,CAAC;YACH;YACA,IAAI,SAAS,QAAA,IAAY,MAAM;gBAC7B,SAAS,QAAA,GAAW,KAAA;gBACpB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;gBACX,CAAC;YACH;YACA,IAAI,SAAS,YAAA,IAAgB,MAAM;gBACjC,SAAS,YAAA,GAAe,KAAA;gBACxB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;gBACX,CAAC;YACH;YAGA,IAAI,SAAS,UAAA,IAAc,MAAM;gBAC/B,IAAI,SAAS,qBAAA,IAAyB,MAAM;oBAC1C,SAAS,qBAAA,GAAwB,SAAS,UAAA;gBAC5C;gBACA,SAAS,UAAA,GAAa,KAAA;YACxB;QACF,OAAA,IACE,IAAA,CAAK,OAAA,CAAQ,UAAA,CAAW,uBAAuB,KAC/C,IAAA,CAAK,OAAA,CAAQ,UAAA,CAAW,4BAA4B,GACpD;YACA,IAAI,SAAS,WAAA,IAAe,MAAM;gBAChC,SAAS,WAAA,GAAc,KAAA;gBACvB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SACE;gBACJ,CAAC;YACH;QACF;QAGA,IACE,cAAc,WAAA,KAAgB,UAC9B,CAAC,uBAAuB,IAAA,CAAK,OAAO,GACpC;YACA,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;YACD,SAAS,YAAA,GAAe,KAAA;QAC1B;QAGA,IACE,cAAc,WAAA,KAAgB,cAC9B,CAAC,2BAA2B,IAAA,CAAK,OAAO,GACxC;YACA,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;YACD,SAAS,YAAA,GAAe,KAAA;QAC1B;QAEA,MAAM,EACJ,OAAOC,YAAAA,EACP,YAAY,gBAAA,EACZ,YAAA,EACF,GAAI,iBAAiB;YACnB;YACA;YACA;YACA;QACF,CAAC;QAED,OAAO;YACL,MAAM;gBACJ,GAAG,QAAA;gBACH,OAAOA;gBACP,aAAa;YACf;YACA,UAAU,CAAC;mBAAG,UAAU;mBAAG,YAAY;aAAA;QACzC;IACF;IAEA,MAAM,WACJ,OAAA,EAC6D;QAxTjE,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;QAyTI,MAAM,EAAE,MAAM,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAE3D,MAAM,EACJ,eAAA,EACA,OAAO,QAAA,EACP,UAAU,WAAA,EACZ,GAAI,UAAM,qMAAA,EAAc;YACtB,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAAS,sMAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D;YACA,uBAAuB;YACvB,+BAA2B,iNAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,SAAS,SAAS,OAAA,CAAQ,CAAC,CAAA;QACjC,MAAM,UAAyC,CAAC,CAAA;QAGhD,MAAM,OAAO,OAAO,OAAA,CAAQ,OAAA;QAC5B,IAAI,QAAQ,QAAQ,KAAK,MAAA,GAAS,GAAG;YACnC,QAAQ,IAAA,CAAK;gBAAE,MAAM;gBAAQ;YAAK,CAAC;QACrC;QAGA,KAAA,MAAW,YAAA,CAAY,KAAA,OAAO,OAAA,CAAQ,UAAA,KAAf,OAAA,KAA6B,CAAC,CAAA,CAAG;YACtD,QAAQ,IAAA,CAAK;gBACX,MAAM;gBACN,YAAA,CAAY,KAAA,SAAS,EAAA,KAAT,OAAA,SAAe,kMAAA,CAAW;gBACtC,UAAU,SAAS,QAAA,CAAS,IAAA;gBAC5B,OAAO,SAAS,QAAA,CAAS,SAAA;YAC3B,CAAC;QACH;QAGA,KAAA,MAAW,cAAA,CAAc,KAAA,OAAO,OAAA,CAAQ,WAAA,KAAf,OAAA,KAA8B,CAAC,CAAA,CAAG;YACzD,QAAQ,IAAA,CAAK;gBACX,MAAM;gBACN,YAAY;gBACZ,QAAI,kMAAA,CAAW;gBACf,KAAK,WAAW,GAAA;gBAChB,OAAO,WAAW,KAAA;YACpB,CAAC;QACH;QAGA,MAAM,yBAAA,CAAyB,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,yBAAA;QAC/C,MAAM,qBAAA,CAAqB,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,qBAAA;QAC3C,MAAM,mBAA6C;YAAE,QAAQ,CAAC;QAAE;QAChE,IAAA,CAAI,0BAAA,OAAA,KAAA,IAAA,uBAAwB,0BAAA,KAA8B,MAAM;YAC9D,iBAAiB,MAAA,CAAO,wBAAA,GACtB,0BAAA,OAAA,KAAA,IAAA,uBAAwB,0BAAA;QAC5B;QACA,IAAA,CAAI,0BAAA,OAAA,KAAA,IAAA,uBAAwB,0BAAA,KAA8B,MAAM;YAC9D,iBAAiB,MAAA,CAAO,wBAAA,GACtB,0BAAA,OAAA,KAAA,IAAA,uBAAwB,0BAAA;QAC5B;QACA,IAAA,CAAA,CAAI,KAAA,OAAO,QAAA,KAAP,OAAA,KAAA,IAAA,GAAiB,OAAA,KAAW,MAAM;YACpC,iBAAiB,MAAA,CAAO,QAAA,GAAW,OAAO,QAAA,CAAS,OAAA;QACrD;QAEA,OAAO;YACL;YACA,cAAc,sBAAsB,OAAO,aAAa;YACxD,OAAO;gBACL,aAAA,CAAa,KAAA,CAAA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,aAAA,KAAhB,OAAA,KAAiC,KAAA;gBAC9C,cAAA,CAAc,KAAA,CAAA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,iBAAA,KAAhB,OAAA,KAAqC,KAAA;gBACnD,aAAA,CAAa,KAAA,CAAA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,YAAA,KAAhB,OAAA,KAAgC,KAAA;gBAC7C,iBAAA,CAAiB,KAAA,0BAAA,OAAA,KAAA,IAAA,uBAAwB,gBAAA,KAAxB,OAAA,KAA4C,KAAA;gBAC7D,mBAAA,CAAmB,KAAA,sBAAA,OAAA,KAAA,IAAA,mBAAoB,aAAA,KAApB,OAAA,KAAqC,KAAA;YAC1D;YACA,SAAS;gBAAE;YAAK;YAChB,UAAU;gBACR,GAAG,oBAAoB,QAAQ,CAAA;gBAC/B,SAAS;gBACT,MAAM;YACR;YACA;YACA;QACF;IACF;IAEA,MAAM,SACJ,OAAA,EAC2D;QAC3D,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAErD,MAAM,OAAO;YACX,GAAG,IAAA;YACH,QAAQ;YACR,gBAAgB;gBACd,eAAe;YACjB;QACF;QAEA,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,UAAM,qMAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAAS,sMAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D;YACA,uBAAuB;YACvB,+BAA2B,wNAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,YAQD,CAAC,CAAA;QAEN,IAAI,eAA4C;QAChD,MAAM,QAA8B;YAClC,aAAa,KAAA;YACb,cAAc,KAAA;YACd,aAAa,KAAA;QACf;QACA,IAAI,eAAe;QACnB,IAAI,eAAe;QAEnB,MAAM,mBAA6C;YAAE,QAAQ,CAAC;QAAE;QAEhE,OAAO;YACL,QAAQ,SAAS,WAAA,CACf,IAAI,gBAGF;gBACA,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAgB;oBAAS,CAAC;gBACvD;gBAEA,WAAU,KAAA,EAAO,UAAA,EAAY;oBA5cvC,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;oBA6cY,IAAI,QAAQ,gBAAA,EAAkB;wBAC5B,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAO,UAAU,MAAM,QAAA;wBAAS,CAAC;oBAC9D;oBAGA,IAAI,CAAC,MAAM,OAAA,EAAS;wBAClB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,MAAM,QAAQ,MAAM,KAAA;oBAGpB,IAAI,WAAW,OAAO;wBACpB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,IAAI,cAAc;wBAChB,eAAe;wBAEf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,GAAG,oBAAoB,KAAK,CAAA;wBAC9B,CAAC;oBACH;oBAEA,IAAI,MAAM,KAAA,IAAS,MAAM;wBACvB,MAAM,WAAA,GAAA,CAAc,KAAA,MAAM,KAAA,CAAM,aAAA,KAAZ,OAAA,KAA6B,KAAA;wBACjD,MAAM,YAAA,GAAA,CAAe,KAAA,MAAM,KAAA,CAAM,iBAAA,KAAZ,OAAA,KAAiC,KAAA;wBACtD,MAAM,WAAA,GAAA,CAAc,KAAA,MAAM,KAAA,CAAM,YAAA,KAAZ,OAAA,KAA4B,KAAA;wBAChD,MAAM,eAAA,GAAA,CACJ,KAAA,CAAA,KAAA,MAAM,KAAA,CAAM,yBAAA,KAAZ,OAAA,KAAA,IAAA,GAAuC,gBAAA,KAAvC,OAAA,KACA,KAAA;wBACF,MAAM,iBAAA,GAAA,CACJ,KAAA,CAAA,KAAA,MAAM,KAAA,CAAM,qBAAA,KAAZ,OAAA,KAAA,IAAA,GAAmC,aAAA,KAAnC,OAAA,KAAoD,KAAA;wBAEtD,IAAA,CAAA,CACE,KAAA,MAAM,KAAA,CAAM,yBAAA,KAAZ,OAAA,KAAA,IAAA,GACI,0BAAA,KAA8B,MAClC;4BACA,iBAAiB,MAAA,CAAO,wBAAA,GAAA,CACtB,KAAA,MAAM,KAAA,CAAM,yBAAA,KAAZ,OAAA,KAAA,IAAA,GAAuC,0BAAA;wBAC3C;wBACA,IAAA,CAAA,CACE,KAAA,MAAM,KAAA,CAAM,yBAAA,KAAZ,OAAA,KAAA,IAAA,GACI,0BAAA,KAA8B,MAClC;4BACA,iBAAiB,MAAA,CAAO,wBAAA,GAAA,CACtB,KAAA,MAAM,KAAA,CAAM,yBAAA,KAAZ,OAAA,KAAA,IAAA,GAAuC,0BAAA;wBAC3C;oBACF;oBAEA,MAAM,SAAS,MAAM,OAAA,CAAQ,CAAC,CAAA;oBAE9B,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,aAAA,KAAiB,MAAM;wBACjC,eAAe,sBAAsB,OAAO,aAAa;oBAC3D;oBAEA,IAAA,CAAA,CAAI,KAAA,UAAA,OAAA,KAAA,IAAA,OAAQ,QAAA,KAAR,OAAA,KAAA,IAAA,GAAkB,OAAA,KAAW,MAAM;wBACrC,iBAAiB,MAAA,CAAO,QAAA,GAAW,OAAO,QAAA,CAAS,OAAA;oBACrD;oBAEA,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,KAAA,KAAS,MAAM;wBACzB;oBACF;oBAEA,MAAM,QAAQ,OAAO,KAAA;oBAErB,IAAI,MAAM,OAAA,IAAW,MAAM;wBACzB,IAAI,CAAC,cAAc;4BACjB,WAAW,OAAA,CAAQ;gCAAE,MAAM;gCAAc,IAAI;4BAAI,CAAC;4BAClD,eAAe;wBACjB;wBAEA,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,IAAI;4BACJ,OAAO,MAAM,OAAA;wBACf,CAAC;oBACH;oBAEA,IAAI,MAAM,UAAA,IAAc,MAAM;wBAC5B,KAAA,MAAW,iBAAiB,MAAM,UAAA,CAAY;4BAC5C,MAAM,QAAQ,cAAc,KAAA;4BAG5B,IAAI,SAAA,CAAU,KAAK,CAAA,IAAK,MAAM;gCAC5B,IAAI,cAAc,IAAA,KAAS,YAAY;oCACrC,MAAM,IAAI,uLAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,yBAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,IAAI,cAAc,EAAA,IAAM,MAAM;oCAC5B,MAAM,IAAI,uLAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,6BAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,IAAA,CAAA,CAAI,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,IAAA,KAAQ,MAAM;oCACxC,MAAM,IAAI,uLAAA,CAAyB;wCACjC,MAAM;wCACN,SAAS,CAAA,wCAAA,CAAA;oCACX,CAAC;gCACH;gCAEA,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,IAAI,cAAc,EAAA;oCAClB,UAAU,cAAc,QAAA,CAAS,IAAA;gCACnC,CAAC;gCAED,SAAA,CAAU,KAAK,CAAA,GAAI;oCACjB,IAAI,cAAc,EAAA;oCAClB,MAAM;oCACN,UAAU;wCACR,MAAM,cAAc,QAAA,CAAS,IAAA;wCAC7B,WAAA,CAAW,KAAA,cAAc,QAAA,CAAS,SAAA,KAAvB,OAAA,KAAoC;oCACjD;oCACA,aAAa;gCACf;gCAEA,MAAMC,YAAW,SAAA,CAAU,KAAK,CAAA;gCAEhC,IAAA,CAAA,CACE,KAAAA,UAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,IAAA,KAAQ,QAAA,CAAA,CAC3B,KAAAA,UAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,SAAA,KAAa,MAChC;oCAEA,IAAIA,UAAS,QAAA,CAAS,SAAA,CAAU,MAAA,GAAS,GAAG;wCAC1C,WAAW,OAAA,CAAQ;4CACjB,MAAM;4CACN,IAAIA,UAAS,EAAA;4CACb,OAAOA,UAAS,QAAA,CAAS,SAAA;wCAC3B,CAAC;oCACH;oCAIA,QAAI,sMAAA,EAAeA,UAAS,QAAA,CAAS,SAAS,GAAG;wCAC/C,WAAW,OAAA,CAAQ;4CACjB,MAAM;4CACN,IAAIA,UAAS,EAAA;wCACf,CAAC;wCAED,WAAW,OAAA,CAAQ;4CACjB,MAAM;4CACN,YAAA,CAAY,KAAAA,UAAS,EAAA,KAAT,OAAA,SAAe,kMAAA,CAAW;4CACtC,UAAUA,UAAS,QAAA,CAAS,IAAA;4CAC5B,OAAOA,UAAS,QAAA,CAAS,SAAA;wCAC3B,CAAC;wCACDA,UAAS,WAAA,GAAc;oCACzB;gCACF;gCAEA;4BACF;4BAGA,MAAM,WAAW,SAAA,CAAU,KAAK,CAAA;4BAEhC,IAAI,SAAS,WAAA,EAAa;gCACxB;4BACF;4BAEA,IAAA,CAAA,CAAI,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,SAAA,KAAa,MAAM;gCAC7C,SAAS,QAAA,CAAU,SAAA,IAAA,CACjB,KAAA,CAAA,KAAA,cAAc,QAAA,KAAd,OAAA,KAAA,IAAA,GAAwB,SAAA,KAAxB,OAAA,KAAqC;4BACzC;4BAGA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,SAAS,EAAA;gCACb,OAAA,CAAO,KAAA,cAAc,QAAA,CAAS,SAAA,KAAvB,OAAA,KAAoC;4BAC7C,CAAC;4BAGD,IAAA,CAAA,CACE,KAAA,SAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,IAAA,KAAQ,QAAA,CAAA,CAC3B,KAAA,SAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,SAAA,KAAa,YAChC,sMAAA,EAAe,SAAS,QAAA,CAAS,SAAS,GAC1C;gCACA,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,IAAI,SAAS,EAAA;gCACf,CAAC;gCAED,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,YAAA,CAAY,KAAA,SAAS,EAAA,KAAT,OAAA,SAAe,kMAAA,CAAW;oCACtC,UAAU,SAAS,QAAA,CAAS,IAAA;oCAC5B,OAAO,SAAS,QAAA,CAAS,SAAA;gCAC3B,CAAC;gCACD,SAAS,WAAA,GAAc;4BACzB;wBACF;oBACF;oBAGA,IAAI,MAAM,WAAA,IAAe,MAAM;wBAC7B,KAAA,MAAW,cAAc,MAAM,WAAA,CAAa;4BAC1C,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY;gCACZ,QAAI,kMAAA,CAAW;gCACf,KAAK,WAAW,GAAA;gCAChB,OAAO,WAAW,KAAA;4BACpB,CAAC;wBACH;oBACF;gBACF;gBAEA,OAAM,UAAA,EAAY;oBAChB,IAAI,cAAc;wBAChB,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAY,IAAI;wBAAI,CAAC;oBAClD;oBAEA,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN;wBACA;wBACA,GAAI,oBAAoB,OAAO;4BAAE;wBAAiB,IAAI,CAAC,CAAA;oBACzD,CAAC;gBACH;YACF,CAAC;YAEH,SAAS;gBAAE;YAAK;YAChB,UAAU;gBAAE,SAAS;YAAgB;QACvC;IACF;AACF;AAEA,IAAM,yBAAyBC,oLAAAA,CAC5B,MAAA,CAAO;IACN,eAAeA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAClC,mBAAmBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACtC,cAAcA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACjC,uBAAuBA,oLAAAA,CACpB,MAAA,CAAO;QACN,eAAeA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACpC,CAAC,EACA,OAAA,CAAQ;IACX,2BAA2BA,oLAAAA,CACxB,MAAA,CAAO;QACN,kBAAkBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACrC,4BAA4BA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAC/C,4BAA4BA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACjD,CAAC,EACA,OAAA,CAAQ;AACb,CAAC,EACA,OAAA,CAAQ;AAIX,IAAM,2BAA2BA,oLAAAA,CAAE,MAAA,CAAO;IACxC,IAAIA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACvB,SAASA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC5B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC1B,SAASA,oLAAAA,CAAE,KAAA,CACTA,oLAAAA,CAAE,MAAA,CAAO;QACP,SAASA,oLAAAA,CAAE,MAAA,CAAO;YAChB,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,WAAW,EAAE,OAAA,CAAQ;YACrC,SAASA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC5B,YAAYA,oLAAAA,CACT,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;gBACP,IAAIA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBACvB,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,UAAU;gBAC1B,UAAUA,oLAAAA,CAAE,MAAA,CAAO;oBACjB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;oBACf,WAAWA,oLAAAA,CAAE,MAAA,CAAO;gBACtB,CAAC;YACH,CAAC,GAEF,OAAA,CAAQ;YACX,aAAaA,oLAAAA,CACV,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;gBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,cAAc;gBAC9B,aAAaA,oLAAAA,CAAE,MAAA,CAAO;gBACtB,WAAWA,oLAAAA,CAAE,MAAA,CAAO;gBACpB,KAAKA,oLAAAA,CAAE,MAAA,CAAO;gBACd,OAAOA,oLAAAA,CAAE,MAAA,CAAO;YAClB,CAAC,GAEF,OAAA,CAAQ;QACb,CAAC;QACD,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAChB,UAAUA,oLAAAA,CACP,MAAA,CAAO;YACN,SAASA,oLAAAA,CACN,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;gBACP,OAAOA,oLAAAA,CAAE,MAAA,CAAO;gBAChB,SAASA,oLAAAA,CAAE,MAAA,CAAO;gBAClB,cAAcA,oLAAAA,CAAE,KAAA,CACdA,oLAAAA,CAAE,MAAA,CAAO;oBACP,OAAOA,oLAAAA,CAAE,MAAA,CAAO;oBAChB,SAASA,oLAAAA,CAAE,MAAA,CAAO;gBACpB,CAAC;YAEL,CAAC,GAEF,OAAA,CAAQ;QACb,CAAC,EACA,OAAA,CAAQ;QACX,eAAeA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACpC,CAAC;IAEH,OAAO;AACT,CAAC;AAID,IAAM,wBAAwBA,oLAAAA,CAAE,KAAA,CAAM;IACpCA,oLAAAA,CAAE,MAAA,CAAO;QACP,IAAIA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACvB,SAASA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAC5B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAC1B,SAASA,oLAAAA,CAAE,KAAA,CACTA,oLAAAA,CAAE,MAAA,CAAO;YACP,OAAOA,oLAAAA,CACJ,MAAA,CAAO;gBACN,MAAMA,oLAAAA,CAAE,IAAA,CAAK;oBAAC,WAAW;iBAAC,EAAE,OAAA,CAAQ;gBACpC,SAASA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBAC5B,YAAYA,oLAAAA,CACT,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;oBACP,OAAOA,oLAAAA,CAAE,MAAA,CAAO;oBAChB,IAAIA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oBACvB,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,UAAU,EAAE,OAAA,CAAQ;oBACpC,UAAUA,oLAAAA,CAAE,MAAA,CAAO;wBACjB,MAAMA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;wBACzB,WAAWA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oBAChC,CAAC;gBACH,CAAC,GAEF,OAAA,CAAQ;gBACX,aAAaA,oLAAAA,CACV,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;oBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,cAAc;oBAC9B,aAAaA,oLAAAA,CAAE,MAAA,CAAO;oBACtB,WAAWA,oLAAAA,CAAE,MAAA,CAAO;oBACpB,KAAKA,oLAAAA,CAAE,MAAA,CAAO;oBACd,OAAOA,oLAAAA,CAAE,MAAA,CAAO;gBAClB,CAAC,GAEF,OAAA,CAAQ;YACb,CAAC,EACA,OAAA,CAAQ;YACX,UAAUA,oLAAAA,CACP,MAAA,CAAO;gBACN,SAASA,oLAAAA,CACN,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;oBACP,OAAOA,oLAAAA,CAAE,MAAA,CAAO;oBAChB,SAASA,oLAAAA,CAAE,MAAA,CAAO;oBAClB,cAAcA,oLAAAA,CAAE,KAAA,CACdA,oLAAAA,CAAE,MAAA,CAAO;wBACP,OAAOA,oLAAAA,CAAE,MAAA,CAAO;wBAChB,SAASA,oLAAAA,CAAE,MAAA,CAAO;oBACpB,CAAC;gBAEL,CAAC,GAEF,OAAA,CAAQ;YACb,CAAC,EACA,OAAA,CAAQ;YACX,eAAeA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAClC,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAClB,CAAC;QAEH,OAAO;IACT,CAAC;IACD;CACD;AAED,SAAS,iBAAiB,OAAA,EAAiB;IACzC,OAAA,CACG,QAAQ,UAAA,CAAW,GAAG,KAAK,QAAQ,UAAA,CAAW,OAAO,CAAA,KACtD,CAAC,QAAQ,UAAA,CAAW,YAAY;AAEpC;AAEA,SAAS,uBAAuB,OAAA,EAAiB;IAC/C,OACE,QAAQ,UAAA,CAAW,IAAI,KACvB,QAAQ,UAAA,CAAW,SAAS,KAC3B,QAAQ,UAAA,CAAW,OAAO,KAAK,CAAC,QAAQ,UAAA,CAAW,YAAY;AAEpE;AAEA,SAAS,2BAA2B,OAAA,EAAiB;IACnD,OACE,QAAQ,UAAA,CAAW,OAAO,KAC1B,QAAQ,UAAA,CAAW,YAAY,KAC9B,QAAQ,UAAA,CAAW,OAAO,KACzB,CAAC,QAAQ,UAAA,CAAW,YAAY,KAChC,CAAC,QAAQ,UAAA,CAAW,YAAY,KAClC,QAAQ,UAAA,CAAW,IAAI,KACvB,QAAQ,UAAA,CAAW,SAAS;AAEhC;AAEA,SAAS,qBAAqB,OAAA,EAAiB;IAx2B/C,IAAA,IAAA;IAy2BE,IAAI,CAAC,iBAAiB,OAAO,GAAG;QAC9B,OAAO;IACT;IAEA,OAAA,CACE,KAAA,CAAA,KAAA,eAAA,CAAgB,OAAuC,CAAA,KAAvD,OAAA,KAAA,IAAA,GACI,iBAAA,KADJ,OAAA,KACyB;AAE7B;AAEA,IAAM,kBAAkB;IACtB,WAAW;QACT,mBAAmB;IACrB;IACA,sBAAsB;QACpB,mBAAmB;IACrB;IACA,cAAc;QACZ,mBAAmB;IACrB;IACA,yBAAyB;QACvB,mBAAmB;IACrB;IACA,IAAI;QACF,mBAAmB;IACrB;IACA,iBAAiB;QACf,mBAAmB;IACrB;IACA,WAAW;QACT,mBAAmB;IACrB;IACA,sBAAsB;QACpB,mBAAmB;IACrB;IACA,WAAW;QACT,mBAAmB;IACrB;IACA,sBAAsB;QACpB,mBAAmB;IACrB;AACF;;;;AU54BO,SAAS,gCAAgC,EAC9C,MAAA,EACA,OAAO,MAAA,EACP,YAAY,WAAA,EACd,EAOE;IAEA,IAAI,OAAO;IAGX,IAAI,MAAA,CAAO,CAAC,CAAA,CAAE,IAAA,KAAS,UAAU;QAC/B,QAAQ,GAAG,MAAA,CAAO,CAAC,CAAA,CAAE,OAAO,CAAA;;AAAA,CAAA;QAC5B,SAAS,OAAO,KAAA,CAAM,CAAC;IACzB;IAEA,KAAA,MAAW,EAAE,IAAA,EAAM,OAAA,CAAQ,CAAA,IAAK,OAAQ;QACtC,OAAQ,MAAM;YACZ,KAAK;gBAAU;oBACb,MAAM,IAAI,iLAAA,CAAmB;wBAC3B,SAAS;wBACT;oBACF,CAAC;gBACH;YAEA,KAAK;gBAAQ;oBACX,MAAM,cAAc,QACjB,GAAA,CAAI,CAAA,SAAQ;wBACX,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,OAAO,KAAK,IAAA;gCACd;wBACF;oBACF,CAAC,EACA,MAAA,CAAO,OAAO,EACd,IAAA,CAAK,EAAE;oBAEV,QAAQ,GAAG,IAAI,CAAA;AAAA,EAAM,WAAW,CAAA;;AAAA,CAAA;oBAChC;gBACF;YAEA,KAAK;gBAAa;oBAChB,MAAM,mBAAmB,QACtB,GAAA,CAAI,CAAA,SAAQ;wBACX,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,OAAO,KAAK,IAAA;gCACd;4BACA,KAAK;gCAAa;oCAChB,MAAM,IAAIO,4LAAAA,CAA8B;wCACtC,eAAe;oCACjB,CAAC;gCACH;wBACF;oBACF,CAAC,EACA,IAAA,CAAK,EAAE;oBAEV,QAAQ,GAAG,SAAS,CAAA;AAAA,EAAM,gBAAgB,CAAA;;AAAA,CAAA;oBAC1C;gBACF;YAEA,KAAK;gBAAQ;oBACX,MAAM,IAAIA,4LAAAA,CAA8B;wBACtC,eAAe;oBACjB,CAAC;gBACH;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAGA,QAAQ,GAAG,SAAS,CAAA;AAAA,CAAA;IAEpB,OAAO;QACL,QAAQ;QACR,eAAe;YAAC,CAAA;AAAA,EAAK,IAAI,CAAA,CAAA,CAAG;SAAA;IAC9B;AACF;;AC5FO,SAASC,qBAAoB,EAClC,EAAA,EACA,KAAA,EACA,OAAA,EACF,EAIG;IACD,OAAO;QACL,IAAI,MAAA,OAAA,KAAM,KAAA;QACV,SAAS,SAAA,OAAA,QAAS,KAAA;QAClB,WAAW,WAAW,OAAO,IAAI,KAAK,UAAU,GAAI,IAAI,KAAA;IAC1D;AACF;;ACZO,SAASC,uBACd,YAAA,EAC6B;IAC7B,OAAQ,cAAc;QACpB,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT,KAAK;QACL,KAAK;YACH,OAAO;QACT;YACE,OAAO;IACX;AACF;;ACbO,IAAM,kCAAkCC,oLAAAA,CAAE,MAAA,CAAO;IAAA;;KAAA,GAItD,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,QAAA,CAAS;IAAA;;;;;;;;;;;;;GAAA,GAgB3B,WAAWA,oLAAAA,CAAE,MAAA,CAAOA,oLAAAA,CAAE,MAAA,CAAO,GAAGA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,QAAA,CAAS;IAAA;;GAAA,GAKrD,QAAQA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;;GAAA,GAM5B,MAAMA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;;;;;;;KAAA,GAW1B,UAAUA,oLAAAA,CAAE,KAAA,CAAM;QAACA,oLAAAA,CAAE,OAAA,CAAQ;QAAGA,oLAAAA,CAAE,MAAA,CAAO,CAAC;KAAC,EAAE,QAAA,CAAS;AACxD,CAAC;;AJXM,IAAM,gCAAN,MAA+D;IAWpE,YACE,OAAA,EACA,MAAA,CACA;QAbF,IAAA,CAAS,oBAAA,GAAuB;QAsBhC,IAAA,CAAS,aAAA,GAA0C;QAEnD;QAVE,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,MAAA,GAAS;IAChB;IAVA,IAAY,sBAA8B;QACxC,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA,CAAS,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CAAA,CAAE,IAAA,CAAK;IACjD;IAUA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAMA,MAAc,QAAQ,EACpB,MAAA,EACA,eAAA,EACA,WAAA,EACA,IAAA,EACA,IAAA,EACA,gBAAA,EACA,eAAA,EACA,eAAe,iBAAA,EACf,cAAA,EACA,KAAA,EACA,UAAA,EACA,IAAA,EACA,eAAA,EACF,EAAiD;QAC/C,MAAM,WAAyC,CAAC,CAAA;QAGhD,MAAM,gBAAgB;YACpB,GAAI,UAAMC,4MAAAA,EAAqB;gBAC7B,UAAU;gBACV;gBACA,QAAQ;YACV,CAAC,CAAA;YACD,GAAI,UAAMA,4MAAAA,EAAqB;gBAC7B,UAAU,IAAA,CAAK,mBAAA;gBACf;gBACA,QAAQ;YACV,CAAC,CAAA;QACH;QAEA,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBAAE,MAAM;gBAAuB,SAAS;YAAO,CAAC;QAChE;QAEA,IAAI,SAAA,OAAA,KAAA,IAAA,MAAO,MAAA,EAAQ;YACjB,SAAS,IAAA,CAAK;gBAAE,MAAM;gBAAuB,SAAS;YAAQ,CAAC;QACjE;QAEA,IAAI,cAAc,MAAM;YACtB,SAAS,IAAA,CAAK;gBAAE,MAAM;gBAAuB,SAAS;YAAa,CAAC;QACtE;QAEA,IAAI,kBAAkB,QAAQ,eAAe,IAAA,KAAS,QAAQ;YAC5D,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SAAS;YACX,CAAC;QACH;QAEA,MAAM,EAAE,QAAQ,gBAAA,EAAkB,aAAA,CAAc,CAAA,GAC9C,gCAAgC;YAAE;QAAO,CAAC;QAE5C,MAAM,OAAO,CAAC;eAAI,iBAAA,OAAA,gBAAiB,CAAC,CAAA,EAAI;eAAI,qBAAA,OAAA,oBAAqB,CAAC,CAAE;SAAA;QAEpE,OAAO;YACL,MAAM;gBAAA,YAAA;gBAEJ,OAAO,IAAA,CAAK,OAAA;gBAAA,2BAAA;gBAGZ,MAAM,cAAc,IAAA;gBACpB,YAAY,cAAc,SAAA;gBAC1B,UAAA,CACE,iBAAA,OAAA,KAAA,IAAA,cAAe,QAAA,MAAa,OACxB,IAAA,CACA,iBAAA,OAAA,KAAA,IAAA,cAAe,QAAA,MAAa,QAC1B,KAAA,IACA,iBAAA,OAAA,KAAA,IAAA,cAAe,QAAA;gBACvB,QAAQ,cAAc,MAAA;gBACtB,MAAM,cAAc,IAAA;gBAAA,yBAAA;gBAGpB,YAAY;gBACZ;gBACA,OAAO;gBACP,mBAAmB;gBACnB,kBAAkB;gBAClB;gBAAA,UAAA;gBAGA,QAAQ;gBAAA,kBAAA;gBAGR,MAAM,KAAK,MAAA,GAAS,IAAI,OAAO,KAAA;YACjC;YACA;QACF;IACF;IAEA,MAAM,WACJ,OAAA,EAC6D;QA7JjE,IAAA,IAAA,IAAA;QA8JI,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAErD,MAAM,EACJ,eAAA,EACA,OAAO,QAAA,EACP,UAAU,WAAA,EACZ,GAAI,UAAMC,qMAAAA,EAAc;YACtB,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;YACN,uBAAuB;YACvB,+BAA2BC,iNAAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,SAAS,SAAS,OAAA,CAAQ,CAAC,CAAA;QAEjC,MAAM,mBAA6C;YAAE,QAAQ,CAAC;QAAE;QAEhE,IAAI,OAAO,QAAA,IAAY,MAAM;YAC3B,iBAAiB,MAAA,CAAO,QAAA,GAAW,OAAO,QAAA;QAC5C;QAEA,OAAO;YACL,SAAS;gBAAC;oBAAE,MAAM;oBAAQ,MAAM,OAAO,IAAA;gBAAK,CAAC;aAAA;YAC7C,OAAO;gBACL,aAAA,CAAa,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,aAAA;gBAC7B,cAAA,CAAc,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,iBAAA;gBAC9B,aAAA,CAAa,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,YAAA;YAC/B;YACA,cAAcC,uBAAsB,OAAO,aAAa;YACxD,SAAS;gBAAE,MAAM;YAAK;YACtB,UAAU;gBACR,GAAGC,qBAAoB,QAAQ,CAAA;gBAC/B,SAAS;gBACT,MAAM;YACR;YACA;YACA;QACF;IACF;IAEA,MAAM,SACJ,OAAA,EAC2D;QAC3D,MAAM,EAAE,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAErD,MAAM,OAAO;YACX,GAAG,IAAA;YACH,QAAQ;YAER,gBAAgB;gBACd,eAAe;YACjB;QACF;QAEA,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,UAAMJ,qMAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D;YACA,uBAAuB;YACvB,+BAA2BI,wNAAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,IAAI,eAA4C;QAChD,MAAM,mBAA6C;YAAE,QAAQ,CAAC;QAAE;QAChE,MAAM,QAA8B;YAClC,aAAa,KAAA;YACb,cAAc,KAAA;YACd,aAAa,KAAA;QACf;QACA,IAAI,eAAe;QAEnB,OAAO;YACL,QAAQ,SAAS,WAAA,CACf,IAAI,gBAGF;gBACA,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAgB;oBAAS,CAAC;gBACvD;gBAEA,WAAU,KAAA,EAAO,UAAA,EAAY;oBAC3B,IAAI,QAAQ,gBAAA,EAAkB;wBAC5B,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAO,UAAU,MAAM,QAAA;wBAAS,CAAC;oBAC9D;oBAGA,IAAI,CAAC,MAAM,OAAA,EAAS;wBAClB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,MAAM,QAAQ,MAAM,KAAA;oBAGpB,IAAI,WAAW,OAAO;wBACpB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,IAAI,cAAc;wBAChB,eAAe;wBAEf,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,GAAGD,qBAAoB,KAAK,CAAA;wBAC9B,CAAC;wBAED,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAc,IAAI;wBAAI,CAAC;oBACpD;oBAEA,IAAI,MAAM,KAAA,IAAS,MAAM;wBACvB,MAAM,WAAA,GAAc,MAAM,KAAA,CAAM,aAAA;wBAChC,MAAM,YAAA,GAAe,MAAM,KAAA,CAAM,iBAAA;wBACjC,MAAM,WAAA,GAAc,MAAM,KAAA,CAAM,YAAA;oBAClC;oBAEA,MAAM,SAAS,MAAM,OAAA,CAAQ,CAAC,CAAA;oBAE9B,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,aAAA,KAAiB,MAAM;wBACjC,eAAeD,uBAAsB,OAAO,aAAa;oBAC3D;oBAEA,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,QAAA,KAAY,MAAM;wBAC5B,iBAAiB,MAAA,CAAO,QAAA,GAAW,OAAO,QAAA;oBAC5C;oBAEA,IAAA,CAAI,UAAA,OAAA,KAAA,IAAA,OAAQ,IAAA,KAAQ,QAAQ,OAAO,IAAA,CAAK,MAAA,GAAS,GAAG;wBAClD,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,IAAI;4BACJ,OAAO,OAAO,IAAA;wBAChB,CAAC;oBACH;gBACF;gBAEA,OAAM,UAAA,EAAY;oBAChB,IAAI,CAAC,cAAc;wBACjB,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAY,IAAI;wBAAI,CAAC;oBAClD;oBAEA,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN;wBACA;wBACA;oBACF,CAAC;gBACH;YACF,CAAC;YAEH,SAAS;gBAAE;YAAK;YAChB,UAAU;gBAAE,SAAS;YAAgB;QACvC;IACF;AACF;AAEA,IAAM,cAAcG,oLAAAA,CAAE,MAAA,CAAO;IAC3B,eAAeA,oLAAAA,CAAE,MAAA,CAAO;IACxB,mBAAmBA,oLAAAA,CAAE,MAAA,CAAO;IAC5B,cAAcA,oLAAAA,CAAE,MAAA,CAAO;AACzB,CAAC;AAID,IAAM,iCAAiCA,oLAAAA,CAAE,MAAA,CAAO;IAC9C,IAAIA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACvB,SAASA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC5B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC1B,SAASA,oLAAAA,CAAE,KAAA,CACTA,oLAAAA,CAAE,MAAA,CAAO;QACP,MAAMA,oLAAAA,CAAE,MAAA,CAAO;QACf,eAAeA,oLAAAA,CAAE,MAAA,CAAO;QACxB,UAAUA,oLAAAA,CACP,MAAA,CAAO;YACN,QAAQA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC;YAC1B,gBAAgBA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC;YAClC,cAAcA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAOA,oLAAAA,CAAE,MAAA,CAAO,GAAGA,oLAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EAAE,OAAA,CAAQ;QAClE,CAAC,EACA,OAAA,CAAQ;IACb,CAAC;IAEH,OAAO,YAAY,OAAA,CAAQ;AAC7B,CAAC;AAID,IAAM,8BAA8BA,oLAAAA,CAAE,KAAA,CAAM;IAC1CA,oLAAAA,CAAE,MAAA,CAAO;QACP,IAAIA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACvB,SAASA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAC5B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAC1B,SAASA,oLAAAA,CAAE,KAAA,CACTA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,MAAA,CAAO;YACf,eAAeA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAClC,OAAOA,oLAAAA,CAAE,MAAA,CAAO;YAChB,UAAUA,oLAAAA,CACP,MAAA,CAAO;gBACN,QAAQA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC;gBAC1B,gBAAgBA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC;gBAClC,cAAcA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAOA,oLAAAA,CAAE,MAAA,CAAO,GAAGA,oLAAAA,CAAE,MAAA,CAAO,CAAC,CAAC,EAAE,OAAA,CAAQ;YAClE,CAAC,EACA,OAAA,CAAQ;QACb,CAAC;QAEH,OAAO,YAAY,OAAA,CAAQ;IAC7B,CAAC;IACD;CACD;;;;;AMvXM,IAAM,iCAAiCM,oLAAAA,CAAE,MAAA,CAAO;IAAA;;;KAAA,GAKrD,YAAYA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;;EAAA,GAMhC,MAAMA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;AAC5B,CAAC;;ADFM,IAAM,uBAAN,MAA+D;IAYpE,YAAY,OAAA,EAAiC,MAAA,CAAsB;QAXnE,IAAA,CAAS,oBAAA,GAAuB;QAEhC,IAAA,CAAS,oBAAA,GAAuB;QAChC,IAAA,CAAS,qBAAA,GAAwB;QAS/B,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,MAAA,GAAS;IAChB;IAPA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAOA,MAAM,QAAQ,EACZ,MAAA,EACA,OAAA,EACA,WAAA,EACA,eAAA,EACF,EAEE;QA1CJ,IAAA;QA2CI,IAAI,OAAO,MAAA,GAAS,IAAA,CAAK,oBAAA,EAAsB;YAC7C,MAAM,IAAI,iMAAA,CAAmC;gBAC3C,UAAU,IAAA,CAAK,QAAA;gBACf,SAAS,IAAA,CAAK,OAAA;gBACd,sBAAsB,IAAA,CAAK,oBAAA;gBAC3B;YACF,CAAC;QACH;QAGA,MAAM,gBAAA,CACH,KAAA,UAAMC,4MAAAA,EAAqB;YAC1B,UAAU;YACV;YACA,QAAQ;QACV,CAAC,CAAA,KAJA,OAAA,KAIM,CAAC;QAEV,MAAM,EACJ,eAAA,EACA,OAAO,QAAA,EACP,QAAA,EACF,GAAI,UAAMC,qMAAAA,EAAc;YACtB,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,OAAO;YACtD,MAAM;gBACJ,OAAO,IAAA,CAAK,OAAA;gBACZ,OAAO;gBACP,iBAAiB;gBACjB,YAAY,cAAc,UAAA;gBAC1B,MAAM,cAAc,IAAA;YACtB;YACA,uBAAuB;YACvB,+BAA2BC,iNAAAA,EACzB;YAEF;YACA,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,OAAO;YACL,YAAY,SAAS,IAAA,CAAK,GAAA,CAAI,CAAA,OAAQ,KAAK,SAAS;YACpD,OAAO,SAAS,KAAA,GACZ;gBAAE,QAAQ,SAAS,KAAA,CAAM,aAAA;YAAc,IACvC,KAAA;YACJ,UAAU;gBAAE,SAAS;gBAAiB,MAAM;YAAS;QACvD;IACF;AACF;AAIA,IAAM,oCAAoCC,oLAAAA,CAAE,MAAA,CAAO;IACjD,MAAMA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO;QAAE,WAAWA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC;IAAE,CAAC,CAAC;IAC1D,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAAE,eAAeA,oLAAAA,CAAE,MAAA,CAAO;IAAE,CAAC,EAAE,OAAA,CAAQ;AACzD,CAAC;;;;AG7FM,IAAM,wBAA4D;IACvE,YAAY;IACZ,YAAY;IACZ,eAAe;AACjB;AAEO,IAAM,2BAA2B,aAAA,GAAA,IAAI,IAAI;IAAC,aAAa;CAAC;;ADQxD,IAAM,mBAAN,MAA+C;IAWpD,YACW,OAAA,EACQ,MAAA,CACjB;QAFS,IAAA,CAAA,OAAA,GAAA;QACQ,IAAA,CAAA,MAAA,GAAA;QAZnB,IAAA,CAAS,oBAAA,GAAuB;IAa7B;IAXH,IAAI,mBAA2B;QAxBjC,IAAA;QAyBI,OAAA,CAAO,KAAA,qBAAA,CAAsB,IAAA,CAAK,OAAO,CAAA,KAAlC,OAAA,KAAuC;IAChD;IAEA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAOA,MAAM,WAAW,EACf,MAAA,EACA,CAAA,EACA,IAAA,EACA,WAAA,EACA,IAAA,EACA,eAAA,EACA,OAAA,EACA,WAAA,EACF,EAEE;QAhDJ,IAAA,IAAA,IAAA,IAAA;QAiDI,MAAM,WAA2C,CAAC,CAAA;QAElD,IAAI,eAAe,MAAM;YACvB,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;QACH;QAEA,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBAAE,MAAM;gBAAuB,SAAS;YAAO,CAAC;QAChE;QAEA,MAAM,cAAA,CAAc,KAAA,CAAA,KAAA,CAAA,KAAA,IAAA,CAAK,MAAA,CAAO,SAAA,KAAZ,OAAA,KAAA,IAAA,GAAuB,WAAA,KAAvB,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,GAAA,KAAA,OAAA,KAA0C,aAAA,GAAA,IAAI,KAAK;QACvE,MAAM,EAAE,OAAO,QAAA,EAAU,eAAA,CAAgB,CAAA,GAAI,UAAMK,qMAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,OAAO;YACtD,MAAM;gBACJ,OAAO,IAAA,CAAK,OAAA;gBACZ;gBACA;gBACA;gBACA,GAAA,CAAI,KAAA,gBAAgB,MAAA,KAAhB,OAAA,KAA0B,CAAC,CAAA;gBAC/B,GAAI,CAAC,yBAAyB,GAAA,CAAI,IAAA,CAAK,OAAO,IAC1C;oBAAE,iBAAiB;gBAAW,IAC9B,CAAC,CAAA;YACP;YACA,uBAAuB;YACvB,+BAA2BC,iNAAAA,EACzB;YAEF;YACA,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,OAAO;YACL,QAAQ,SAAS,IAAA,CAAK,GAAA,CAAI,CAAA,OAAQ,KAAK,QAAQ;YAC/C;YACA,UAAU;gBACR,WAAW;gBACX,SAAS,IAAA,CAAK,OAAA;gBACd,SAAS;YACX;YACA,kBAAkB;gBAChB,QAAQ;oBACN,QAAQ,SAAS,IAAA,CAAK,GAAA,CAAI,CAAA,OACxB,KAAK,cAAA,GACD;4BACE,eAAe,KAAK,cAAA;wBACtB,IACA;gBAER;YACF;QACF;IACF;AACF;AAIA,IAAM,4BAA4BC,oLAAAA,CAAE,MAAA,CAAO;IACzC,MAAMA,oLAAAA,CAAE,KAAA,CACNA,oLAAAA,CAAE,MAAA,CAAO;QAAE,UAAUA,oLAAAA,CAAE,MAAA,CAAO;QAAG,gBAAgBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAE,CAAC;AAE5E,CAAC;;;AEnHM,IAAM,4BAA4BE,oLAAAA,CAAE,MAAA,CAAO;IAChD,WAAWA,oLAAAA,CACR,KAAA,CAAM;QACLA,oLAAAA,CAAE,MAAA,CAAO;QACTA,oLAAAA,CAAE,MAAA,CAAO;YACP,SAASA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,QAAA,CAAS;QACxC,CAAC;KACF,EACA,QAAA,CAAS;AACd,CAAC;AAEM,IAAM,sBAAkBD,wNAAAA,EAU7B;IACA,IAAI;IACJ,MAAM;IACN,aAAaC,oLAAAA,CAAE,MAAA,CAAO,CAAC,CAAC;AAC1B,CAAC;;ACxBM,IAAM,cAAc;IACzB;IACA;IACA;AACF;;;;;;;;AESA,SAAS,SAAS,IAAA,EAAc,QAAA,EAAuC;IACrE,IAAI,CAAC,SAAU,CAAA,OAAO;IACtB,OAAO,SAAS,IAAA,CAAK,CAAA,SAAU,KAAK,UAAA,CAAW,MAAM,CAAC;AACxD;AAEA,eAAsB,iCAAiC,EACrD,MAAA,EACA,iBAAA,EACA,cAAA,EACF,EAOG;IAjCH,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;IAkCE,MAAM,WAAkC,CAAC,CAAA;IACzC,MAAM,WAA8C,CAAC,CAAA;IAErD,KAAA,MAAW,EAAE,IAAA,EAAM,OAAA,CAAQ,CAAA,IAAK,OAAQ;QACtC,OAAQ,MAAM;YACZ,KAAK;gBAAU;oBACb,OAAQ,mBAAmB;wBACzB,KAAK;4BAAU;gCACb,SAAS,IAAA,CAAK;oCAAE,MAAM;oCAAU;gCAAQ,CAAC;gCACzC;4BACF;wBACA,KAAK;4BAAa;gCAChB,SAAS,IAAA,CAAK;oCAAE,MAAM;oCAAa;gCAAQ,CAAC;gCAC5C;4BACF;wBACA,KAAK;4BAAU;gCACb,SAAS,IAAA,CAAK;oCACZ,MAAM;oCACN,SAAS;gCACX,CAAC;gCACD;4BACF;wBACA;4BAAS;gCACP,MAAM,mBAA0B;gCAChC,MAAM,IAAI,MACR,CAAA,iCAAA,EAAoC,gBAAgB,EAAA;4BAExD;oBACF;oBACA;gBACF;YAEA,KAAK;gBAAQ;oBACX,SAAS,IAAA,CAAK;wBACZ,MAAM;wBACN,SAAS,QAAQ,GAAA,CAAI,CAAC,MAAM,UAAU;4BArEhD,IAAAY,KAAAC,KAAAC;4BAsEY,OAAQ,KAAK,IAAA,EAAM;gCACjB,KAAK;oCAAQ;wCACX,OAAO;4CAAE,MAAM;4CAAc,MAAM,KAAK,IAAA;wCAAK;oCAC/C;gCACA,KAAK;oCAAQ;wCACX,IAAI,KAAK,SAAA,CAAU,UAAA,CAAW,QAAQ,GAAG;4CACvC,MAAM,YACJ,KAAK,SAAA,KAAc,YACf,eACA,KAAK,SAAA;4CAEX,OAAO;gDACL,MAAM;gDACN,GAAI,KAAK,IAAA,YAAgB,MACrB;oDAAE,WAAW,KAAK,IAAA,CAAK,QAAA,CAAS;gDAAE,IAClC,OAAO,KAAK,IAAA,KAAS,YACnB,SAAS,KAAK,IAAA,EAAM,cAAc,IAClC;oDAAE,SAAS,KAAK,IAAA;gDAAK,IACrB;oDACE,WAAW,CAAA,KAAA,EAAQ,SAAS,CAAA,QAAA,MAAWH,uMAAAA,EAAgB,KAAK,IAAI,CAAC,EAAA;gDACnE,CAAA;gDACN,QAAA,CAAQE,MAAAA,CAAAD,MAAA,KAAK,eAAA,KAAL,OAAA,KAAA,IAAAA,IAAsB,MAAA,KAAtB,OAAA,KAAA,IAAAC,IAA8B,WAAA;4CACxC;wCACF,OAAA,IAAW,KAAK,SAAA,KAAc,mBAAmB;4CAC/C,IAAI,KAAK,IAAA,YAAgB,KAAK;gDAC5B,OAAO;oDACL,MAAM;oDACN,UAAU,KAAK,IAAA,CAAK,QAAA,CAAS;gDAC/B;4CACF;4CACA,OAAO;gDACL,MAAM;gDACN,GAAI,OAAO,KAAK,IAAA,KAAS,YACzB,SAAS,KAAK,IAAA,EAAM,cAAc,IAC9B;oDAAE,SAAS,KAAK,IAAA;gDAAK,IACrB;oDACE,UAAA,CAAUC,MAAA,KAAK,QAAA,KAAL,OAAAA,MAAiB,CAAA,KAAA,EAAQ,KAAK,CAAA,IAAA,CAAA;oDACxC,WAAW,CAAA,4BAAA,MAA+BH,uMAAAA,EAAgB,KAAK,IAAI,CAAC,EAAA;gDACtE,CAAA;4CACN;wCACF,OAAO;4CACL,MAAM,IAAIH,4LAAAA,CAA8B;gDACtC,eAAe,CAAA,qBAAA,EAAwB,KAAK,SAAS,EAAA;4CACvD,CAAC;wCACH;oCACF;4BACF;wBACF,CAAC;oBACH,CAAC;oBAED;gBACF;YAEA,KAAK;gBAAa;oBAChB,MAAM,oBAA8D,CAAC;oBAErE,KAAA,MAAW,QAAQ,QAAS;wBAC1B,OAAQ,KAAK,IAAA,EAAM;4BACjB,KAAK;gCAAQ;oCACX,SAAS,IAAA,CAAK;wCACZ,MAAM;wCACN,SAAS;4CAAC;gDAAE,MAAM;gDAAe,MAAM,KAAK,IAAA;4CAAK,CAAC;yCAAA;wCAClD,IAAA,CACG,KAAA,CAAA,KAAA,CAAA,KAAA,KAAK,eAAA,KAAL,OAAA,KAAA,IAAA,GAAsB,MAAA,KAAtB,OAAA,KAAA,IAAA,GAA8B,MAAA,KAA9B,OAAA,KAAmD,KAAA;oCACxD,CAAC;oCACD;gCACF;4BACA,KAAK;gCAAa;oCAChB,IAAI,KAAK,gBAAA,EAAkB;wCACzB;oCACF;oCAEA,SAAS,IAAA,CAAK;wCACZ,MAAM;wCACN,SAAS,KAAK,UAAA;wCACd,MAAM,KAAK,QAAA;wCACX,WAAW,KAAK,SAAA,CAAU,KAAK,KAAK;wCACpC,IAAA,CACG,KAAA,CAAA,KAAA,CAAA,KAAA,KAAK,eAAA,KAAL,OAAA,KAAA,IAAA,GAAsB,MAAA,KAAtB,OAAA,KAAA,IAAA,GAA8B,MAAA,KAA9B,OAAA,KAAmD,KAAA;oCACxD,CAAC;oCACD;gCACF;4BAEA,KAAK;gCAAe;oCAClB,SAAS,IAAA,CAAK;wCACZ,MAAM;wCACN,SAAS,CAAA,8EAAA,CAAA;oCACX,CAAC;oCACD;gCACF;4BAEA,KAAK;gCAAa;oCAChB,MAAM,kBAAkB,UAAMC,4MAAAA,EAAqB;wCACjD,UAAU;wCACV,iBAAiB,KAAK,eAAA;wCACtB,QAAQ;oCACV,CAAC;oCAED,MAAM,cAAc,mBAAA,OAAA,KAAA,IAAA,gBAAiB,MAAA;oCAErC,IAAI,eAAe,MAAM;wCACvB,MAAM,2BAA2B,iBAAA,CAAkB,WAAW,CAAA;wCAE9D,MAAM,eAGD,CAAC,CAAA;wCAEN,IAAI,KAAK,IAAA,CAAK,MAAA,GAAS,GAAG;4CACxB,aAAa,IAAA,CAAK;gDAAE,MAAM;gDAAgB,MAAM,KAAK,IAAA;4CAAK,CAAC;wCAC7D,OAAA,IAAW,6BAA6B,KAAA,GAAW;4CACjD,SAAS,IAAA,CAAK;gDACZ,MAAM;gDACN,SAAS,CAAA,4FAAA,EAA+F,KAAK,SAAA,CAAU,IAAI,CAAC,CAAA,CAAA,CAAA;4CAC9H,CAAC;wCACH;wCAEA,IAAI,6BAA6B,KAAA,GAAW;4CAC1C,iBAAA,CAAkB,WAAW,CAAA,GAAI;gDAC/B,MAAM;gDACN,IAAI;gDACJ,mBACE,mBAAA,OAAA,KAAA,IAAA,gBAAiB,yBAAA;gDACnB,SAAS;4CACX;4CACA,SAAS,IAAA,CAAK,iBAAA,CAAkB,WAAW,CAAC;wCAC9C,OAAO;4CACL,yBAAyB,OAAA,CAAQ,IAAA,CAAK,GAAG,YAAY;wCACvD;oCACF,OAAO;wCACL,SAAS,IAAA,CAAK;4CACZ,MAAM;4CACN,SAAS,CAAA,uEAAA,EAA0E,KAAK,SAAA,CAAU,IAAI,CAAC,CAAA,CAAA,CAAA;wCACzG,CAAC;oCACH;oCACA;gCACF;wBACF;oBACF;oBAEA;gBACF;YAEA,KAAK;gBAAQ;oBACX,KAAA,MAAW,QAAQ,QAAS;wBAC1B,MAAM,SAAS,KAAK,MAAA;wBAEpB,IAAI;wBACJ,OAAQ,OAAO,IAAA,EAAM;4BACnB,KAAK;4BACL,KAAK;gCACH,eAAe,OAAO,KAAA;gCACtB;4BACF,KAAK;4BACL,KAAK;4BACL,KAAK;gCACH,eAAe,KAAK,SAAA,CAAU,OAAO,KAAK;gCAC1C;wBACJ;wBAEA,SAAS,IAAA,CAAK;4BACZ,MAAM;4BACN,SAAS,KAAK,UAAA;4BACd,QAAQ;wBACV,CAAC;oBACH;oBAEA;gBACF;YAEA;gBAAS;oBACP,MAAM,mBAA0B;oBAChC,MAAM,IAAI,MAAM,CAAA,kBAAA,EAAqB,gBAAgB,EAAE;gBACzD;QACF;IACF;IAEA,OAAO;QAAE;QAAU;IAAS;AAC9B;AAEA,IAAM,gDAAgDC,oLAAAA,CAAE,MAAA,CAAO;IAC7D,QAAQA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC3B,2BAA2BA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;AAChD,CAAC;;AC3PM,SAAS,8BAA8B,EAC5C,YAAA,EACA,YAAA,EACF,EAGgC;IAC9B,OAAQ,cAAc;QACpB,KAAK,KAAA;QACL,KAAK;YACH,OAAO,eAAe,eAAe;QACvC,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT;YACE,OAAO,eAAe,eAAe;IACzC;AACF;;ACVO,SAAS,sBAAsB,EACpC,KAAA,EACA,UAAA,EACA,gBAAA,EACF,EAeE;IAEA,QAAA,CAAQ,SAAA,OAAA,KAAA,IAAA,MAAO,MAAA,IAAS,QAAQ,KAAA;IAEhC,MAAM,eAA6C,CAAC,CAAA;IAEpD,IAAI,SAAS,MAAM;QACjB,OAAO;YAAE,OAAO,KAAA;YAAW,YAAY,KAAA;YAAW;QAAa;IACjE;IAEA,MAAMM,eAA0C,CAAC,CAAA;IAEjD,KAAA,MAAW,QAAQ,MAAO;QACxB,OAAQ,KAAK,IAAA,EAAM;YACjB,KAAK;gBACHA,aAAY,IAAA,CAAK;oBACf,MAAM;oBACN,MAAM,KAAK,IAAA;oBACX,aAAa,KAAK,WAAA;oBAClB,YAAY,KAAK,WAAA;oBACjB,QAAQ;gBACV,CAAC;gBACD;YACF,KAAK;gBAAoB;oBACvB,OAAQ,KAAK,EAAA,EAAI;wBACf,KAAK;4BAAsB;gCACzB,MAAM,OAAO,qBAAqB,KAAA,CAAM,KAAK,IAAI;gCACjDA,aAAY,IAAA,CAAK;oCACf,MAAM;oCACN,kBAAkB,KAAK,cAAA;oCACvB,iBAAiB,KAAK,aAAA;oCACtB,iBAAiB,KAAK,OAAA,GAClB;wCAAE,QAAQ,KAAK,OAAA,CAAQ,MAAA;oCAAO,IAC9B,KAAA;oCACJ,SAAS,KAAK,OAAA;gCAChB,CAAC;gCACD;4BACF;wBACA,KAAK;4BAA6B;gCAChC,MAAM,OAAO,2BAA2B,KAAA,CAAM,KAAK,IAAI;gCACvDA,aAAY,IAAA,CAAK;oCACf,MAAM;oCACN,qBAAqB,KAAK,iBAAA;oCAC1B,eAAe,KAAK,YAAA;gCACtB,CAAC;gCACD;4BACF;wBACA,KAAK;4BAA2B;gCAC9B,MAAM,OAAO,0BAA0B,KAAA,CAAM,KAAK,IAAI;gCACtDA,aAAY,IAAA,CAAK;oCACf,MAAM;oCACN,WACE,KAAK,SAAA,IAAa,OACd;wCAAE,MAAM;wCAAQ,UAAU,KAAA;oCAAU,IACpC,OAAO,KAAK,SAAA,KAAc,WACxB,KAAK,SAAA,GACL;wCAAE,MAAM;wCAAQ,UAAU,KAAK,SAAA,CAAU,OAAA;oCAAQ;gCAC3D,CAAC;gCACD;4BACF;wBACA;4BAAS;gCACP,aAAa,IAAA,CAAK;oCAAE,MAAM;oCAAoB;gCAAK,CAAC;gCACpD;4BACF;oBACF;oBACA;gBACF;YACA;gBACE,aAAa,IAAA,CAAK;oBAAE,MAAM;oBAAoB;gBAAK,CAAC;gBACpD;QACJ;IACF;IAEA,IAAI,cAAc,MAAM;QACtB,OAAO;YAAE,OAAOA;YAAa,YAAY,KAAA;YAAW;QAAa;IACnE;IAEA,MAAM,OAAO,WAAW,IAAA;IAExB,OAAQ,MAAM;QACZ,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO;gBAAE,OAAOA;gBAAa,YAAY;gBAAM;YAAa;QAC9D,KAAK;YACH,OAAO;gBACL,OAAOA;gBACP,YACE,WAAW,QAAA,KAAa,sBACxB,WAAW,QAAA,KAAa,iBACxB,WAAW,QAAA,KAAa,uBACpB;oBAAE,MAAM,WAAW,QAAA;gBAAS,IAC5B;oBAAE,MAAM;oBAAY,MAAM,WAAW,QAAA;gBAAS;gBACpD;YACF;QACF;YAAS;gBACP,MAAM,mBAA0B;gBAChC,MAAM,IAAIC,4LAAAA,CAA8B;oBACtC,eAAe,CAAA,kBAAA,EAAqB,gBAAgB,EAAA;gBACtD,CAAC;YACH;IACF;AACF;;AHxGA,IAAM,oBAAoBC,oLAAAA,CAAE,MAAA,CAAO;IACjC,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,iBAAiB;IACjC,IAAIA,oLAAAA,CAAE,MAAA,CAAO;IACb,QAAQA,oLAAAA,CAAE,MAAA,CAAO;IACjB,QAAQA,oLAAAA,CACL,kBAAA,CAAmB,QAAQ;QAC1BA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,QAAQ;YACxB,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAC5B,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;YAC3B,KAAKA,oLAAAA,CAAE,MAAA,CAAO;QAChB,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,MAAM;YACtB,KAAKA,oLAAAA,CAAE,MAAA,CAAO;YACd,SAASA,oLAAAA,CAAE,MAAA,CAAO;QACpB,CAAC;KACF,EACA,OAAA,CAAQ;AACb,CAAC;AASD,IAAM,mBAAmB;AAEzB,IAAM,kBAAkBA,oLAAAA,CAAE,KAAA,CACxBA,oLAAAA,CAAE,MAAA,CAAO;IACP,OAAOA,oLAAAA,CAAE,MAAA,CAAO;IAChB,SAASA,oLAAAA,CAAE,MAAA,CAAO;IAClB,cAAcA,oLAAAA,CAAE,KAAA,CACdA,oLAAAA,CAAE,MAAA,CAAO;QACP,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAChB,SAASA,oLAAAA,CAAE,MAAA,CAAO;IACpB,CAAC;AAEL,CAAC;AAGI,IAAM,+BAAN,MAA8D;IAOnE,YAAY,OAAA,EAAiC,MAAA,CAAsB;QANnE,IAAA,CAAS,oBAAA,GAAuB;QAWhC,IAAA,CAAS,aAAA,GAA0C;YACjD,WAAW;gBAAC,iBAAiB;aAAA;YAC7B,mBAAmB;gBAAC,iBAAiB;aAAA;QACvC;QAPE,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,MAAA,GAAS;IAChB;IAOA,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAEA,MAAc,QAAQ,EACpB,eAAA,EACA,WAAA,EACA,aAAA,EACA,IAAA,EACA,IAAA,EACA,eAAA,EACA,gBAAA,EACA,IAAA,EACA,MAAA,EACA,eAAA,EACA,KAAA,EACA,UAAA,EACA,cAAA,EACF,EAAiD;QA3GnD,IAAA,IAAA;QA4GI,MAAM,WAAyC,CAAC,CAAA;QAChD,MAAM,cAAc,wBAAwB,IAAA,CAAK,OAAO;QAExD,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBAAE,MAAM;gBAAuB,SAAS;YAAO,CAAC;QAChE;QAEA,IAAI,QAAQ,MAAM;YAChB,SAAS,IAAA,CAAK;gBAAE,MAAM;gBAAuB,SAAS;YAAO,CAAC;QAChE;QAEA,IAAI,mBAAmB,MAAM;YAC3B,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;YACX,CAAC;QACH;QAEA,IAAI,oBAAoB,MAAM;YAC5B,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;YACX,CAAC;QACH;QAEA,IAAI,iBAAiB,MAAM;YACzB,SAAS,IAAA,CAAK;gBAAE,MAAM;gBAAuB,SAAS;YAAgB,CAAC;QACzE;QAEA,MAAM,EAAE,QAAA,EAAU,UAAU,eAAA,CAAgB,CAAA,GAC1C,MAAM,iCAAiC;YACrC;YACA,mBAAmB,YAAY,iBAAA;YAC/B,gBAAgB,IAAA,CAAK,MAAA,CAAO,cAAA;QAC9B,CAAC;QAEH,SAAS,IAAA,CAAK,GAAG,eAAe;QAEhC,MAAM,gBAAgB,UAAMC,4MAAAA,EAAqB;YAC/C,UAAU;YACV;YACA,QAAQ;QACV,CAAC;QAED,MAAM,mBAAA,CAAmB,KAAA,iBAAA,OAAA,KAAA,IAAA,cAAe,gBAAA,KAAf,OAAA,KAAmC;QAE5D,MAAM,cACJ,OAAA,CAAO,iBAAA,OAAA,KAAA,IAAA,cAAe,QAAA,MAAa,WAC/B,iBAAA,OAAA,KAAA,IAAA,cAAe,QAAA,GAAA,CACf,iBAAA,OAAA,KAAA,IAAA,cAAe,QAAA,MAAa,OAC1B,mBACA,KAAA;QACR,MAAM,uBAAuB,cACzB,MAAM,OAAA,CAAQ,iBAAA,OAAA,KAAA,IAAA,cAAe,OAAO,IAClC,CAAC;eAAG,iBAAA,OAAA,KAAA,IAAA,cAAe,OAAA;YAAS,8BAA8B;SAAA,GAC1D;YAAC,8BAA8B;SAAA,GACjC,iBAAA,OAAA,KAAA,IAAA,cAAe,OAAA;QAEnB,MAAM,WAAW;YACf,OAAO,IAAA,CAAK,OAAA;YACZ,OAAO;YACP;YACA,OAAO;YACP,mBAAmB;YAEnB,GAAA,CAAA,CAAK,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,UAAA,CAAU,iBAAA,OAAA,KAAA,IAAA,cAAe,aAAA,CAAA,KAAkB;gBACvE,MAAM;oBACJ,GAAA,CAAI,kBAAA,OAAA,KAAA,IAAA,eAAgB,IAAA,MAAS,UAAU;wBACrC,QACE,eAAe,MAAA,IAAU,OACrB;4BACE,MAAM;4BACN,QAAQ;4BACR,MAAA,CAAM,KAAA,eAAe,IAAA,KAAf,OAAA,KAAuB;4BAC7B,aAAa,eAAe,WAAA;4BAC5B,QAAQ,eAAe,MAAA;wBACzB,IACA;4BAAE,MAAM;wBAAc;oBAC9B,CAAA;oBACA,GAAA,CAAI,iBAAA,OAAA,KAAA,IAAA,cAAe,aAAA,KAAiB;wBAClC,WAAW,cAAc,aAAA;oBAC3B,CAAA;gBACF;YACF,CAAA;YAAA,oBAAA;YAGA,UAAU,iBAAA,OAAA,KAAA,IAAA,cAAe,QAAA;YACzB,qBAAqB,iBAAA,OAAA,KAAA,IAAA,cAAe,iBAAA;YACpC,sBAAsB,iBAAA,OAAA,KAAA,IAAA,cAAe,kBAAA;YACrC,OAAO,iBAAA,OAAA,KAAA,IAAA,cAAe,KAAA;YACtB,MAAM,iBAAA,OAAA,KAAA,IAAA,cAAe,IAAA;YACrB,cAAc,iBAAA,OAAA,KAAA,IAAA,cAAe,YAAA;YAC7B,cAAc,iBAAA,OAAA,KAAA,IAAA,cAAe,WAAA;YAC7B,SAAS;YACT,kBAAkB,iBAAA,OAAA,KAAA,IAAA,cAAe,cAAA;YACjC,mBAAmB,iBAAA,OAAA,KAAA,IAAA,cAAe,gBAAA;YAClC,cAAc;YAAA,2BAAA;YAGd,GAAI,YAAY,gBAAA,IAAA,CAAA,CACb,iBAAA,OAAA,KAAA,IAAA,cAAe,eAAA,KAAmB,QAAA,CACjC,iBAAA,OAAA,KAAA,IAAA,cAAe,gBAAA,KAAoB,IAAA,KAAS;gBAC5C,WAAW;oBACT,GAAA,CAAI,iBAAA,OAAA,KAAA,IAAA,cAAe,eAAA,KAAmB,QAAQ;wBAC5C,QAAQ,cAAc,eAAA;oBACxB,CAAA;oBACA,GAAA,CAAI,iBAAA,OAAA,KAAA,IAAA,cAAe,gBAAA,KAAoB,QAAQ;wBAC7C,SAAS,cAAc,gBAAA;oBACzB,CAAA;gBACF;YACF,CAAA;YACF,GAAI,YAAY,sBAAA,IAA0B;gBACxC,YAAY;YACd,CAAA;QACF;QAEA,IAAI,YAAY,gBAAA,EAAkB;YAGhC,IAAI,SAAS,WAAA,IAAe,MAAM;gBAChC,SAAS,WAAA,GAAc,KAAA;gBACvB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;YAEA,IAAI,SAAS,KAAA,IAAS,MAAM;gBAC1B,SAAS,KAAA,GAAQ,KAAA;gBACjB,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;QACF,OAAO;YACL,IAAA,CAAI,iBAAA,OAAA,KAAA,IAAA,cAAe,eAAA,KAAmB,MAAM;gBAC1C,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;YAEA,IAAA,CAAI,iBAAA,OAAA,KAAA,IAAA,cAAe,gBAAA,KAAoB,MAAM;gBAC3C,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS;gBACX,CAAC;YACH;QACF;QAGA,IAAA,CACE,iBAAA,OAAA,KAAA,IAAA,cAAe,WAAA,MAAgB,UAC/B,CAAC,YAAY,sBAAA,EACb;YACA,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;YAED,OAAQ,SAAiB,YAAA;QAC3B;QAGA,IAAA,CACE,iBAAA,OAAA,KAAA,IAAA,cAAe,WAAA,MAAgB,cAC/B,CAAC,YAAY,0BAAA,EACb;YACA,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SACE;YACJ,CAAC;YAED,OAAQ,SAAiB,YAAA;QAC3B;QAEA,MAAM,EACJ,OAAOC,YAAAA,EACP,YAAY,gBAAA,EACZ,YAAA,EACF,GAAI,sBAAsB;YACxB;YACA;YACA;QACF,CAAC;QAED,OAAO;YACL,MAAM;gBACJ,GAAG,QAAA;gBACH,OAAOA;gBACP,aAAa;YACf;YACA,UAAU,CAAC;mBAAG,UAAU;mBAAG,YAAY;aAAA;QACzC;IACF;IAEA,MAAM,WACJ,OAAA,EAC6D;QA1TjE,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;QA2TI,MAAM,EAAE,MAAM,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAC3D,MAAM,MAAM,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;YAC1B,MAAM;YACN,SAAS,IAAA,CAAK,OAAA;QAChB,CAAC;QAED,MAAM,EACJ,eAAA,EACA,OAAO,QAAA,EACP,UAAU,WAAA,EACZ,GAAI,UAAMC,qMAAAA,EAAc;YACtB;YACA,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D;YACA,uBAAuB;YACvB,+BAA2BC,iNAAAA,EACzBL,oLAAAA,CAAE,MAAA,CAAO;gBACP,IAAIA,oLAAAA,CAAE,MAAA,CAAO;gBACb,YAAYA,oLAAAA,CAAE,MAAA,CAAO;gBACrB,OAAOA,oLAAAA,CACJ,MAAA,CAAO;oBACN,MAAMA,oLAAAA,CAAE,MAAA,CAAO;oBACf,SAASA,oLAAAA,CAAE,MAAA,CAAO;gBACpB,CAAC,EACA,OAAA,CAAQ;gBACX,OAAOA,oLAAAA,CAAE,MAAA,CAAO;gBAChB,QAAQA,oLAAAA,CAAE,KAAA,CACRA,oLAAAA,CAAE,kBAAA,CAAmB,QAAQ;oBAC3BA,oLAAAA,CAAE,MAAA,CAAO;wBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,SAAS;wBACzB,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;wBAC3B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;wBACb,SAASA,oLAAAA,CAAE,KAAA,CACTA,oLAAAA,CAAE,MAAA,CAAO;4BACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,aAAa;4BAC7B,MAAMA,oLAAAA,CAAE,MAAA,CAAO;4BACf,UAAU,gBAAgB,OAAA,CAAQ;4BAClC,aAAaA,oLAAAA,CAAE,KAAA,CACbA,oLAAAA,CAAE,kBAAA,CAAmB,QAAQ;gCAC3BA,oLAAAA,CAAE,MAAA,CAAO;oCACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,cAAc;oCAC9B,aAAaA,oLAAAA,CAAE,MAAA,CAAO;oCACtB,WAAWA,oLAAAA,CAAE,MAAA,CAAO;oCACpB,KAAKA,oLAAAA,CAAE,MAAA,CAAO;oCACd,OAAOA,oLAAAA,CAAE,MAAA,CAAO;gCAClB,CAAC;gCACDA,oLAAAA,CAAE,MAAA,CAAO;oCACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;oCAC/B,SAASA,oLAAAA,CAAE,MAAA,CAAO;oCAClB,UAAUA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oCAC7B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oCAC1B,aAAaA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oCAChC,WAAWA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;oCAC9B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gCAC5B,CAAC;6BACF;wBAEL,CAAC;oBAEL,CAAC;oBACDA,oLAAAA,CAAE,MAAA,CAAO;wBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;wBAC/B,SAASA,oLAAAA,CAAE,MAAA,CAAO;wBAClB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;wBACf,WAAWA,oLAAAA,CAAE,MAAA,CAAO;wBACpB,IAAIA,oLAAAA,CAAE,MAAA,CAAO;oBACf,CAAC;oBACD;oBACAA,oLAAAA,CAAE,MAAA,CAAO;wBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;wBAC/B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;wBACb,QAAQA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;oBAC9B,CAAC;oBACDA,oLAAAA,CAAE,MAAA,CAAO;wBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,kBAAkB;wBAClC,IAAIA,oLAAAA,CAAE,MAAA,CAAO;wBACb,QAAQA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;wBAC5B,SAASA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ;wBACrC,SAASA,oLAAAA,CACN,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;4BACP,YAAYA,oLAAAA,CAAE,MAAA,CAAO;gCACnB,SAASA,oLAAAA,CAAE,MAAA,CAAO;gCAClB,UAAUA,oLAAAA,CAAE,MAAA,CAAO;gCACnB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;gCAChB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;4BACjB,CAAC;wBACH,CAAC,GAEF,OAAA,CAAQ;oBACb,CAAC;oBACDA,oLAAAA,CAAE,MAAA,CAAO;wBACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;wBAC3B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;wBACb,mBAAmBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;wBACtC,SAASA,oLAAAA,CAAE,KAAA,CACTA,oLAAAA,CAAE,MAAA,CAAO;4BACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,cAAc;4BAC9B,MAAMA,oLAAAA,CAAE,MAAA,CAAO;wBACjB,CAAC;oBAEL,CAAC;iBACF;gBAEH,cAAcA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;gBACjC,oBAAoBA,oLAAAA,CAAE,MAAA,CAAO;oBAAE,QAAQA,oLAAAA,CAAE,MAAA,CAAO;gBAAE,CAAC,EAAE,QAAA,CAAS;gBAC9D,OAAOM;YACT,CAAC;YAEH,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,IAAI,SAAS,KAAA,EAAO;YAClB,MAAM,IAAI,2KAAA,CAAa;gBACrB,SAAS,SAAS,KAAA,CAAM,OAAA;gBACxB;gBACA,mBAAmB;gBACnB,YAAY;gBACZ;gBACA,cAAc;gBACd,aAAa;YACf,CAAC;QACH;QAEA,MAAM,UAAyC,CAAC,CAAA;QAChD,MAAM,WAAmD,CAAC,CAAA;QAG1D,KAAA,MAAW,QAAQ,SAAS,MAAA,CAAQ;YAClC,OAAQ,KAAK,IAAA,EAAM;gBACjB,KAAK;oBAAa;wBAEhB,IAAI,KAAK,OAAA,CAAQ,MAAA,KAAW,GAAG;4BAC7B,KAAK,OAAA,CAAQ,IAAA,CAAK;gCAAE,MAAM;gCAAgB,MAAM;4BAAG,CAAC;wBACtD;wBAEA,KAAA,MAAW,WAAW,KAAK,OAAA,CAAS;4BAClC,QAAQ,IAAA,CAAK;gCACX,MAAM;gCACN,MAAM,QAAQ,IAAA;gCACd,kBAAkB;oCAChB,QAAQ;wCACN,QAAQ,KAAK,EAAA;wCACb,2BAAA,CAA2B,KAAA,KAAK,iBAAA,KAAL,OAAA,KAA0B;oCACvD;gCACF;4BACF,CAAC;wBACH;wBACA;oBACF;gBAEA,KAAK;oBAAW;wBACd,KAAA,MAAW,eAAe,KAAK,OAAA,CAAS;4BACtC,IAAA,CAAA,CACE,KAAA,CAAA,KAAA,QAAQ,eAAA,KAAR,OAAA,KAAA,IAAA,GAAyB,MAAA,KAAzB,OAAA,KAAA,IAAA,GAAiC,QAAA,KACjC,YAAY,QAAA,EACZ;gCACA,SAAS,IAAA,CAAK,YAAY,QAAQ;4BACpC;4BAEA,QAAQ,IAAA,CAAK;gCACX,MAAM;gCACN,MAAM,YAAY,IAAA;gCAClB,kBAAkB;oCAChB,QAAQ;wCACN,QAAQ,KAAK,EAAA;oCACf;gCACF;4BACF,CAAC;4BAED,KAAA,MAAW,cAAc,YAAY,WAAA,CAAa;gCAChD,IAAI,WAAW,IAAA,KAAS,gBAAgB;oCACtC,QAAQ,IAAA,CAAK;wCACX,MAAM;wCACN,YAAY;wCACZ,IAAA,CAAI,KAAA,CAAA,KAAA,CAAA,KAAA,IAAA,CAAK,MAAA,EAAO,UAAA,KAAZ,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,GAAA,KAAA,OAAA,SAA8BC,kMAAAA,CAAW;wCAC7C,KAAK,WAAW,GAAA;wCAChB,OAAO,WAAW,KAAA;oCACpB,CAAC;gCACH,OAAA,IAAW,WAAW,IAAA,KAAS,iBAAiB;oCAC9C,QAAQ,IAAA,CAAK;wCACX,MAAM;wCACN,YAAY;wCACZ,IAAA,CAAI,KAAA,CAAA,KAAA,CAAA,KAAA,IAAA,CAAK,MAAA,EAAO,UAAA,KAAZ,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,GAAA,KAAA,OAAA,SAA8BA,kMAAAA,CAAW;wCAC7C,WAAW;wCACX,OAAA,CAAO,KAAA,CAAA,KAAA,WAAW,KAAA,KAAX,OAAA,KAAoB,WAAW,QAAA,KAA/B,OAAA,KAA2C;wCAClD,UAAA,CAAU,KAAA,WAAW,QAAA,KAAX,OAAA,KAAuB,WAAW,OAAA;oCAC9C,CAAC;gCACH;4BACF;wBACF;wBAEA;oBACF;gBAEA,KAAK;oBAAiB;wBACpB,QAAQ,IAAA,CAAK;4BACX,MAAM;4BACN,YAAY,KAAK,OAAA;4BACjB,UAAU,KAAK,IAAA;4BACf,OAAO,KAAK,SAAA;4BACZ,kBAAkB;gCAChB,QAAQ;oCACN,QAAQ,KAAK,EAAA;gCACf;4BACF;wBACF,CAAC;wBACD;oBACF;gBAEA,KAAK;oBAAmB;wBACtB,QAAQ,IAAA,CAAK;4BACX,MAAM;4BACN,YAAY,KAAK,EAAA;4BACjB,UAAU;4BACV,OAAO,KAAK,SAAA,CAAU;gCAAE,QAAQ,KAAK,MAAA;4BAAO,CAAC;4BAC7C,kBAAkB;wBACpB,CAAC;wBAED,QAAQ,IAAA,CAAK;4BACX,MAAM;4BACN,YAAY,KAAK,EAAA;4BACjB,UAAU;4BACV,QAAQ;gCAAE,QAAQ,KAAK,MAAA;4BAAO;4BAC9B,kBAAkB;wBACpB,CAAC;wBACD;oBACF;gBAEA,KAAK;oBAAiB;wBACpB,QAAQ,IAAA,CAAK;4BACX,MAAM;4BACN,YAAY,KAAK,EAAA;4BACjB,UAAU;4BACV,OAAO;4BACP,kBAAkB;wBACpB,CAAC;wBAED,QAAQ,IAAA,CAAK;4BACX,MAAM;4BACN,YAAY,KAAK,EAAA;4BACjB,UAAU;4BACV,QAAQ;gCACN,MAAM;gCACN,QAAQ,KAAK,MAAA,IAAU;4BACzB;4BACA,kBAAkB;wBACpB,CAAC;wBACD;oBACF;gBAEA,KAAK;oBAAoB;wBACvB,QAAQ,IAAA,CAAK;4BACX,MAAM;4BACN,YAAY,KAAK,EAAA;4BACjB,UAAU;4BACV,OAAO;4BACP,kBAAkB;wBACpB,CAAC;wBAED,QAAQ,IAAA,CAAK;4BACX,MAAM;4BACN,YAAY,KAAK,EAAA;4BACjB,UAAU;4BACV,QAAQ;gCACN,MAAM;gCACN,QAAQ,KAAK,MAAA,IAAU;gCACvB,GAAI,KAAK,OAAA,IAAW;oCAAE,SAAS,KAAK,OAAA;gCAAQ,CAAA;gCAC5C,GAAI,KAAK,OAAA,IAAW;oCAAE,SAAS,KAAK,OAAA;gCAAQ,CAAA;4BAC9C;4BACA,kBAAkB;wBACpB,CAAC;wBACD;oBACF;YACF;QACF;QAEA,MAAM,mBAA6C;YACjD,QAAQ;gBAAE,YAAY,SAAS,EAAA;YAAG;QACpC;QAEA,IAAI,SAAS,MAAA,GAAS,GAAG;YACvB,iBAAiB,MAAA,CAAO,QAAA,GAAW;QACrC;QAEA,IAAI,OAAO,SAAS,YAAA,KAAiB,UAAU;YAC7C,iBAAiB,MAAA,CAAO,WAAA,GAAc,SAAS,YAAA;QACjD;QAEA,OAAO;YACL;YACA,cAAc,8BAA8B;gBAC1C,cAAA,CAAc,KAAA,SAAS,kBAAA,KAAT,OAAA,KAAA,IAAA,GAA6B,MAAA;gBAC3C,cAAc,QAAQ,IAAA,CAAK,CAAA,OAAQ,KAAK,IAAA,KAAS,WAAW;YAC9D,CAAC;YACD,OAAO;gBACL,aAAa,SAAS,KAAA,CAAM,YAAA;gBAC5B,cAAc,SAAS,KAAA,CAAM,aAAA;gBAC7B,aAAa,SAAS,KAAA,CAAM,YAAA,GAAe,SAAS,KAAA,CAAM,aAAA;gBAC1D,iBAAA,CACE,KAAA,CAAA,KAAA,SAAS,KAAA,CAAM,qBAAA,KAAf,OAAA,KAAA,IAAA,GAAsC,gBAAA,KAAtC,OAAA,KAA0D,KAAA;gBAC5D,mBAAA,CACE,KAAA,CAAA,KAAA,SAAS,KAAA,CAAM,oBAAA,KAAf,OAAA,KAAA,IAAA,GAAqC,aAAA,KAArC,OAAA,KAAsD,KAAA;YAC1D;YACA,SAAS;gBAAE;YAAK;YAChB,UAAU;gBACR,IAAI,SAAS,EAAA;gBACb,WAAW,IAAI,KAAK,SAAS,UAAA,GAAa,GAAI;gBAC9C,SAAS,SAAS,KAAA;gBAClB,SAAS;gBACT,MAAM;YACR;YACA;YACA;QACF;IACF;IAEA,MAAM,SACJ,OAAA,EAC2D;QAC3D,MAAM,EAAE,MAAM,IAAA,EAAM,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAE3D,MAAM,EAAE,eAAA,EAAiB,OAAO,QAAA,CAAS,CAAA,GAAI,UAAMJ,qMAAAA,EAAc;YAC/D,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;gBACJ,GAAG,IAAA;gBACH,QAAQ;YACV;YACA,uBAAuB;YACvB,+BAA2BI,wNAAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,OAAO,IAAA;QAEb,IAAI,eAA4C;QAChD,MAAM,QAA8B;YAClC,aAAa,KAAA;YACb,cAAc,KAAA;YACd,aAAa,KAAA;QACf;QACA,MAAM,WAAmD,CAAC,CAAA;QAC1D,IAAI,aAA4B;QAChC,MAAM,mBAGF,CAAC;QACL,IAAI,eAAe;QAEnB,MAAM,kBAMF,CAAC;QAEL,IAAI;QAEJ,OAAO;YACL,QAAQ,SAAS,WAAA,CACf,IAAI,gBAGF;gBACA,OAAM,UAAA,EAAY;oBAChB,WAAW,OAAA,CAAQ;wBAAE,MAAM;wBAAgB;oBAAS,CAAC;gBACvD;gBAEA,WAAU,KAAA,EAAO,UAAA,EAAY;oBAprBvC,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;oBAqrBY,IAAI,QAAQ,gBAAA,EAAkB;wBAC5B,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAO,UAAU,MAAM,QAAA;wBAAS,CAAC;oBAC9D;oBAGA,IAAI,CAAC,MAAM,OAAA,EAAS;wBAClB,eAAe;wBACf,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO,MAAM,KAAA;wBAAM,CAAC;wBACxD;oBACF;oBAEA,MAAM,QAAQ,MAAM,KAAA;oBAEpB,IAAI,+BAA+B,KAAK,GAAG;wBACzC,IAAI,MAAM,IAAA,CAAK,IAAA,KAAS,iBAAiB;4BACvC,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI;gCACrC,UAAU,MAAM,IAAA,CAAK,IAAA;gCACrB,YAAY,MAAM,IAAA,CAAK,OAAA;4BACzB;4BAEA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,OAAA;gCACf,UAAU,MAAM,IAAA,CAAK,IAAA;4BACvB,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,mBAAmB;4BAChD,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI;gCACrC,UAAU;gCACV,YAAY,MAAM,IAAA,CAAK,EAAA;4BACzB;4BAEA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;gCACf,UAAU;4BACZ,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,iBAAiB;4BAC9C,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI;gCACrC,UAAU;gCACV,YAAY,MAAM,IAAA,CAAK,EAAA;4BACzB;4BAEA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;gCACf,UAAU;4BACZ,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,oBAAoB;4BACjD,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI;gCACrC,UAAU;gCACV,YAAY,MAAM,IAAA,CAAK,EAAA;4BACzB;4BAEA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;gCACf,UAAU;4BACZ,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,WAAW;4BACxC,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;gCACf,kBAAkB;oCAChB,QAAQ;wCACN,QAAQ,MAAM,IAAA,CAAK,EAAA;oCACrB;gCACF;4BACF,CAAC;wBACH,OAAA,IAAW,wCAAwC,KAAK,GAAG;4BACzD,eAAA,CAAgB,MAAM,IAAA,CAAK,EAAE,CAAA,GAAI;gCAC/B,kBAAkB,MAAM,IAAA,CAAK,iBAAA;gCAC7B,cAAc;oCAAC,CAAC;iCAAA;4BAClB;4BAEA,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,GAAG,MAAM,IAAA,CAAK,EAAE,CAAA,EAAA,CAAA;gCACpB,kBAAkB;oCAChB,QAAQ;wCACN,QAAQ,MAAM,IAAA,CAAK,EAAA;wCACnB,2BAAA,CACE,KAAA,MAAM,IAAA,CAAK,iBAAA,KAAX,OAAA,KAAgC;oCACpC;gCACF;4BACF,CAAC;wBACH;oBACF,OAAA,IAAW,8BAA8B,KAAK,GAAG;wBAC/C,IAAI,MAAM,IAAA,CAAK,IAAA,KAAS,iBAAiB;4BACvC,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI,KAAA;4BACvC,eAAe;4BAEf,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,OAAA;4BACjB,CAAC;4BAED,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,IAAA,CAAK,OAAA;gCACvB,UAAU,MAAM,IAAA,CAAK,IAAA;gCACrB,OAAO,MAAM,IAAA,CAAK,SAAA;gCAClB,kBAAkB;oCAChB,QAAQ;wCACN,QAAQ,MAAM,IAAA,CAAK,EAAA;oCACrB;gCACF;4BACF,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,mBAAmB;4BAChD,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI,KAAA;4BACvC,eAAe;4BAEf,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;4BACjB,CAAC;4BAED,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,IAAA,CAAK,EAAA;gCACvB,UAAU;gCACV,OAAO,KAAK,SAAA,CAAU;oCAAE,QAAQ,MAAM,IAAA,CAAK,MAAA;gCAAO,CAAC;gCACnD,kBAAkB;4BACpB,CAAC;4BAED,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,IAAA,CAAK,EAAA;gCACvB,UAAU;gCACV,QAAQ;oCAAE,QAAQ,MAAM,IAAA,CAAK,MAAA;gCAAO;gCACpC,kBAAkB;4BACpB,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,iBAAiB;4BAC9C,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI,KAAA;4BACvC,eAAe;4BAEf,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;4BACjB,CAAC;4BAED,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,IAAA,CAAK,EAAA;gCACvB,UAAU;gCACV,OAAO;gCACP,kBAAkB;4BACpB,CAAC;4BAED,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,IAAA,CAAK,EAAA;gCACvB,UAAU;gCACV,QAAQ;oCACN,MAAM;oCACN,QAAQ,MAAM,IAAA,CAAK,MAAA,IAAU;gCAC/B;gCACA,kBAAkB;4BACpB,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,oBAAoB;4BACjD,gBAAA,CAAiB,MAAM,YAAY,CAAA,GAAI,KAAA;4BACvC,eAAe;4BAEf,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;4BACjB,CAAC;4BAED,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,IAAA,CAAK,EAAA;gCACvB,UAAU;gCACV,OAAO;gCACP,kBAAkB;4BACpB,CAAC;4BAED,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY,MAAM,IAAA,CAAK,EAAA;gCACvB,UAAU;gCACV,QAAQ;oCACN,MAAM;oCACN,QAAQ,MAAM,IAAA,CAAK,MAAA,IAAU;oCAC7B,GAAI,MAAM,IAAA,CAAK,OAAA,IAAW;wCAAE,SAAS,MAAM,IAAA,CAAK,OAAA;oCAAQ,CAAA;oCACxD,GAAI,MAAM,IAAA,CAAK,OAAA,IAAW;wCAAE,SAAS,MAAM,IAAA,CAAK,OAAA;oCAAQ,CAAA;gCAC1D;gCACA,kBAAkB;4BACpB,CAAC;wBACH,OAAA,IAAW,MAAM,IAAA,CAAK,IAAA,KAAS,WAAW;4BACxC,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,MAAM,IAAA,CAAK,EAAA;4BACjB,CAAC;wBACH,OAAA,IAAW,uCAAuC,KAAK,GAAG;4BACxD,MAAM,sBAAsB,eAAA,CAAgB,MAAM,IAAA,CAAK,EAAE,CAAA;4BAEzD,KAAA,MAAW,gBAAgB,oBAAoB,YAAA,CAAc;gCAC3D,WAAW,OAAA,CAAQ;oCACjB,MAAM;oCACN,IAAI,GAAG,MAAM,IAAA,CAAK,EAAE,CAAA,CAAA,EAAI,YAAY,EAAA;oCACpC,kBAAkB;wCAChB,QAAQ;4CACN,QAAQ,MAAM,IAAA,CAAK,EAAA;4CACnB,2BAAA,CACE,KAAA,MAAM,IAAA,CAAK,iBAAA,KAAX,OAAA,KAAgC;wCACpC;oCACF;gCACF,CAAC;4BACH;4BAEA,OAAO,eAAA,CAAgB,MAAM,IAAA,CAAK,EAAE,CAAA;wBACtC;oBACF,OAAA,IAAW,0CAA0C,KAAK,GAAG;wBAC3D,MAAM,WAAW,gBAAA,CAAiB,MAAM,YAAY,CAAA;wBAEpD,IAAI,YAAY,MAAM;4BACpB,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,SAAS,UAAA;gCACb,OAAO,MAAM,KAAA;4BACf,CAAC;wBACH;oBACF,OAAA,IAAW,uBAAuB,KAAK,GAAG;wBACxC,aAAa,MAAM,QAAA,CAAS,EAAA;wBAC5B,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,IAAI,MAAM,QAAA,CAAS,EAAA;4BACnB,WAAW,IAAI,KAAK,MAAM,QAAA,CAAS,UAAA,GAAa,GAAI;4BACpD,SAAS,MAAM,QAAA,CAAS,KAAA;wBAC1B,CAAC;oBACH,OAAA,IAAW,iBAAiB,KAAK,GAAG;wBAClC,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,IAAI,MAAM,OAAA;4BACV,OAAO,MAAM,KAAA;wBACf,CAAC;wBAED,IAAA,CAAA,CAAI,KAAA,CAAA,KAAA,QAAQ,eAAA,KAAR,OAAA,KAAA,IAAA,GAAyB,MAAA,KAAzB,OAAA,KAAA,IAAA,GAAiC,QAAA,KAAY,MAAM,QAAA,EAAU;4BAC/D,SAAS,IAAA,CAAK,MAAM,QAAQ;wBAC9B;oBACF,OAAA,IAAW,yCAAyC,KAAK,GAAG;wBAE1D,IAAI,MAAM,aAAA,GAAgB,GAAG;4BAC3B,CAAA,KAAA,eAAA,CAAgB,MAAM,OAAO,CAAA,KAA7B,OAAA,KAAA,IAAA,GAAgC,YAAA,CAAa,IAAA,CAC3C,MAAM,aAAA;4BAGR,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,IAAI,GAAG,MAAM,OAAO,CAAA,CAAA,EAAI,MAAM,aAAa,EAAA;gCAC3C,kBAAkB;oCAChB,QAAQ;wCACN,QAAQ,MAAM,OAAA;wCACd,2BAAA,CACE,KAAA,CAAA,KAAA,eAAA,CAAgB,MAAM,OAAO,CAAA,KAA7B,OAAA,KAAA,IAAA,GAAgC,gBAAA,KAAhC,OAAA,KACA;oCACJ;gCACF;4BACF,CAAC;wBACH;oBACF,OAAA,IAAW,yCAAyC,KAAK,GAAG;wBAC1D,WAAW,OAAA,CAAQ;4BACjB,MAAM;4BACN,IAAI,GAAG,MAAM,OAAO,CAAA,CAAA,EAAI,MAAM,aAAa,EAAA;4BAC3C,OAAO,MAAM,KAAA;4BACb,kBAAkB;gCAChB,QAAQ;oCACN,QAAQ,MAAM,OAAA;gCAChB;4BACF;wBACF,CAAC;oBACH,OAAA,IAAW,wBAAwB,KAAK,GAAG;wBACzC,eAAe,8BAA8B;4BAC3C,cAAA,CAAc,KAAA,MAAM,QAAA,CAAS,kBAAA,KAAf,OAAA,KAAA,IAAA,GAAmC,MAAA;4BACjD;wBACF,CAAC;wBACD,MAAM,WAAA,GAAc,MAAM,QAAA,CAAS,KAAA,CAAM,YAAA;wBACzC,MAAM,YAAA,GAAe,MAAM,QAAA,CAAS,KAAA,CAAM,aAAA;wBAC1C,MAAM,WAAA,GACJ,MAAM,QAAA,CAAS,KAAA,CAAM,YAAA,GACrB,MAAM,QAAA,CAAS,KAAA,CAAM,aAAA;wBACvB,MAAM,eAAA,GAAA,CACJ,KAAA,CAAA,KAAA,MAAM,QAAA,CAAS,KAAA,CAAM,qBAAA,KAArB,OAAA,KAAA,IAAA,GAA4C,gBAAA,KAA5C,OAAA,KACA,KAAA;wBACF,MAAM,iBAAA,GAAA,CACJ,KAAA,CAAA,KAAA,MAAM,QAAA,CAAS,KAAA,CAAM,oBAAA,KAArB,OAAA,KAAA,IAAA,GAA2C,aAAA,KAA3C,OAAA,KACA,KAAA;wBACF,IAAI,OAAO,MAAM,QAAA,CAAS,YAAA,KAAiB,UAAU;4BACnD,cAAc,MAAM,QAAA,CAAS,YAAA;wBAC/B;oBACF,OAAA,IAAW,+BAA+B,KAAK,GAAG;wBAChD,IAAI,MAAM,UAAA,CAAW,IAAA,KAAS,gBAAgB;4BAC5C,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY;gCACZ,IAAA,CAAI,KAAA,CAAA,KAAA,CAAA,KAAA,KAAK,MAAA,EAAO,UAAA,KAAZ,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,GAAA,KAAA,OAAA,SAA8BD,kMAAAA,CAAW;gCAC7C,KAAK,MAAM,UAAA,CAAW,GAAA;gCACtB,OAAO,MAAM,UAAA,CAAW,KAAA;4BAC1B,CAAC;wBACH,OAAA,IAAW,MAAM,UAAA,CAAW,IAAA,KAAS,iBAAiB;4BACpD,WAAW,OAAA,CAAQ;gCACjB,MAAM;gCACN,YAAY;gCACZ,IAAA,CAAI,KAAA,CAAA,KAAA,CAAA,KAAA,KAAK,MAAA,EAAO,UAAA,KAAZ,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,GAAA,KAAA,OAAA,SAA8BA,kMAAAA,CAAW;gCAC7C,WAAW;gCACX,OAAA,CACE,KAAA,CAAA,KAAA,MAAM,UAAA,CAAW,KAAA,KAAjB,OAAA,KACA,MAAM,UAAA,CAAW,QAAA,KADjB,OAAA,KAEA;gCACF,UAAA,CACE,KAAA,MAAM,UAAA,CAAW,QAAA,KAAjB,OAAA,KAA6B,MAAM,UAAA,CAAW,OAAA;4BAClD,CAAC;wBACH;oBACF,OAAA,IAAW,aAAa,KAAK,GAAG;wBAC9B,WAAW,OAAA,CAAQ;4BAAE,MAAM;4BAAS,OAAO;wBAAM,CAAC;oBACpD;gBACF;gBAEA,OAAM,UAAA,EAAY;oBAChB,MAAM,mBAA6C;wBACjD,QAAQ;4BACN;wBACF;oBACF;oBAEA,IAAI,SAAS,MAAA,GAAS,GAAG;wBACvB,iBAAiB,MAAA,CAAO,QAAA,GAAW;oBACrC;oBAEA,IAAI,gBAAgB,KAAA,GAAW;wBAC7B,iBAAiB,MAAA,CAAO,WAAA,GAAc;oBACxC;oBAEA,WAAW,OAAA,CAAQ;wBACjB,MAAM;wBACN;wBACA;wBACA;oBACF,CAAC;gBACH;YACF,CAAC;YAEH,SAAS;gBAAE;YAAK;YAChB,UAAU;gBAAE,SAAS;YAAgB;QACvC;IACF;AACF;AAEA,IAAMD,eAAcN,oLAAAA,CAAE,MAAA,CAAO;IAC3B,cAAcA,oLAAAA,CAAE,MAAA,CAAO;IACvB,sBAAsBA,oLAAAA,CACnB,MAAA,CAAO;QAAE,eAAeA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAAE,CAAC,EAC9C,OAAA,CAAQ;IACX,eAAeA,oLAAAA,CAAE,MAAA,CAAO;IACxB,uBAAuBA,oLAAAA,CACpB,MAAA,CAAO;QAAE,kBAAkBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAAE,CAAC,EACjD,OAAA,CAAQ;AACb,CAAC;AAED,IAAM,uBAAuBA,oLAAAA,CAAE,MAAA,CAAO;IACpC,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,4BAA4B;IAC5C,SAASA,oLAAAA,CAAE,MAAA,CAAO;IAClB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;IAChB,UAAU,gBAAgB,OAAA,CAAQ;AACpC,CAAC;AAED,IAAM,mBAAmBA,oLAAAA,CAAE,MAAA,CAAO;IAChC,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,OAAO;IACvB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;IACf,SAASA,oLAAAA,CAAE,MAAA,CAAO;IAClB,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC1B,iBAAiBA,oLAAAA,CAAE,MAAA,CAAO;AAC5B,CAAC;AAED,IAAM,8BAA8BA,oLAAAA,CAAE,MAAA,CAAO;IAC3C,MAAMA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAsB,qBAAqB;KAAC;IAC1D,UAAUA,oLAAAA,CAAE,MAAA,CAAO;QACjB,oBAAoBA,oLAAAA,CAAE,MAAA,CAAO;YAAE,QAAQA,oLAAAA,CAAE,MAAA,CAAO;QAAE,CAAC,EAAE,OAAA,CAAQ;QAC7D,OAAOM;QACP,cAAcN,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACnC,CAAC;AACH,CAAC;AAED,IAAM,6BAA6BA,oLAAAA,CAAE,MAAA,CAAO;IAC1C,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,kBAAkB;IAClC,UAAUA,oLAAAA,CAAE,MAAA,CAAO;QACjB,IAAIA,oLAAAA,CAAE,MAAA,CAAO;QACb,YAAYA,oLAAAA,CAAE,MAAA,CAAO;QACrB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAChB,cAAcA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACnC,CAAC;AACH,CAAC;AAED,IAAM,gCAAgCA,oLAAAA,CAAE,MAAA,CAAO;IAC7C,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,4BAA4B;IAC5C,cAAcA,oLAAAA,CAAE,MAAA,CAAO;IACvB,MAAMA,oLAAAA,CAAE,kBAAA,CAAmB,QAAQ;QACjCA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,SAAS;YACzB,IAAIA,oLAAAA,CAAE,MAAA,CAAO;QACf,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;YAC3B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,mBAAmBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACxC,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;YAC/B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,SAASA,oLAAAA,CAAE,MAAA,CAAO;YAClB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;YACf,WAAWA,oLAAAA,CAAE,MAAA,CAAO;QACtB,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,iBAAiB;YACjC,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,QAAQA,oLAAAA,CAAE,MAAA,CAAO;YACjB,QAAQA,oLAAAA,CACL,MAAA,CAAO;gBACN,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,QAAQ;gBACxB,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;YAC7B,CAAC,EACA,OAAA,CAAQ;QACb,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;YAC/B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,QAAQA,oLAAAA,CAAE,MAAA,CAAO;QACnB,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,kBAAkB;YAClC,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,QAAQA,oLAAAA,CAAE,MAAA,CAAO;YACjB,SAASA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ;YACrC,SAASA,oLAAAA,CACN,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;gBACP,YAAYA,oLAAAA,CAAE,MAAA,CAAO;oBACnB,SAASA,oLAAAA,CAAE,MAAA,CAAO;oBAClB,UAAUA,oLAAAA,CAAE,MAAA,CAAO;oBACnB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;oBAChB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;gBACjB,CAAC;YACH,CAAC,GAEF,QAAA,CAAS;QACd,CAAC;KACF;AACH,CAAC;AAED,IAAM,+BAA+BA,oLAAAA,CAAE,MAAA,CAAO;IAC5C,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,2BAA2B;IAC3C,cAAcA,oLAAAA,CAAE,MAAA,CAAO;IACvB,MAAMA,oLAAAA,CAAE,kBAAA,CAAmB,QAAQ;QACjCA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,SAAS;YACzB,IAAIA,oLAAAA,CAAE,MAAA,CAAO;QACf,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;YAC3B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,mBAAmBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QACxC,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;YAC/B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,SAASA,oLAAAA,CAAE,MAAA,CAAO;YAClB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;YACf,WAAWA,oLAAAA,CAAE,MAAA,CAAO;YACpB,QAAQA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;QAC/B,CAAC;QACD;QACAA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;YAC/B,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,QAAQA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;QAC/B,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,kBAAkB;YAClC,IAAIA,oLAAAA,CAAE,MAAA,CAAO;YACb,QAAQA,oLAAAA,CAAE,OAAA,CAAQ,WAAW;YAC7B,SAASA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,OAAA,CAAQ;YACrC,SAASA,oLAAAA,CACN,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;gBACP,YAAYA,oLAAAA,CAAE,MAAA,CAAO;oBACnB,SAASA,oLAAAA,CAAE,MAAA,CAAO;oBAClB,UAAUA,oLAAAA,CAAE,MAAA,CAAO;oBACnB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;oBAChB,MAAMA,oLAAAA,CAAE,MAAA,CAAO;gBACjB,CAAC;YACH,CAAC,GAEF,OAAA,CAAQ;QACb,CAAC;KACF;AACH,CAAC;AAED,IAAM,2CAA2CA,oLAAAA,CAAE,MAAA,CAAO;IACxD,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,wCAAwC;IACxD,SAASA,oLAAAA,CAAE,MAAA,CAAO;IAClB,cAAcA,oLAAAA,CAAE,MAAA,CAAO;IACvB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;AAClB,CAAC;AAED,IAAM,gCAAgCA,oLAAAA,CAAE,MAAA,CAAO;IAC7C,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,uCAAuC;IACvD,YAAYA,oLAAAA,CAAE,kBAAA,CAAmB,QAAQ;QACvCA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,cAAc;YAC9B,KAAKA,oLAAAA,CAAE,MAAA,CAAO;YACd,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAClB,CAAC;QACDA,oLAAAA,CAAE,MAAA,CAAO;YACP,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,eAAe;YAC/B,SAASA,oLAAAA,CAAE,MAAA,CAAO;YAClB,UAAUA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC7B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC1B,aAAaA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAChC,WAAWA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;YAC9B,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;QAC5B,CAAC;KACF;AACH,CAAC;AAED,IAAM,0CAA0CA,oLAAAA,CAAE,MAAA,CAAO;IACvD,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,uCAAuC;IACvD,SAASA,oLAAAA,CAAE,MAAA,CAAO;IAClB,eAAeA,oLAAAA,CAAE,MAAA,CAAO;AAC1B,CAAC;AAED,IAAM,0CAA0CA,oLAAAA,CAAE,MAAA,CAAO;IACvD,MAAMA,oLAAAA,CAAE,OAAA,CAAQ,uCAAuC;IACvD,SAASA,oLAAAA,CAAE,MAAA,CAAO;IAClB,eAAeA,oLAAAA,CAAE,MAAA,CAAO;IACxB,OAAOA,oLAAAA,CAAE,MAAA,CAAO;AAClB,CAAC;AAED,IAAM,6BAA6BA,oLAAAA,CAAE,KAAA,CAAM;IACzC;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACAA,oLAAAA,CAAE,MAAA,CAAO;QAAE,MAAMA,oLAAAA,CAAE,MAAA,CAAO;IAAE,CAAC,EAAE,KAAA,CAAM;CACtC;AAOD,SAAS,iBACP,KAAA,EAC+C;IAC/C,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,8BACP,KAAA,EACuD;IACvD,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,uCACP,KAAA,EAMA;IACA,OACE,8BAA8B,KAAK,KAAK,MAAM,IAAA,CAAK,IAAA,KAAS;AAEhE;AAEA,SAAS,wBACP,KAAA,EACsD;IACtD,OACE,MAAM,IAAA,KAAS,wBAAwB,MAAM,IAAA,KAAS;AAE1D;AAEA,SAAS,uBACP,KAAA,EACqD;IACrD,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,0CACP,KAAA,EACmE;IACnE,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,+BACP,KAAA,EACwD;IACxD,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,wCACP,KAAA,EAMA;IACA,OACE,+BAA+B,KAAK,KAAK,MAAM,IAAA,CAAK,IAAA,KAAS;AAEjE;AAEA,SAAS,+BACP,KAAA,EACwD;IACxD,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,yCACP,KAAA,EACkE;IAClE,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,yCACP,KAAA,EACkE;IAClE,OAAO,MAAM,IAAA,KAAS;AACxB;AAEA,SAAS,aACP,KAAA,EAC2C;IAC3C,OAAO,MAAM,IAAA,KAAS;AACxB;AAUA,SAAS,wBAAwB,OAAA,EAAuC;IACtE,MAAMS,0BACJ,QAAQ,UAAA,CAAW,IAAI,KACvB,QAAQ,UAAA,CAAW,SAAS,KAC3B,QAAQ,UAAA,CAAW,OAAO,KAAK,CAAC,QAAQ,UAAA,CAAW,YAAY;IAClE,MAAMC,8BACJ,QAAQ,UAAA,CAAW,OAAO,KAC1B,QAAQ,UAAA,CAAW,YAAY,KAC9B,QAAQ,UAAA,CAAW,OAAO,KACzB,CAAC,QAAQ,UAAA,CAAW,YAAY,KAChC,CAAC,QAAQ,UAAA,CAAW,YAAY,KAClC,QAAQ,UAAA,CAAW,IAAI,KACvB,QAAQ,UAAA,CAAW,SAAS;IAC9B,MAAM,WAAW;QACf,wBAAwB;QACxB,mBAAmB;QACnB,wBAAAD;QACA,4BAAAC;IACF;IAGA,IAAI,QAAQ,UAAA,CAAW,YAAY,GAAG;QACpC,OAAO;YACL,GAAG,QAAA;YACH,kBAAkB;QACpB;IACF;IAGA,IACE,QAAQ,UAAA,CAAW,GAAG,KACtB,QAAQ,UAAA,CAAW,OAAO,KAC1B,QAAQ,UAAA,CAAW,QAAQ,KAC3B,QAAQ,UAAA,CAAW,cAAc,GACjC;QACA,IAAI,QAAQ,UAAA,CAAW,SAAS,KAAK,QAAQ,UAAA,CAAW,YAAY,GAAG;YACrE,OAAO;gBACL,GAAG,QAAA;gBACH,kBAAkB;gBAClB,mBAAmB;YACrB;QACF;QAEA,OAAO;YACL,GAAG,QAAA;YACH,kBAAkB;YAClB,mBAAmB;QACrB;IACF;IAGA,OAAO;QACL,GAAG,QAAA;QACH,kBAAkB;IACpB;AACF;AAGA,IAAM,uCAAuCV,oLAAAA,CAAE,MAAA,CAAO;IACpD,UAAUA,oLAAAA,CAAE,GAAA,CAAI,EAAE,OAAA,CAAQ;IAC1B,mBAAmBA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,OAAA,CAAQ;IACvC,oBAAoBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACvC,OAAOA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,OAAA,CAAQ;IAC3B,MAAMA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACzB,iBAAiBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACpC,kBAAkBA,oLAAAA,CAAE,OAAA,CAAQ,EAAE,OAAA,CAAQ;IACtC,cAAcA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACjC,kBAAkBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACrC,aAAaA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAQ;QAAQ,UAAU;KAAC,EAAE,OAAA,CAAQ;IAC1D,SAASA,oLAAAA,CACN,KAAA,CACCA,oLAAAA,CAAE,IAAA,CAAK;QACL;QACA;QACA;KACD,GAEF,OAAA,CAAQ;IACX,eAAeA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAO;QAAU,MAAM;KAAC,EAAE,OAAA,CAAQ;IACzD,gBAAgBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACnC,kBAAkBA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAAA;;;;;;;;;;;GAAA,GAcrC,UAAUA,oLAAAA,CACP,KAAA,CAAM;QAACA,oLAAAA,CAAE,OAAA,CAAQ;QAAGA,oLAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,CAAC,EAAE,GAAA,CAAI,gBAAgB,CAAC;KAAC,EAC5D,QAAA,CAAS;AACd,CAAC;;;AIp5CD,IAAM,8BAA8Be,oLAAAA,CAAE,MAAA,CAAO;IAC3C,cAAcA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IACjC,OAAOA,oLAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,IAAI,EAAE,GAAA,CAAI,CAAG,EAAE,OAAA,CAAQ,CAAG,EAAE,OAAA,CAAQ;AAC5D,CAAC;AAYM,IAAM,oBAAN,MAAiD;IAOtD,YACW,OAAA,EACQ,MAAA,CACjB;QAFS,IAAA,CAAA,OAAA,GAAA;QACQ,IAAA,CAAA,MAAA,GAAA;QARnB,IAAA,CAAS,oBAAA,GAAuB;IAS7B;IAPH,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAOA,MAAc,QAAQ,EACpB,IAAA,EACA,QAAQ,OAAA,EACR,eAAe,KAAA,EACf,KAAA,EACA,YAAA,EACA,QAAA,EACA,eAAA,EACF,EAA+C;QAC7C,MAAM,WAAuC,CAAC,CAAA;QAG9C,MAAM,gBAAgB,UAAMC,4MAAAA,EAAqB;YAC/C,UAAU;YACV;YACA,QAAQ;QACV,CAAC;QAGD,MAAM,cAAuC;YAC3C,OAAO,IAAA,CAAK,OAAA;YACZ,OAAO;YACP;YACA,iBAAiB;YACjB;YACA;QACF;QAEA,IAAI,cAAc;YAChB,IAAI;gBAAC;gBAAO;gBAAQ;gBAAO;gBAAQ;gBAAO,KAAK;aAAA,CAAE,QAAA,CAAS,YAAY,GAAG;gBACvE,YAAY,eAAA,GAAkB;YAChC,OAAO;gBACL,SAAS,IAAA,CAAK;oBACZ,MAAM;oBACN,SAAS;oBACT,SAAS,CAAA,2BAAA,EAA8B,YAAY,CAAA,oBAAA,CAAA;gBACrD,CAAC;YACH;QACF;QAGA,IAAI,eAAe;YACjB,MAAM,qBAA2C,CAAC;YAElD,IAAA,MAAW,OAAO,mBAAoB;gBACpC,MAAM,QAAQ,kBAAA,CAAmB,GAAiC,CAAA;gBAClE,IAAI,UAAU,KAAA,GAAW;oBACvB,WAAA,CAAY,GAAG,CAAA,GAAI;gBACrB;YACF;QACF;QAEA,IAAI,UAAU;YACZ,SAAS,IAAA,CAAK;gBACZ,MAAM;gBACN,SAAS;gBACT,SAAS,CAAA,4EAAA,EAA+E,QAAQ,CAAA,cAAA,CAAA;YAClG,CAAC;QACH;QAEA,OAAO;YACL;YACA;QACF;IACF;IAEA,MAAM,WACJ,OAAA,EAC2D;QA7G/D,IAAA,IAAA,IAAA;QA8GI,MAAM,cAAA,CAAc,KAAA,CAAA,KAAA,CAAA,KAAA,IAAA,CAAK,MAAA,CAAO,SAAA,KAAZ,OAAA,KAAA,IAAA,GAAuB,WAAA,KAAvB,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,GAAA,KAAA,OAAA,KAA0C,aAAA,GAAA,IAAI,KAAK;QACvE,MAAM,EAAE,WAAA,EAAa,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAE5D,MAAM,EACJ,OAAO,KAAA,EACP,eAAA,EACA,UAAU,WAAA,EACZ,GAAI,UAAMC,qMAAAA,EAAc;YACtB,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D,MAAM;YACN,uBAAuB;YACvB,+BAA2B,mNAAA,CAA4B;YACvD,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,OAAO;YACL;YACA;YACA,SAAS;gBACP,MAAM,KAAK,SAAA,CAAU,WAAW;YAClC;YACA,UAAU;gBACR,WAAW;gBACX,SAAS,IAAA,CAAK,OAAA;gBACd,SAAS;gBACT,MAAM;YACR;QACF;IACF;AACF;;;;AEvIO,IAAM,qCAAqCK,oLAAAA,CAAE,MAAA,CAAO;IAAA;;GAAA,GAKzD,SAASA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC,EAAE,QAAA,CAAS;IAAA;;GAAA,GAKtC,UAAUA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;GAAA,GAK9B,QAAQA,oLAAAA,CAAE,MAAA,CAAO,EAAE,QAAA,CAAS;IAAA;;;GAAA,GAM5B,aAAaA,oLAAAA,CAAE,MAAA,CAAO,EAAE,GAAA,CAAI,CAAC,EAAE,GAAA,CAAI,CAAC,EAAE,OAAA,CAAQ,CAAC,EAAE,QAAA,CAAS;IAAA;;;GAAA,GAM1D,wBAAwBA,oLAAAA,CACrB,KAAA,CAAMA,oLAAAA,CAAE,IAAA,CAAK;QAAC;QAAQ,SAAS;KAAC,CAAC,EACjC,OAAA,CAAQ;QAAC,SAAS;KAAC,EACnB,QAAA,CAAS;AACd,CAAC;;ADFD,IAAM,cAAc;IAClB,WAAW;IACX,QAAQ;IACR,UAAU;IACV,aAAa;IACb,YAAY;IACZ,SAAS;IACT,WAAW;IACX,SAAS;IACT,SAAS;IACT,UAAU;IACV,OAAO;IACP,QAAQ;IACR,OAAO;IACP,SAAS;IACT,UAAU;IACV,SAAS;IACT,QAAQ;IACR,UAAU;IACV,QAAQ;IACR,OAAO;IACP,QAAQ;IACR,OAAO;IACP,WAAW;IACX,WAAW;IACX,YAAY;IACZ,SAAS;IACT,UAAU;IACV,SAAS;IACT,QAAQ;IACR,QAAQ;IACR,SAAS;IACT,YAAY;IACZ,YAAY;IACZ,OAAO;IACP,SAAS;IACT,OAAO;IACP,QAAQ;IACR,WAAW;IACX,SAAS;IACT,QAAQ;IACR,YAAY;IACZ,UAAU;IACV,SAAS;IACT,SAAS;IACT,QAAQ;IACR,WAAW;IACX,SAAS;IACT,SAAS;IACT,SAAS;IACT,SAAS;IACT,OAAO;IACP,MAAM;IACN,SAAS;IACT,WAAW;IACX,MAAM;IACN,YAAY;IACZ,OAAO;AACT;AAEO,IAAM,2BAAN,MAA+D;IAOpE,YACW,OAAA,EACQ,MAAA,CACjB;QAFS,IAAA,CAAA,OAAA,GAAA;QACQ,IAAA,CAAA,MAAA,GAAA;QARnB,IAAA,CAAS,oBAAA,GAAuB;IAS7B;IAPH,IAAI,WAAmB;QACrB,OAAO,IAAA,CAAK,MAAA,CAAO,QAAA;IACrB;IAOA,MAAc,QAAQ,EACpB,KAAA,EACA,SAAA,EACA,eAAA,EACF,EAAmC;QACjC,MAAM,WAA8C,CAAC,CAAA;QAGrD,MAAM,gBAAgB,UAAMC,4MAAAA,EAAqB;YAC/C,UAAU;YACV;YACA,QAAQ;QACV,CAAC;QAGD,MAAM,WAAW,IAAI,SAAS;QAC9B,MAAM,OACJ,iBAAiB,aACb,IAAI,KAAK;YAAC,KAAK;SAAC,IAChB,IAAI,KAAK;gBAAC,iNAAA,EAA0B,KAAK,CAAC;SAAC;QAEjD,SAAS,MAAA,CAAO,SAAS,IAAA,CAAK,OAAO;QACrC,MAAM,oBAAgB,4MAAA,EAAqB,SAAS;QACpD,SAAS,MAAA,CACP,QACA,IAAI,KAAK;YAAC,IAAI;SAAA,EAAG,SAAS;YAAE,MAAM;QAAU,CAAC,GAC7C,CAAA,MAAA,EAAS,aAAa,EAAA;QAIxB,IAAI,eAAe;YACjB,MAAM,4BAA4B;gBAChC,SAAS,cAAc,OAAA;gBACvB,UAAU,cAAc,QAAA;gBACxB,QAAQ,cAAc,MAAA;gBAAA,qHAAA;gBAAA,iEAAA;gBAGtB,iBAAiB;oBACf;oBACA;iBACF,CAAE,QAAA,CAAS,IAAA,CAAK,OAAO,IACnB,SACA;gBACJ,aAAa,cAAc,WAAA;gBAC3B,yBAAyB,cAAc,sBAAA;YACzC;YAEA,KAAA,MAAW,CAAC,KAAK,KAAK,CAAA,IAAK,OAAO,OAAA,CAAQ,yBAAyB,EAAG;gBACpE,IAAI,SAAS,MAAM;oBACjB,SAAS,MAAA,CAAO,KAAK,OAAO,KAAK,CAAC;gBACpC;YACF;QACF;QAEA,OAAO;YACL;YACA;QACF;IACF;IAEA,MAAM,WACJ,OAAA,EACkE;QA5KtE,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA,IAAA;QA6KI,MAAM,cAAA,CAAc,KAAA,CAAA,KAAA,CAAA,KAAA,IAAA,CAAK,MAAA,CAAO,SAAA,KAAZ,OAAA,KAAA,IAAA,GAAuB,WAAA,KAAvB,OAAA,KAAA,IAAA,GAAA,IAAA,CAAA,GAAA,KAAA,OAAA,KAA0C,aAAA,GAAA,IAAI,KAAK;QACvE,MAAM,EAAE,QAAA,EAAU,QAAA,CAAS,CAAA,GAAI,MAAM,IAAA,CAAK,OAAA,CAAQ,OAAO;QAEzD,MAAM,EACJ,OAAO,QAAA,EACP,eAAA,EACA,UAAU,WAAA,EACZ,GAAI,UAAM,yMAAA,EAAkB;YAC1B,KAAK,IAAA,CAAK,MAAA,CAAO,GAAA,CAAI;gBACnB,MAAM;gBACN,SAAS,IAAA,CAAK,OAAA;YAChB,CAAC;YACD,aAASC,sMAAAA,EAAe,IAAA,CAAK,MAAA,CAAO,OAAA,CAAQ,GAAG,QAAQ,OAAO;YAC9D;YACA,uBAAuB;YACvB,+BAA2BC,iNAAAA,EACzB;YAEF,aAAa,QAAQ,WAAA;YACrB,OAAO,IAAA,CAAK,MAAA,CAAO,KAAA;QACrB,CAAC;QAED,MAAM,WACJ,SAAS,QAAA,IAAY,QAAQ,SAAS,QAAA,IAAY,cAC9C,WAAA,CAAY,SAAS,QAAoC,CAAA,GACzD,KAAA;QAEN,OAAO;YACL,MAAM,SAAS,IAAA;YACf,UAAA,CACE,KAAA,CAAA,KAAA,CAAA,KAAA,SAAS,QAAA,KAAT,OAAA,KAAA,IAAA,GAAmB,GAAA,CAAI,CAAA,UAAA,CAAY;oBACjC,MAAM,QAAQ,IAAA;oBACd,aAAa,QAAQ,KAAA;oBACrB,WAAW,QAAQ,GAAA;gBACrB,CAAA,EAAA,KAJA,OAAA,KAAA,CAKA,KAAA,SAAS,KAAA,KAAT,OAAA,KAAA,IAAA,GAAgB,GAAA,CAAI,CAAA,OAAA,CAAS;oBAC3B,MAAM,KAAK,IAAA;oBACX,aAAa,KAAK,KAAA;oBAClB,WAAW,KAAK,GAAA;gBAClB,CAAA,EAAA,KATA,OAAA,KAUA,CAAC,CAAA;YACH;YACA,mBAAA,CAAmB,KAAA,SAAS,QAAA,KAAT,OAAA,KAAqB,KAAA;YACxC;YACA,UAAU;gBACR,WAAW;gBACX,SAAS,IAAA,CAAK,OAAA;gBACd,SAAS;gBACT,MAAM;YACR;QACF;IACF;AACF;AAEA,IAAM,oCAAoCC,oLAAAA,CAAE,MAAA,CAAO;IACjD,MAAMA,oLAAAA,CAAE,MAAA,CAAO;IACf,UAAUA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC7B,UAAUA,oLAAAA,CAAE,MAAA,CAAO,EAAE,OAAA,CAAQ;IAC7B,OAAOA,oLAAAA,CACJ,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;QACP,MAAMA,oLAAAA,CAAE,MAAA,CAAO;QACf,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAChB,KAAKA,oLAAAA,CAAE,MAAA,CAAO;IAChB,CAAC,GAEF,OAAA,CAAQ;IACX,UAAUA,oLAAAA,CACP,KAAA,CACCA,oLAAAA,CAAE,MAAA,CAAO;QACP,IAAIA,oLAAAA,CAAE,MAAA,CAAO;QACb,MAAMA,oLAAAA,CAAE,MAAA,CAAO;QACf,OAAOA,oLAAAA,CAAE,MAAA,CAAO;QAChB,KAAKA,oLAAAA,CAAE,MAAA,CAAO;QACd,MAAMA,oLAAAA,CAAE,MAAA,CAAO;QACf,QAAQA,oLAAAA,CAAE,KAAA,CAAMA,oLAAAA,CAAE,MAAA,CAAO,CAAC;QAC1B,aAAaA,oLAAAA,CAAE,MAAA,CAAO;QACtB,aAAaA,oLAAAA,CAAE,MAAA,CAAO;QACtB,mBAAmBA,oLAAAA,CAAE,MAAA,CAAO;QAC5B,gBAAgBA,oLAAAA,CAAE,MAAA,CAAO;IAC3B,CAAC,GAEF,OAAA,CAAQ;AACb,CAAC;;A1B1HM,SAAS,aACd,UAAkC,CAAC,CAAA,EACnB;IAxIlB,IAAA,IAAA;IAyIE,MAAM,UAAA,CACJ,KAAA,IAAA,4MAAA,EAAqB,QAAQ,OAAO,CAAA,KAApC,OAAA,KAAyC;IAE3C,MAAM,eAAA,CAAe,KAAA,QAAQ,IAAA,KAAR,OAAA,KAAgB;IAErC,MAAM,aAAa,IAAA,CAAO;YACxB,eAAe,CAAA,OAAA,MAAU,kMAAA,EAAW;gBAClC,QAAQ,QAAQ,MAAA;gBAChB,yBAAyB;gBACzB,aAAa;YACf,CAAC,CAAC,EAAA;YACF,uBAAuB,QAAQ,YAAA;YAC/B,kBAAkB,QAAQ,OAAA;YAC1B,GAAG,QAAQ,OAAA;QACb,CAAA;IAEA,MAAM,kBAAkB,CAAC,UACvB,IAAI,wBAAwB,SAAS;YACnC,UAAU,GAAG,YAAY,CAAA,KAAA,CAAA;YACzB,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,GAAM,GAAG,OAAO,GAAG,IAAI,EAAA;YACpC,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAC;IAEH,MAAM,wBAAwB,CAAC,UAC7B,IAAI,8BAA8B,SAAS;YACzC,UAAU,GAAG,YAAY,CAAA,WAAA,CAAA;YACzB,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,GAAM,GAAG,OAAO,GAAG,IAAI,EAAA;YACpC,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAC;IAEH,MAAM,uBAAuB,CAAC,UAC5B,IAAI,qBAAqB,SAAS;YAChC,UAAU,GAAG,YAAY,CAAA,UAAA,CAAA;YACzB,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,GAAM,GAAG,OAAO,GAAG,IAAI,EAAA;YACpC,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAC;IAEH,MAAM,mBAAmB,CAAC,UACxB,IAAI,iBAAiB,SAAS;YAC5B,UAAU,GAAG,YAAY,CAAA,MAAA,CAAA;YACzB,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,GAAM,GAAG,OAAO,GAAG,IAAI,EAAA;YACpC,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAC;IAEH,MAAM,2BAA2B,CAAC,UAChC,IAAI,yBAAyB,SAAS;YACpC,UAAU,GAAG,YAAY,CAAA,cAAA,CAAA;YACzB,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,GAAM,GAAG,OAAO,GAAG,IAAI,EAAA;YACpC,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAC;IAEH,MAAM,oBAAoB,CAAC,UACzB,IAAI,kBAAkB,SAAS;YAC7B,UAAU,GAAG,YAAY,CAAA,OAAA,CAAA;YACzB,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,GAAM,GAAG,OAAO,GAAG,IAAI,EAAA;YACpC,SAAS;YACT,OAAO,QAAQ,KAAA;QACjB,CAAC;IAEH,MAAM,sBAAsB,CAAC,YAAoC;QAC/D,IAAI,YAAY;YACd,MAAM,IAAI,MACR;QAEJ;QAEA,OAAO,qBAAqB,OAAO;IACrC;IAEA,MAAM,uBAAuB,CAAC,YAAoC;QAChE,OAAO,IAAI,6BAA6B,SAAS;YAC/C,UAAU,GAAG,YAAY,CAAA,UAAA,CAAA;YACzB,KAAK,CAAC,EAAE,IAAA,CAAK,CAAA,GAAM,GAAG,OAAO,GAAG,IAAI,EAAA;YACpC,SAAS;YACT,OAAO,QAAQ,KAAA;YACf,gBAAgB;gBAAC,OAAO;aAAA;QAC1B,CAAC;IACH;IAEA,MAAM,WAAW,SAAU,OAAA,EAAiC;QAC1D,OAAO,oBAAoB,OAAO;IACpC;IAEA,SAAS,aAAA,GAAgB;IACzB,SAAS,IAAA,GAAO;IAChB,SAAS,UAAA,GAAa;IACtB,SAAS,SAAA,GAAY;IACrB,SAAS,SAAA,GAAY;IACrB,SAAS,aAAA,GAAgB;IACzB,SAAS,kBAAA,GAAqB;IAE9B,SAAS,KAAA,GAAQ;IACjB,SAAS,UAAA,GAAa;IAEtB,SAAS,aAAA,GAAgB;IACzB,SAAS,kBAAA,GAAqB;IAE9B,SAAS,MAAA,GAAS;IAClB,SAAS,WAAA,GAAc;IAEvB,SAAS,KAAA,GAAQ;IAEjB,OAAO;AACT;AAKO,IAAM,SAAS,aAAa","debugId":null}}]
}